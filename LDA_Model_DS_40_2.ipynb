{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA Model_DS_40_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ilyaas189/Text-Analytics_CE_807/blob/main/LDA_Model_DS_40_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "h48neXM-ANwE",
        "outputId": "956a17ed-2434-49ef-a6dc-048dac08f01c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from google.colab import files\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import random\n",
        "uploaded = files.upload()\n",
        "files = list(uploaded.keys())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-64ad856b-541a-4724-bf8d-b9bb47427b84\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-64ad856b-541a-4724-bf8d-b9bb47427b84\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcrJU_pzAhOm",
        "outputId": "40a97d92-5ba5-45b1-9d7e-5f01866b1354"
      },
      "source": [
        "# Import Dataset\n",
        "data = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "print(data.target_names.unique())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
            " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
            " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
            " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
            " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
            " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "SnGiNUYGAtLQ",
        "outputId": "473f698c-3531-4a5d-ce88-e9b5b6e6afee"
      },
      "source": [
        "data.head(20)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
              "      <td>16</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
              "      <td>13</td>\n",
              "      <td>sci.med</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
              "      <td>3</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
              "      <td>8</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>From: david@terminus.ericsson.se (David Bold)\\...</td>\n",
              "      <td>19</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>From: dbm0000@tm0006.lerc.nasa.gov (David B. M...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...</td>\n",
              "      <td>6</td>\n",
              "      <td>misc.forsale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...</td>\n",
              "      <td>12</td>\n",
              "      <td>sci.electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>From: abarden@tybse1.uucp (Ann Marie Barden)\\n...</td>\n",
              "      <td>5</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              content  ...              target_names\n",
              "0   From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...                 rec.autos\n",
              "1   From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...     comp.sys.mac.hardware\n",
              "2   From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...     comp.sys.mac.hardware\n",
              "3   From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...             comp.graphics\n",
              "4   From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...                 sci.space\n",
              "5   From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...  ...        talk.politics.guns\n",
              "6   From: bmdelane@quads.uchicago.edu (brian manni...  ...                   sci.med\n",
              "7   From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...  ...  comp.sys.ibm.pc.hardware\n",
              "8   From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...  ...   comp.os.ms-windows.misc\n",
              "9   From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...  ...     comp.sys.mac.hardware\n",
              "10  From: irwin@cmptrc.lonestar.org (Irwin Arnstei...  ...           rec.motorcycles\n",
              "11  From: david@terminus.ericsson.se (David Bold)\\...  ...        talk.religion.misc\n",
              "12  From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...  ...     comp.sys.mac.hardware\n",
              "13  From: dbm0000@tm0006.lerc.nasa.gov (David B. M...  ...                 sci.space\n",
              "14  From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...  ...              misc.forsale\n",
              "15  From: mathew <mathew@mantis.co.uk>\\nSubject: R...  ...               alt.atheism\n",
              "16  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...  ...             comp.graphics\n",
              "17  From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...  ...                 rec.autos\n",
              "18  From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...  ...           sci.electronics\n",
              "19  From: abarden@tybse1.uucp (Ann Marie Barden)\\n...  ...            comp.windows.x\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1t4Hd65BKo4",
        "outputId": "ec796cf8-2712-49ea-97af-c870dec7337f"
      },
      "source": [
        "data_clusterization = data[['content', 'target_names']]\n",
        "data_clusterization.dropna(inplace=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "0xRJ8_03Bd1W",
        "outputId": "5a590c1a-4a39-4465-8cd4-06613b3cfe0e"
      },
      "source": [
        "data_clusterization.head(2)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content           target_names\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...              rec.autos\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  comp.sys.mac.hardware"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iUh1DoLBmXP",
        "outputId": "8c8c8365-1e6c-4377-ad54-af5d92df56bb"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7hwfWd1Bw8S"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        " stemmer = SnowballStemmer(language='english')\n",
        " return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        " result = []\n",
        " for token in gensim.utils.simple_preprocess(text):\n",
        "   if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "     result.append(lemmatize_stemming(token))\n",
        " return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJfVX8biB_Sa"
      },
      "source": [
        "processed_docs = data_clusterization['content'].map(preprocess)\n",
        "data_processed = processed_docs.to_frame()\n",
        "data_processed['content'] = data_processed.content.apply(lambda x: ' '.join(x))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCHPTBYJClMy",
        "outputId": "0677ca00-001a-4bdb-a7f1-0e02a1f4d215"
      },
      "source": [
        "!pip install tokenize_uk\n",
        "from collections import Counter\n",
        "from tokenize_uk.tokenize_uk import tokenize_words"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenize_uk\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/21/72abb0304b532e1b2d2473b50d8063ddd0943e3b3fe7e86b366bc4d02aa2/tokenize_uk-0.2.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tokenize_uk) (1.15.0)\n",
            "Building wheels for collected packages: tokenize-uk\n",
            "  Building wheel for tokenize-uk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tokenize-uk: filename=tokenize_uk-0.2.0-py2.py3-none-any.whl size=4565 sha256=cfa4d3cf3538117d629df6294ef1e6052e9f0caf8cc437ce9a5e9832ba84e27f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/e1/95/fd8af5b40aeebdc4e178974e7f638f5553aa8772117054db9e\n",
            "Successfully built tokenize-uk\n",
            "Installing collected packages: tokenize-uk\n",
            "Successfully installed tokenize-uk-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "94mq8WUoCqHq",
        "outputId": "14eebf25-96b4-4d16-f6c6-7787754511d9"
      },
      "source": [
        "def display_words(data, title, ax):\n",
        " count = Counter(sum(map(lambda text: tokenize_words(text), data), []))\n",
        " popular = np.array(sorted(count.items(), key=lambda x: x[1], reverse=True)[:20])\n",
        " plt.sca(ax)\n",
        " plt.title(title)\n",
        " plt.bar(popular[:,0], np.int32(popular[:,1]))\n",
        " plt.xticks(rotation=\"vertical\")\n",
        "fig, ax = plt.subplots(figsize=(16, 5))\n",
        "display_words(data_processed.sample(1000).content, \"The most popular words]\", ax)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCM4qevNC5Ty"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMnRgz3aC8f5",
        "outputId": "8b8307f8-8a66-4afc-d3b7-30873515d9ee"
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "count_data = count_vectorizer.fit_transform(data_processed['content'])\n",
        "count_data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11314x61410 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 934270 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TmSX73jDEJS"
      },
      "source": [
        "likelihood = []\n",
        "n_clusters = []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9uTcUJlDHT0"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hki6oWR0DLwb"
      },
      "source": [
        "def estimate_number_clusters(data, nclusters):\n",
        " for n in nclusters:\n",
        "   likelihood.append(LDA(n_components=n, n_jobs=-1).fit(data).score(data))\n",
        " n_clusters.append(n)\n",
        " print(\"Sccesfully estimated \", n)\n",
        " fig, ax = plt.subplots(figsize=(15, 5))\n",
        " sns.lineplot(x=n_clusters, y=likelihood, ax=ax)\n",
        " ax.set_title('Elbow method for choosing n, likelihood')\n",
        " ax.set_ylabel('Likelihood')\n",
        " ax.set_xlabel('n')\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CBG_y1fJszZ"
      },
      "source": [
        "# estimate_number_clusters(count_data, [10, 15, 20, 50])\n",
        " \n",
        " "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XNMixjQJuYE"
      },
      "source": [
        "def print_topics(model, count_vectorizer, n_top_words):\n",
        "  words = count_vectorizer.get_feature_names()\n",
        "  for topic_idx, topic in enumerate(model.components_):\n",
        "    print(\"\\nTopic #%d:\" % topic_idx)\n",
        "    print(\" \".join([words[i]\n",
        "  for i in topic.argsort()[:-n_top_words - 1:-1]]))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugizp_hhFpzm"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWtTkYX1Ftia",
        "outputId": "6a56405a-bf05-445c-c4d4-80fc82c1a901"
      },
      "source": [
        "number_topics = 40\n",
        "number_words = 10\n",
        "# Create and fit the LDA model\n",
        "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
        "lda.fit(count_data)\n",
        "# Print the topics found by the LDA model\n",
        "print(\"Topics found via LDA:\")\n",
        "print_topics(lda, count_vectorizer, number_words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topics found via LDA:\n",
            "\n",
            "Topic #0:\n",
            "drive card line subject driver organ control scsi problem work\n",
            "\n",
            "Topic #1:\n",
            "moral write subject line organ post host object caltech cwru\n",
            "\n",
            "Topic #2:\n",
            "line subject organ post write nntp host andrew articl univers\n",
            "\n",
            "Topic #3:\n",
            "access insur digex subject organ line write alaska post articl\n",
            "\n",
            "Topic #4:\n",
            "line organ subject henri launch toronto netcom radar post write\n",
            "\n",
            "Topic #5:\n",
            "line subject organ write post articl host work nntp problem\n",
            "\n",
            "Topic #6:\n",
            "line organ subject post univers nntp host colorado point articl\n",
            "\n",
            "Topic #7:\n",
            "line subject organ sale univers post game columbia host nntp\n",
            "\n",
            "Topic #8:\n",
            "write subject line organ indiana articl freenet carleton monash univers\n",
            "\n",
            "Topic #9:\n",
            "line subject organ like wire power good time write look\n",
            "\n",
            "Topic #10:\n",
            "subject line organ nasa post articl write nntp host david\n",
            "\n",
            "Topic #11:\n",
            "christian jesus know believ peopl bibl think write say come\n",
            "\n",
            "Topic #12:\n",
            "church pope cathol south time rockefel father organ nuclear secret\n",
            "\n",
            "Topic #13:\n",
            "jpeg imag line keyboard subject dseg appear post organ color\n",
            "\n",
            "Topic #14:\n",
            "encrypt chip clipper secur file entri key govern line escrow\n",
            "\n",
            "Topic #15:\n",
            "window subject line file organ problem motif font server applic\n",
            "\n",
            "Topic #16:\n",
            "israel isra say peopl arab go know jew come kill\n",
            "\n",
            "Topic #17:\n",
            "harvard widget visual colormap valu risc david instruct write subject\n",
            "\n",
            "Topic #18:\n",
            "exist peopl question think reason believ write argument evid articl\n",
            "\n",
            "Topic #19:\n",
            "space nasa center univers research scienc program year nation inform\n",
            "\n",
            "Topic #20:\n",
            "scsi line organ subject write post articl oracl host nntp\n",
            "\n",
            "Topic #21:\n",
            "write articl subject organ line pitt know bank like gordon\n",
            "\n",
            "Topic #22:\n",
            "game play season flyer hockey team line year puck goal\n",
            "\n",
            "Topic #23:\n",
            "write subject organ line articl informatik slave absolut ingr hamburg\n",
            "\n",
            "Topic #24:\n",
            "sandvik write christian kent appl line organ subject articl newton\n",
            "\n",
            "Topic #25:\n",
            "file program mail imag data avail softwar includ list user\n",
            "\n",
            "Topic #26:\n",
            "presid state think write know go clinton ohio line articl\n",
            "\n",
            "Topic #27:\n",
            "peopl right state govern think weapon like crime time gun\n",
            "\n",
            "Topic #28:\n",
            "period play ericsson captain power sweden scorer edmonton second hartford\n",
            "\n",
            "Topic #29:\n",
            "articl write organ subject line drug post univers nntp host\n",
            "\n",
            "Topic #30:\n",
            "line subject organ monitor window post color video nntp host\n",
            "\n",
            "Topic #31:\n",
            "team game player play hockey line subject organ think toronto\n",
            "\n",
            "Topic #32:\n",
            "stratus write subject organ articl line post host nntp year\n",
            "\n",
            "Topic #33:\n",
            "orbit earth mission nasa moon probe mar spacecraft baalk kelvin\n",
            "\n",
            "Topic #34:\n",
            "bike motorcycl like organ ride rider line subject helmet post\n",
            "\n",
            "Topic #35:\n",
            "gatech prism subject line organ write georgia post institut technolog\n",
            "\n",
            "Topic #36:\n",
            "water virginia health cancer medic cool public tower nuclear organ\n",
            "\n",
            "Topic #37:\n",
            "armenian turkish turk armenia turkey greek peopl genocid argic serdar\n",
            "\n",
            "Topic #38:\n",
            "write subject like line articl organ post man colorado servic\n",
            "\n",
            "Topic #39:\n",
            "year line write organ subject articl post good buffalo univers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "LrPaQEiuGRt3",
        "outputId": "f5528171-e7e6-429a-8c7d-938204182928"
      },
      "source": [
        "cluster_probabilities = lda.transform(count_data)\n",
        "data_processed['target'] = np.argmax(cluster_probabilities, axis=1)\n",
        "data_processed.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lerxst thing subject nntp post host organ univ...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>guykuo carson washington subject clock poll fi...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twilli purdu thoma willi subject question orga...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jgreen amber green subject weitek organ harri ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>head harvard jonathan mcdowel subject shuttl l...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  target\n",
              "0  lerxst thing subject nntp post host organ univ...       9\n",
              "1  guykuo carson washington subject clock poll fi...      30\n",
              "2  twilli purdu thoma willi subject question orga...       9\n",
              "3  jgreen amber green subject weitek organ harri ...      15\n",
              "4  head harvard jonathan mcdowel subject shuttl l...      10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJNJOHB9GkKP"
      },
      "source": [
        "import seaborn as sns\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "At3W9AMVGnga",
        "outputId": "d972b126-6470-459f-b940-8c038455b23b"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "sns.countplot(x=data_processed.target);\n",
        "ax.set_title(\"Number of articles that correspond to the topic\");\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ07JMrCRAYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3799f8d-e429-452d-b54d-7091b7c8f217"
      },
      "source": [
        "#Loading the data set - training data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "mydata_train = fetch_20newsgroups(subset='train', shuffle=True, remove = ('headers', 'footers', 'quotes'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpyae_wBRHIU",
        "outputId": "f01c731b-0860-4042-af66-47b128bddf0c"
      },
      "source": [
        "list(mydata_train)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'filenames', 'target_names', 'target', 'DESCR']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsmrhUPeRJ9l",
        "outputId": "c3b03533-a69e-40a6-fb81-0945413b85e2"
      },
      "source": [
        "print('Training data size:', len(mydata_train['data']))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size: 11314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv1WrOdSRONT",
        "outputId": "0f36496d-490c-4efb-edb8-5cc3e4f03be2"
      },
      "source": [
        "# Printing all the categories\n",
        "mydata_train.target_names"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krZedPVlRRxL",
        "outputId": "0c3859f5-d8d9-450a-c175-13e0a2047256"
      },
      "source": [
        "\n",
        "# Finding frequency of each category\n",
        "targets, frequency = np.unique(mydata_train.target, return_counts=True)\n",
        "targets, frequency"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "        17, 18, 19]),\n",
              " array([480, 584, 591, 590, 578, 593, 585, 594, 598, 597, 600, 595, 591,\n",
              "        594, 593, 599, 546, 564, 465, 377]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSr8qhRVRWTb",
        "outputId": "02e3da01-fb58-4e97-a45d-e6d9b0aa4631"
      },
      "source": [
        "targets_str = np.array(mydata_train.target_names)\n",
        "print(list(zip(targets_str, frequency)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('alt.atheism', 480), ('comp.graphics', 584), ('comp.os.ms-windows.misc', 591), ('comp.sys.ibm.pc.hardware', 590), ('comp.sys.mac.hardware', 578), ('comp.windows.x', 593), ('misc.forsale', 585), ('rec.autos', 594), ('rec.motorcycles', 598), ('rec.sport.baseball', 597), ('rec.sport.hockey', 600), ('sci.crypt', 595), ('sci.electronics', 591), ('sci.med', 594), ('sci.space', 593), ('soc.religion.christian', 599), ('talk.politics.guns', 546), ('talk.politics.mideast', 564), ('talk.politics.misc', 465), ('talk.religion.misc', 377)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pZ_KnVPRZSm"
      },
      "source": [
        "mydata_test = fetch_20newsgroups(subset='test', shuffle=True, remove = ('headers', 'footers', 'quotes'))\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEcSYoJmRcUc",
        "outputId": "dc443b6e-cbca-4e94-fe24-fe42dce5ec48"
      },
      "source": [
        "print('Testing data size:', len(mydata_test['data']))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing data size: 7532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "_aSKch0QRf_o",
        "outputId": "808fc923-ee26-4470-8eff-dece4c4df858"
      },
      "source": [
        "mydata_train_df = pd.DataFrame({'data': mydata_train.data, 'target': mydata_train.target})\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I was wondering if anyone out there could enli...       7\n",
              "1  A fair number of brave souls who upgraded thei...       4\n",
              "2  well folks, my mac plus finally gave up the gh...       4\n",
              "3  \\nDo you have Weitek's address/phone number?  ...       1\n",
              "4  From article <C5owCB.n3p@world.std.com>, by to...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "ttru-cT7Rj9K",
        "outputId": "06b439c1-d13d-44e9-f406-d93a4d65fb54"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "import re\n",
        "import string\n",
        "\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_train_df['data'] = mydata_train_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks  my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\ndo you have weitek s address phone number   ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>from article      world std com   by tombaker ...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i was wondering if anyone out there could enli...       7\n",
              "1  a fair number of brave souls who upgraded thei...       4\n",
              "2  well folks  my mac plus finally gave up the gh...       4\n",
              "3  \\ndo you have weitek s address phone number   ...       1\n",
              "4  from article      world std com   by tombaker ...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "8f6jlH07RoBH",
        "outputId": "ddab5a25-2b6c-4cb7-c9da-0a784d8abede"
      },
      "source": [
        "mydata_test_df = pd.DataFrame({'data': mydata_test.data, 'target': mydata_test.target})\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIn a word, yes.\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThey were attacking the Iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nI've just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I am a little confused on all of the models of...       7\n",
              "1  I'm not familiar at all with the format of the...       5\n",
              "2                                \\nIn a word, yes.\\n       0\n",
              "3  \\nThey were attacking the Iraqis to drive them...      17\n",
              "4  \\nI've just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "tUjU5KP5RrlP",
        "outputId": "a3c8ff24-df77-400c-ddb2-46de0c0bf6a7"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_test_df['data'] = mydata_test_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i m not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nin a word  yes \\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nthey were attacking the iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\ni ve just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i am a little confused on all of the models of...       7\n",
              "1  i m not familiar at all with the format of the...       5\n",
              "2                                \\nin a word  yes \\n       0\n",
              "3  \\nthey were attacking the iraqis to drive them...      17\n",
              "4  \\ni ve just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUELDX2-bNNg",
        "outputId": "fd21555c-6377-4efd-c61a-56ccd336b22d"
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "X_train_cv = count_vect.fit_transform(mydata_train_df.data) # fit_transform learns the\n",
        "X_test_cv = count_vect.transform(mydata_test_df.data) # transform uses the same vocab an\n",
        "print(X_train_cv.shape)\n",
        "print(type(X_train_cv))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11314, 67822)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRUtZ9-VAkiY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
        "from keras.models import Model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Oz3FjnHAqOw",
        "outputId": "5ec66c36-60ad-41db-9667-a90b6df2592b"
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian'] \n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, \n",
        "                                      categories=categories,)\n",
        "\n",
        "print (newsgroups_train.target_names)\n",
        "print (len(newsgroups_train.data))\n",
        "\n",
        "#print (newsgroups_train.data[1])\n",
        "print(\"\\n\".join(newsgroups_train.data[0].split(\"\\n\")[10:15]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'soc.religion.christian']\n",
            "1079\n",
            "   WASHINGTON, April 19  -- A symposium on the Dead Sea \n",
            "Scrolls will be held at the Library of Congress on Wednesday,\n",
            "April 21, and Thursday, April 22.  The two-day program, cosponsored\n",
            "by the library and Baltimore Hebrew University, with additional\n",
            "support from the Project Judaica Foundation, will be held in the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9VVEyQWAu6m",
        "outputId": "161722e2-2552-4f88-dc4e-69f89aee2d0a"
      },
      "source": [
        "%%time\n",
        "\n",
        "texts = []\n",
        "\n",
        "labels=newsgroups_train.target\n",
        "texts = newsgroups_train.data\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NB_WORDS = 20000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "print (sequences[0][:10])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19, 8762, 3621, 11894, 58, 8762, 3621, 43, 1472, 2]\n",
            "CPU times: user 463 ms, sys: 4.87 ms, total: 468 ms\n",
            "Wall time: 473 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C-jZJV1Ay0E",
        "outputId": "4732c2a9-8229-4a0f-b722-c4789e92f692"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20030 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3leeqbJA1-q",
        "outputId": "efae23b8-d35c-4400-d8b7-b31214f403ff"
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print (data.shape)\n",
        "print (data[0][200:250])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1079, 1000)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0    19  8762  3621 11894    58  8762  3621\n",
            "    43  1472     2  2130     3   189   450  1001  3622  2980  1682   476\n",
            "   627    50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TATKrjgmA6lK",
        "outputId": "d5891ef5-9018-48e3-ceb1-25e87ee2de26"
      },
      "source": [
        "labels = to_categorical(np.array(labels))\n",
        "\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1079, 1000)\n",
            "Shape of label tensor: (1079, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKD1nppNA_cG",
        "outputId": "bfcdbeed-0218-405d-8805-40d0cf6766a8"
      },
      "source": [
        "VALIDATION_SPLIT = 0.1\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices) \n",
        "data = data[indices] \n",
        "labels = labels[indices] \n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples] \n",
        "y_train = labels[:-nb_validation_samples] \n",
        "x_val = data[-nb_validation_samples:] \n",
        "y_val = labels[-nb_validation_samples:] \n",
        "\n",
        "print (x_train.shape)\n",
        "print (y_train.shape)\n",
        "\n",
        "print('Number of positive and negative reviews in traing and validation set ') \n",
        "print (y_train.sum(axis=0))\n",
        "print (y_val.sum(axis=0))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(972, 1000)\n",
            "(972, 2)\n",
            "Number of positive and negative reviews in traing and validation set \n",
            "[436. 536.]\n",
            "[44. 63.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "1jN7GicoBSkh",
        "outputId": "358be31e-3303-4be3-ca80-5c16646d42d6"
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros.\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print (embedding_matrix.shape)\n",
        "\n",
        "print (embedding_matrix[0][:10])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6fb53264530f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# words not found in embedding index will be all-zeros.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StT4yPYaBUgr",
        "outputId": "aca96e12-5eac-4bc2-e594-5def5499f091"
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix], \n",
        "                            input_length=MAX_SEQUENCE_LENGTH, \n",
        "                            trainable=False)\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32') \n",
        "embedded_sequences = embedding_layer(sequence_input) \n",
        "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences) \n",
        "l_pool1 = MaxPooling1D(5)(l_cov1) \n",
        "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1) \n",
        "l_pool2 = MaxPooling1D(5)(l_cov2) \n",
        "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2) \n",
        "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
        "\n",
        "l_flat = Flatten()(l_pool3) \n",
        "l_dense = Dense(128, activation='relu')(l_flat) \n",
        "preds = Dense(2, activation='softmax')(l_dense)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1000)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1000, 100)         2003100   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 996, 128)          64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 199, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 195, 128)          82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 39, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 35, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 2,248,094\n",
            "Trainable params: 244,994\n",
            "Non-trainable params: 2,003,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohWKe6xrBfGj",
        "outputId": "f3d23737-3d48-4e53-d464-0afd8e49ede1"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "                    epochs=500, batch_size=512)   "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 35s 1s/step - loss: 0.9815 - acc: 0.5264 - val_loss: 0.8678 - val_acc: 0.4112\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.7793 - acc: 0.4979 - val_loss: 0.6924 - val_acc: 0.5888\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.7070 - acc: 0.5499 - val_loss: 0.6855 - val_acc: 0.5888\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.6869 - acc: 0.5654 - val_loss: 0.6834 - val_acc: 0.5888\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.6861 - acc: 0.5499 - val_loss: 0.6788 - val_acc: 0.5888\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.6913 - acc: 0.5462 - val_loss: 0.6837 - val_acc: 0.5888\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.6855 - acc: 0.5486 - val_loss: 0.6783 - val_acc: 0.5888\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6876 - acc: 0.5473 - val_loss: 0.6813 - val_acc: 0.5888\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6832 - acc: 0.5558 - val_loss: 0.6811 - val_acc: 0.5888\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6823 - acc: 0.5564 - val_loss: 0.6818 - val_acc: 0.5888\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6818 - acc: 0.5526 - val_loss: 0.6809 - val_acc: 0.5888\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6806 - acc: 0.5525 - val_loss: 0.6805 - val_acc: 0.5888\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.6786 - acc: 0.5539 - val_loss: 0.6817 - val_acc: 0.5794\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.6783 - acc: 0.5586 - val_loss: 0.6779 - val_acc: 0.5888\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.6841 - acc: 0.5654 - val_loss: 0.6767 - val_acc: 0.5888\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6783 - acc: 0.5512 - val_loss: 0.6785 - val_acc: 0.5794\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.6739 - acc: 0.5940 - val_loss: 0.6818 - val_acc: 0.5514\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6754 - acc: 0.5965 - val_loss: 0.6753 - val_acc: 0.5888\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6801 - acc: 0.5070 - val_loss: 0.6802 - val_acc: 0.5607\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.6736 - acc: 0.5845 - val_loss: 0.6742 - val_acc: 0.5888\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.6724 - acc: 0.5794 - val_loss: 0.6907 - val_acc: 0.5701\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6698 - acc: 0.7038 - val_loss: 0.6720 - val_acc: 0.5888\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6681 - acc: 0.5507 - val_loss: 0.6705 - val_acc: 0.5981\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6609 - acc: 0.5879 - val_loss: 0.6803 - val_acc: 0.5888\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6596 - acc: 0.7043 - val_loss: 0.6666 - val_acc: 0.5888\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6545 - acc: 0.6004 - val_loss: 0.6664 - val_acc: 0.5701\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6565 - acc: 0.5942 - val_loss: 0.6668 - val_acc: 0.6355\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6484 - acc: 0.6556 - val_loss: 0.6610 - val_acc: 0.5981\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6420 - acc: 0.6054 - val_loss: 0.6812 - val_acc: 0.5327\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6454 - acc: 0.6689 - val_loss: 0.6508 - val_acc: 0.5981\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6367 - acc: 0.6156 - val_loss: 0.6436 - val_acc: 0.5888\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6135 - acc: 0.6766 - val_loss: 0.6498 - val_acc: 0.7196\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6062 - acc: 0.8076 - val_loss: 0.6361 - val_acc: 0.6262\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6013 - acc: 0.6930 - val_loss: 0.6426 - val_acc: 0.6729\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.5963 - acc: 0.7178 - val_loss: 0.6025 - val_acc: 0.7009\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.5693 - acc: 0.7483 - val_loss: 0.6018 - val_acc: 0.6449\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.5547 - acc: 0.6967 - val_loss: 0.6852 - val_acc: 0.4486\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6071 - acc: 0.5391 - val_loss: 0.5808 - val_acc: 0.6636\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.5418 - acc: 0.7201 - val_loss: 0.5617 - val_acc: 0.7944\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.5234 - acc: 0.8182 - val_loss: 0.5460 - val_acc: 0.7944\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.4949 - acc: 0.8409 - val_loss: 0.5322 - val_acc: 0.7850\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.4881 - acc: 0.7708 - val_loss: 0.5472 - val_acc: 0.7757\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.4752 - acc: 0.8683 - val_loss: 0.5287 - val_acc: 0.7103\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.4563 - acc: 0.7713 - val_loss: 0.5360 - val_acc: 0.7570\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.4394 - acc: 0.8542 - val_loss: 0.5042 - val_acc: 0.7290\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.4306 - acc: 0.8142 - val_loss: 0.4660 - val_acc: 0.8037\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.3766 - acc: 0.8953 - val_loss: 0.4400 - val_acc: 0.8318\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.3896 - acc: 0.8632 - val_loss: 0.5377 - val_acc: 0.7196\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.4142 - acc: 0.7944 - val_loss: 0.6316 - val_acc: 0.5794\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.4580 - acc: 0.6979 - val_loss: 0.5104 - val_acc: 0.7383\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.3926 - acc: 0.8229 - val_loss: 0.4990 - val_acc: 0.7196\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.3695 - acc: 0.8665 - val_loss: 0.4482 - val_acc: 0.7850\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.3315 - acc: 0.8642 - val_loss: 0.4615 - val_acc: 0.7757\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.3279 - acc: 0.8938 - val_loss: 0.4221 - val_acc: 0.8131\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.3104 - acc: 0.8634 - val_loss: 0.4122 - val_acc: 0.7944\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.2954 - acc: 0.9287 - val_loss: 0.3836 - val_acc: 0.8598\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.2853 - acc: 0.8731 - val_loss: 0.3559 - val_acc: 0.8692\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.2617 - acc: 0.9392 - val_loss: 0.3307 - val_acc: 0.8692\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.2400 - acc: 0.9007 - val_loss: 0.3182 - val_acc: 0.8879\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.2162 - acc: 0.9380 - val_loss: 0.3174 - val_acc: 0.8785\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.2176 - acc: 0.9302 - val_loss: 0.3031 - val_acc: 0.8879\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.2012 - acc: 0.9348 - val_loss: 0.2898 - val_acc: 0.8785\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.1875 - acc: 0.9326 - val_loss: 0.2834 - val_acc: 0.8879\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.1689 - acc: 0.9441 - val_loss: 0.2725 - val_acc: 0.8879\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.1583 - acc: 0.9460 - val_loss: 0.2641 - val_acc: 0.8972\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.1483 - acc: 0.9475 - val_loss: 0.2738 - val_acc: 0.8879\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.1511 - acc: 0.9600 - val_loss: 0.2508 - val_acc: 0.8972\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.1438 - acc: 0.9510 - val_loss: 0.2977 - val_acc: 0.8785\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.1491 - acc: 0.9301 - val_loss: 0.3290 - val_acc: 0.8131\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.1816 - acc: 0.9371 - val_loss: 0.2529 - val_acc: 0.9065\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.1349 - acc: 0.9509 - val_loss: 0.2255 - val_acc: 0.9065\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1221 - acc: 0.9499 - val_loss: 0.2240 - val_acc: 0.8972\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.1077 - acc: 0.9831 - val_loss: 0.2216 - val_acc: 0.9065\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1053 - acc: 0.9596 - val_loss: 0.2129 - val_acc: 0.8972\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0933 - acc: 0.9852 - val_loss: 0.2171 - val_acc: 0.9159\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0887 - acc: 0.9711 - val_loss: 0.2082 - val_acc: 0.8972\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0838 - acc: 0.9845 - val_loss: 0.2274 - val_acc: 0.9159\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0896 - acc: 0.9686 - val_loss: 0.2004 - val_acc: 0.9065\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0798 - acc: 0.9809 - val_loss: 0.1884 - val_acc: 0.9252\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0657 - acc: 0.9879 - val_loss: 0.1821 - val_acc: 0.9065\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0645 - acc: 0.9850 - val_loss: 0.1784 - val_acc: 0.9159\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0574 - acc: 0.9932 - val_loss: 0.1825 - val_acc: 0.9252\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0560 - acc: 0.9865 - val_loss: 0.1711 - val_acc: 0.9065\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.0483 - acc: 0.9959 - val_loss: 0.1670 - val_acc: 0.9065\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0453 - acc: 0.9925 - val_loss: 0.1685 - val_acc: 0.9252\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0474 - acc: 0.9966 - val_loss: 0.1961 - val_acc: 0.9252\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0462 - acc: 0.9880 - val_loss: 0.1742 - val_acc: 0.9252\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0472 - acc: 0.9945 - val_loss: 0.1832 - val_acc: 0.9252\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0367 - acc: 0.9913 - val_loss: 0.1572 - val_acc: 0.9159\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0406 - acc: 0.9918 - val_loss: 0.1547 - val_acc: 0.9252\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0343 - acc: 0.9973 - val_loss: 0.1988 - val_acc: 0.9252\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0383 - acc: 0.9886 - val_loss: 0.1725 - val_acc: 0.9252\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0376 - acc: 0.9980 - val_loss: 0.2048 - val_acc: 0.9252\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0340 - acc: 0.9926 - val_loss: 0.1598 - val_acc: 0.9252\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0299 - acc: 0.9980 - val_loss: 0.2198 - val_acc: 0.9252\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0364 - acc: 0.9880 - val_loss: 0.1562 - val_acc: 0.9159\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0281 - acc: 0.9987 - val_loss: 0.1976 - val_acc: 0.9252\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 0.0233 - acc: 0.9953 - val_loss: 0.1716 - val_acc: 0.9252\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0282 - acc: 0.9973 - val_loss: 0.2309 - val_acc: 0.9252\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0283 - acc: 0.9900 - val_loss: 0.1724 - val_acc: 0.9252\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.2290 - val_acc: 0.9252\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0230 - acc: 0.9960 - val_loss: 0.1804 - val_acc: 0.9252\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.2221 - val_acc: 0.9252\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0224 - acc: 0.9960 - val_loss: 0.1465 - val_acc: 0.9159\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1654 - val_acc: 0.9346\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0159 - acc: 0.9980 - val_loss: 0.1557 - val_acc: 0.9439\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0138 - acc: 0.9987 - val_loss: 0.1355 - val_acc: 0.9252\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9346\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0116 - acc: 0.9993 - val_loss: 0.1367 - val_acc: 0.9159\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.1483 - val_acc: 0.9439\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0102 - acc: 0.9987 - val_loss: 0.1679 - val_acc: 0.9439\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0096 - acc: 0.9987 - val_loss: 0.1358 - val_acc: 0.9252\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.1500 - val_acc: 0.9439\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.1590 - val_acc: 0.9439\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9159\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.1557 - val_acc: 0.9439\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.1523 - val_acc: 0.9439\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1371 - val_acc: 0.9159\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1596 - val_acc: 0.9439\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1491 - val_acc: 0.9439\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1403 - val_acc: 0.9252\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1636 - val_acc: 0.9439\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1423 - val_acc: 0.9346\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.1503 - val_acc: 0.9439\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.1616 - val_acc: 0.9439\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.1433 - val_acc: 0.9346\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1468 - val_acc: 0.9439\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1616 - val_acc: 0.9439\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1470 - val_acc: 0.9439\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1393 - val_acc: 0.9252\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1648 - val_acc: 0.9439\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1512 - val_acc: 0.9439\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1445 - val_acc: 0.9439\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1551 - val_acc: 0.9439\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1526 - val_acc: 0.9439\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1463 - val_acc: 0.9439\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1551 - val_acc: 0.9439\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1534 - val_acc: 0.9439\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1490 - val_acc: 0.9439\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1534 - val_acc: 0.9439\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1542 - val_acc: 0.9439\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1493 - val_acc: 0.9439\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1535 - val_acc: 0.9439\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1569 - val_acc: 0.9439\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9439\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1480 - val_acc: 0.9439\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.9439\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9439\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1486 - val_acc: 0.9439\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1589 - val_acc: 0.9439\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1541 - val_acc: 0.9439\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1498 - val_acc: 0.9439\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1584 - val_acc: 0.9439\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1538 - val_acc: 0.9439\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1482 - val_acc: 0.9439\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1527 - val_acc: 0.9439\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1625 - val_acc: 0.9439\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1506 - val_acc: 0.9439\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1450 - val_acc: 0.9439\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1598 - val_acc: 0.9439\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1613 - val_acc: 0.9439\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1515 - val_acc: 0.9439\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1490 - val_acc: 0.9439\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1625 - val_acc: 0.9439\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1570 - val_acc: 0.9439\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1485 - val_acc: 0.9439\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1551 - val_acc: 0.9439\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1637 - val_acc: 0.9439\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1523 - val_acc: 0.9439\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1480 - val_acc: 0.9439\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1574 - val_acc: 0.9439\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1664 - val_acc: 0.9439\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1537 - val_acc: 0.9439\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1463 - val_acc: 0.9439\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1620 - val_acc: 0.9439\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1651 - val_acc: 0.9439\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1483 - val_acc: 0.9439\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1510 - val_acc: 0.9439\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1638 - val_acc: 0.9439\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1615 - val_acc: 0.9439\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1492 - val_acc: 0.9439\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1559 - val_acc: 0.9439\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 0.9439\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1530 - val_acc: 0.9439\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 9.8551e-04 - acc: 1.0000 - val_loss: 0.1513 - val_acc: 0.9439\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 9.2786e-04 - acc: 1.0000 - val_loss: 0.1622 - val_acc: 0.9439\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 9.5680e-04 - acc: 1.0000 - val_loss: 0.1586 - val_acc: 0.9439\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 9.0758e-04 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 0.9439\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 9.5032e-04 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9439\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.7162e-04 - acc: 1.0000 - val_loss: 0.1616 - val_acc: 0.9439\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 8.8857e-04 - acc: 1.0000 - val_loss: 0.1661 - val_acc: 0.9439\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 7.9001e-04 - acc: 1.0000 - val_loss: 0.1563 - val_acc: 0.9439\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.1610e-04 - acc: 1.0000 - val_loss: 0.1491 - val_acc: 0.9439\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 8.3538e-04 - acc: 1.0000 - val_loss: 0.1618 - val_acc: 0.9439\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 7.9634e-04 - acc: 1.0000 - val_loss: 0.1659 - val_acc: 0.9439\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 7.6552e-04 - acc: 1.0000 - val_loss: 0.1560 - val_acc: 0.9439\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 7.9881e-04 - acc: 1.0000 - val_loss: 0.1522 - val_acc: 0.9439\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 7.9232e-04 - acc: 1.0000 - val_loss: 0.1589 - val_acc: 0.9439\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 7.4563e-04 - acc: 1.0000 - val_loss: 0.1650 - val_acc: 0.9439\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.5025e-04 - acc: 1.0000 - val_loss: 0.1555 - val_acc: 0.9439\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 7.2465e-04 - acc: 1.0000 - val_loss: 0.1550 - val_acc: 0.9439\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.2735e-04 - acc: 1.0000 - val_loss: 0.1626 - val_acc: 0.9439\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 6.8548e-04 - acc: 1.0000 - val_loss: 0.1607 - val_acc: 0.9439\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 7.1533e-04 - acc: 1.0000 - val_loss: 0.1532 - val_acc: 0.9439\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 6.6673e-04 - acc: 1.0000 - val_loss: 0.1577 - val_acc: 0.9439\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 6.6286e-04 - acc: 1.0000 - val_loss: 0.1644 - val_acc: 0.9439\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 6.8155e-04 - acc: 1.0000 - val_loss: 0.1607 - val_acc: 0.9439\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.5033e-04 - acc: 1.0000 - val_loss: 0.1542 - val_acc: 0.9439\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.7872e-04 - acc: 1.0000 - val_loss: 0.1587 - val_acc: 0.9439\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 6.4128e-04 - acc: 1.0000 - val_loss: 0.1618 - val_acc: 0.9439\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.3311e-04 - acc: 1.0000 - val_loss: 0.1592 - val_acc: 0.9439\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 6.1154e-04 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 0.9439\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 6.2039e-04 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.9439\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 6.0038e-04 - acc: 1.0000 - val_loss: 0.1625 - val_acc: 0.9439\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 6.3576e-04 - acc: 1.0000 - val_loss: 0.1557 - val_acc: 0.9439\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 5.6866e-04 - acc: 1.0000 - val_loss: 0.1574 - val_acc: 0.9439\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 5.9480e-04 - acc: 1.0000 - val_loss: 0.1644 - val_acc: 0.9439\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 5.8580e-04 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.9439\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 5.5894e-04 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.9439\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 5.6623e-04 - acc: 1.0000 - val_loss: 0.1550 - val_acc: 0.9439\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 5.6773e-04 - acc: 1.0000 - val_loss: 0.1621 - val_acc: 0.9439\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 5.5714e-04 - acc: 1.0000 - val_loss: 0.1652 - val_acc: 0.9439\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 5.6228e-04 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 0.9439\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 5.4010e-04 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 0.9439\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 5.5129e-04 - acc: 1.0000 - val_loss: 0.1598 - val_acc: 0.9439\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.2676e-04 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9439\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.3025e-04 - acc: 1.0000 - val_loss: 0.1594 - val_acc: 0.9439\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.1993e-04 - acc: 1.0000 - val_loss: 0.1583 - val_acc: 0.9439\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 5.1664e-04 - acc: 1.0000 - val_loss: 0.1606 - val_acc: 0.9439\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.8906e-04 - acc: 1.0000 - val_loss: 0.1633 - val_acc: 0.9439\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 4.8377e-04 - acc: 1.0000 - val_loss: 0.1607 - val_acc: 0.9439\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 4.8367e-04 - acc: 1.0000 - val_loss: 0.1611 - val_acc: 0.9439\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 4.6129e-04 - acc: 1.0000 - val_loss: 0.1615 - val_acc: 0.9439\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 4.3768e-04 - acc: 1.0000 - val_loss: 0.1584 - val_acc: 0.9439\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 4.6345e-04 - acc: 1.0000 - val_loss: 0.1587 - val_acc: 0.9439\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 4.7257e-04 - acc: 1.0000 - val_loss: 0.1646 - val_acc: 0.9439\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 4.3707e-04 - acc: 1.0000 - val_loss: 0.1642 - val_acc: 0.9439\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.4170e-04 - acc: 1.0000 - val_loss: 0.1546 - val_acc: 0.9533\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 4.3306e-04 - acc: 1.0000 - val_loss: 0.1591 - val_acc: 0.9439\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 4.4188e-04 - acc: 1.0000 - val_loss: 0.1661 - val_acc: 0.9439\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.0775e-04 - acc: 1.0000 - val_loss: 0.1644 - val_acc: 0.9439\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 4.2030e-04 - acc: 1.0000 - val_loss: 0.1590 - val_acc: 0.9439\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 4.0261e-04 - acc: 1.0000 - val_loss: 0.1568 - val_acc: 0.9533\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.1714e-04 - acc: 1.0000 - val_loss: 0.1634 - val_acc: 0.9439\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 4.0246e-04 - acc: 1.0000 - val_loss: 0.1670 - val_acc: 0.9439\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.0230e-04 - acc: 1.0000 - val_loss: 0.1615 - val_acc: 0.9439\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 4.0215e-04 - acc: 1.0000 - val_loss: 0.1555 - val_acc: 0.9533\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 3.9643e-04 - acc: 1.0000 - val_loss: 0.1617 - val_acc: 0.9439\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 3.8949e-04 - acc: 1.0000 - val_loss: 0.1696 - val_acc: 0.9439\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.9052e-04 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 0.9439\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.7042e-04 - acc: 1.0000 - val_loss: 0.1583 - val_acc: 0.9533\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.6063e-04 - acc: 1.0000 - val_loss: 0.1582 - val_acc: 0.9533\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.6296e-04 - acc: 1.0000 - val_loss: 0.1631 - val_acc: 0.9439\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.7206e-04 - acc: 1.0000 - val_loss: 0.1677 - val_acc: 0.9439\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.4962e-04 - acc: 1.0000 - val_loss: 0.1645 - val_acc: 0.9439\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 3.3972e-04 - acc: 1.0000 - val_loss: 0.1599 - val_acc: 0.9439\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 3.3286e-04 - acc: 1.0000 - val_loss: 0.1596 - val_acc: 0.9439\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.4793e-04 - acc: 1.0000 - val_loss: 0.1634 - val_acc: 0.9439\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.3013e-04 - acc: 1.0000 - val_loss: 0.1654 - val_acc: 0.9439\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.3585e-04 - acc: 1.0000 - val_loss: 0.1637 - val_acc: 0.9439\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.2737e-04 - acc: 1.0000 - val_loss: 0.1613 - val_acc: 0.9439\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.2930e-04 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.9439\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.1727e-04 - acc: 1.0000 - val_loss: 0.1626 - val_acc: 0.9439\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.2506e-04 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 0.9439\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.2631e-04 - acc: 1.0000 - val_loss: 0.1632 - val_acc: 0.9439\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 2.9774e-04 - acc: 1.0000 - val_loss: 0.1628 - val_acc: 0.9439\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 3.0568e-04 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9439\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.2013e-04 - acc: 1.0000 - val_loss: 0.1635 - val_acc: 0.9439\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.0809e-04 - acc: 1.0000 - val_loss: 0.1606 - val_acc: 0.9533\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.0270e-04 - acc: 1.0000 - val_loss: 0.1591 - val_acc: 0.9533\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 2.9537e-04 - acc: 1.0000 - val_loss: 0.1669 - val_acc: 0.9439\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.0041e-04 - acc: 1.0000 - val_loss: 0.1696 - val_acc: 0.9439\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.8142e-04 - acc: 1.0000 - val_loss: 0.1629 - val_acc: 0.9439\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.9403e-04 - acc: 1.0000 - val_loss: 0.1596 - val_acc: 0.9533\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.8504e-04 - acc: 1.0000 - val_loss: 0.1629 - val_acc: 0.9439\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.9260e-04 - acc: 1.0000 - val_loss: 0.1651 - val_acc: 0.9439\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.8165e-04 - acc: 1.0000 - val_loss: 0.1646 - val_acc: 0.9439\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.6197e-04 - acc: 1.0000 - val_loss: 0.1650 - val_acc: 0.9439\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.6906e-04 - acc: 1.0000 - val_loss: 0.1637 - val_acc: 0.9439\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.7138e-04 - acc: 1.0000 - val_loss: 0.1613 - val_acc: 0.9533\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.6566e-04 - acc: 1.0000 - val_loss: 0.1640 - val_acc: 0.9439\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.7919e-04 - acc: 1.0000 - val_loss: 0.1645 - val_acc: 0.9439\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 2.6671e-04 - acc: 1.0000 - val_loss: 0.1640 - val_acc: 0.9439\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.5875e-04 - acc: 1.0000 - val_loss: 0.1651 - val_acc: 0.9439\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.4481e-04 - acc: 1.0000 - val_loss: 0.1661 - val_acc: 0.9439\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.5776e-04 - acc: 1.0000 - val_loss: 0.1624 - val_acc: 0.9533\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.5799e-04 - acc: 1.0000 - val_loss: 0.1650 - val_acc: 0.9439\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.5094e-04 - acc: 1.0000 - val_loss: 0.1672 - val_acc: 0.9439\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.5448e-04 - acc: 1.0000 - val_loss: 0.1645 - val_acc: 0.9533\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.5557e-04 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 0.9439\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.4409e-04 - acc: 1.0000 - val_loss: 0.1642 - val_acc: 0.9533\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.5178e-04 - acc: 1.0000 - val_loss: 0.1644 - val_acc: 0.9533\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.3514e-04 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 0.9439\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.4313e-04 - acc: 1.0000 - val_loss: 0.1639 - val_acc: 0.9533\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.3462e-04 - acc: 1.0000 - val_loss: 0.1639 - val_acc: 0.9533\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.2756e-04 - acc: 1.0000 - val_loss: 0.1659 - val_acc: 0.9533\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 2.2664e-04 - acc: 1.0000 - val_loss: 0.1675 - val_acc: 0.9439\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.4708e-04 - acc: 1.0000 - val_loss: 0.1645 - val_acc: 0.9533\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.3086e-04 - acc: 1.0000 - val_loss: 0.1635 - val_acc: 0.9533\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 2.3076e-04 - acc: 1.0000 - val_loss: 0.1658 - val_acc: 0.9533\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.2522e-04 - acc: 1.0000 - val_loss: 0.1677 - val_acc: 0.9439\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.1900e-04 - acc: 1.0000 - val_loss: 0.1660 - val_acc: 0.9533\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.2117e-04 - acc: 1.0000 - val_loss: 0.1644 - val_acc: 0.9533\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 2.1243e-04 - acc: 1.0000 - val_loss: 0.1657 - val_acc: 0.9533\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 2.2479e-04 - acc: 1.0000 - val_loss: 0.1643 - val_acc: 0.9533\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.1264e-04 - acc: 1.0000 - val_loss: 0.1677 - val_acc: 0.9533\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.1255e-04 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 0.9533\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.1577e-04 - acc: 1.0000 - val_loss: 0.1639 - val_acc: 0.9533\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.0691e-04 - acc: 1.0000 - val_loss: 0.1637 - val_acc: 0.9533\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.0736e-04 - acc: 1.0000 - val_loss: 0.1658 - val_acc: 0.9533\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.9850e-04 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9533\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.1169e-04 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 0.9533\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.0392e-04 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9533\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.0921e-04 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 0.9533\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.0101e-04 - acc: 1.0000 - val_loss: 0.1683 - val_acc: 0.9533\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.9727e-04 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9533\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.0371e-04 - acc: 1.0000 - val_loss: 0.1640 - val_acc: 0.9533\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.0363e-04 - acc: 1.0000 - val_loss: 0.1661 - val_acc: 0.9533\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.0358e-04 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 0.9533\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.9388e-04 - acc: 1.0000 - val_loss: 0.1692 - val_acc: 0.9533\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.9518e-04 - acc: 1.0000 - val_loss: 0.1665 - val_acc: 0.9533\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.9542e-04 - acc: 1.0000 - val_loss: 0.1642 - val_acc: 0.9533\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.9456e-04 - acc: 1.0000 - val_loss: 0.1676 - val_acc: 0.9533\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.8758e-04 - acc: 1.0000 - val_loss: 0.1683 - val_acc: 0.9533\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.9211e-04 - acc: 1.0000 - val_loss: 0.1686 - val_acc: 0.9533\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.8079e-04 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9533\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.8307e-04 - acc: 1.0000 - val_loss: 0.1674 - val_acc: 0.9533\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.8200e-04 - acc: 1.0000 - val_loss: 0.1678 - val_acc: 0.9533\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.7573e-04 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 0.9533\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.7544e-04 - acc: 1.0000 - val_loss: 0.1680 - val_acc: 0.9533\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.8238e-04 - acc: 1.0000 - val_loss: 0.1659 - val_acc: 0.9533\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.7288e-04 - acc: 1.0000 - val_loss: 0.1650 - val_acc: 0.9533\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.7439e-04 - acc: 1.0000 - val_loss: 0.1679 - val_acc: 0.9533\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 1.7831e-04 - acc: 1.0000 - val_loss: 0.1706 - val_acc: 0.9533\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.7172e-04 - acc: 1.0000 - val_loss: 0.1679 - val_acc: 0.9533\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.6808e-04 - acc: 1.0000 - val_loss: 0.1637 - val_acc: 0.9533\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.7459e-04 - acc: 1.0000 - val_loss: 0.1651 - val_acc: 0.9533\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.6464e-04 - acc: 1.0000 - val_loss: 0.1680 - val_acc: 0.9533\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.5778e-04 - acc: 1.0000 - val_loss: 0.1703 - val_acc: 0.9533\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.6414e-04 - acc: 1.0000 - val_loss: 0.1691 - val_acc: 0.9533\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 185ms/step - loss: 1.6196e-04 - acc: 1.0000 - val_loss: 0.1664 - val_acc: 0.9533\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.6352e-04 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9533\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.6422e-04 - acc: 1.0000 - val_loss: 0.1665 - val_acc: 0.9533\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.5928e-04 - acc: 1.0000 - val_loss: 0.1704 - val_acc: 0.9533\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.6892e-04 - acc: 1.0000 - val_loss: 0.1704 - val_acc: 0.9533\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.6532e-04 - acc: 1.0000 - val_loss: 0.1671 - val_acc: 0.9533\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.5320e-04 - acc: 1.0000 - val_loss: 0.1670 - val_acc: 0.9533\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.6330e-04 - acc: 1.0000 - val_loss: 0.1673 - val_acc: 0.9533\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.6182e-04 - acc: 1.0000 - val_loss: 0.1693 - val_acc: 0.9533\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.4969e-04 - acc: 1.0000 - val_loss: 0.1701 - val_acc: 0.9533\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.5651e-04 - acc: 1.0000 - val_loss: 0.1683 - val_acc: 0.9533\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.5478e-04 - acc: 1.0000 - val_loss: 0.1679 - val_acc: 0.9533\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.5281e-04 - acc: 1.0000 - val_loss: 0.1669 - val_acc: 0.9533\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.4404e-04 - acc: 1.0000 - val_loss: 0.1690 - val_acc: 0.9533\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.5184e-04 - acc: 1.0000 - val_loss: 0.1679 - val_acc: 0.9533\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.4471e-04 - acc: 1.0000 - val_loss: 0.1689 - val_acc: 0.9533\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.4515e-04 - acc: 1.0000 - val_loss: 0.1701 - val_acc: 0.9533\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.4074e-04 - acc: 1.0000 - val_loss: 0.1687 - val_acc: 0.9533\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.3806e-04 - acc: 1.0000 - val_loss: 0.1684 - val_acc: 0.9533\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.3378e-04 - acc: 1.0000 - val_loss: 0.1662 - val_acc: 0.9533\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.4028e-04 - acc: 1.0000 - val_loss: 0.1678 - val_acc: 0.9533\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.4552e-04 - acc: 1.0000 - val_loss: 0.1693 - val_acc: 0.9533\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.4088e-04 - acc: 1.0000 - val_loss: 0.1682 - val_acc: 0.9533\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.3873e-04 - acc: 1.0000 - val_loss: 0.1691 - val_acc: 0.9533\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.3970e-04 - acc: 1.0000 - val_loss: 0.1687 - val_acc: 0.9533\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.3921e-04 - acc: 1.0000 - val_loss: 0.1671 - val_acc: 0.9533\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.3321e-04 - acc: 1.0000 - val_loss: 0.1694 - val_acc: 0.9533\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.3679e-04 - acc: 1.0000 - val_loss: 0.1706 - val_acc: 0.9533\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.3384e-04 - acc: 1.0000 - val_loss: 0.1690 - val_acc: 0.9533\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.3110e-04 - acc: 1.0000 - val_loss: 0.1688 - val_acc: 0.9533\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.3276e-04 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9533\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.2710e-04 - acc: 1.0000 - val_loss: 0.1699 - val_acc: 0.9533\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.2989e-04 - acc: 1.0000 - val_loss: 0.1730 - val_acc: 0.9533\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.3755e-04 - acc: 1.0000 - val_loss: 0.1695 - val_acc: 0.9533\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.3177e-04 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 0.9533\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.2465e-04 - acc: 1.0000 - val_loss: 0.1682 - val_acc: 0.9533\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.2878e-04 - acc: 1.0000 - val_loss: 0.1702 - val_acc: 0.9533\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.2896e-04 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.9533\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.2721e-04 - acc: 1.0000 - val_loss: 0.1704 - val_acc: 0.9533\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 1.1579e-04 - acc: 1.0000 - val_loss: 0.1685 - val_acc: 0.9533\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.1905e-04 - acc: 1.0000 - val_loss: 0.1686 - val_acc: 0.9533\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2592e-04 - acc: 1.0000 - val_loss: 0.1686 - val_acc: 0.9533\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.1859e-04 - acc: 1.0000 - val_loss: 0.1698 - val_acc: 0.9533\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.2299e-04 - acc: 1.0000 - val_loss: 0.1699 - val_acc: 0.9533\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.1485e-04 - acc: 1.0000 - val_loss: 0.1694 - val_acc: 0.9533\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.1919e-04 - acc: 1.0000 - val_loss: 0.1693 - val_acc: 0.9533\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.1494e-04 - acc: 1.0000 - val_loss: 0.1715 - val_acc: 0.9533\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.1769e-04 - acc: 1.0000 - val_loss: 0.1696 - val_acc: 0.9533\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.1809e-04 - acc: 1.0000 - val_loss: 0.1682 - val_acc: 0.9533\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.1908e-04 - acc: 1.0000 - val_loss: 0.1682 - val_acc: 0.9533\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.1791e-04 - acc: 1.0000 - val_loss: 0.1718 - val_acc: 0.9533\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.1232e-04 - acc: 1.0000 - val_loss: 0.1735 - val_acc: 0.9533\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.1869e-04 - acc: 1.0000 - val_loss: 0.1695 - val_acc: 0.9533\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 184ms/step - loss: 1.1781e-04 - acc: 1.0000 - val_loss: 0.1670 - val_acc: 0.9533\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.1280e-04 - acc: 1.0000 - val_loss: 0.1693 - val_acc: 0.9533\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.1452e-04 - acc: 1.0000 - val_loss: 0.1726 - val_acc: 0.9533\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.0982e-04 - acc: 1.0000 - val_loss: 0.1720 - val_acc: 0.9533\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.1047e-04 - acc: 1.0000 - val_loss: 0.1715 - val_acc: 0.9533\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.0848e-04 - acc: 1.0000 - val_loss: 0.1697 - val_acc: 0.9533\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.0741e-04 - acc: 1.0000 - val_loss: 0.1684 - val_acc: 0.9533\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 9.9442e-05 - acc: 1.0000 - val_loss: 0.1687 - val_acc: 0.9533\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.0415e-04 - acc: 1.0000 - val_loss: 0.1692 - val_acc: 0.9533\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.0983e-04 - acc: 1.0000 - val_loss: 0.1726 - val_acc: 0.9533\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.0753e-04 - acc: 1.0000 - val_loss: 0.1731 - val_acc: 0.9533\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.0103e-04 - acc: 1.0000 - val_loss: 0.1703 - val_acc: 0.9533\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.0108e-04 - acc: 1.0000 - val_loss: 0.1690 - val_acc: 0.9533\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.0210e-04 - acc: 1.0000 - val_loss: 0.1680 - val_acc: 0.9533\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 9.9596e-05 - acc: 1.0000 - val_loss: 0.1697 - val_acc: 0.9533\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 9.9932e-05 - acc: 1.0000 - val_loss: 0.1737 - val_acc: 0.9533\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 9.9815e-05 - acc: 1.0000 - val_loss: 0.1719 - val_acc: 0.9533\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.0046e-04 - acc: 1.0000 - val_loss: 0.1706 - val_acc: 0.9533\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.0142e-04 - acc: 1.0000 - val_loss: 0.1703 - val_acc: 0.9533\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 9.9356e-05 - acc: 1.0000 - val_loss: 0.1704 - val_acc: 0.9533\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 1.0297e-04 - acc: 1.0000 - val_loss: 0.1701 - val_acc: 0.9533\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.0583e-04 - acc: 1.0000 - val_loss: 0.1701 - val_acc: 0.9533\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 9.7484e-05 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 0.9533\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 9.1806e-05 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9533\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.0207e-04 - acc: 1.0000 - val_loss: 0.1704 - val_acc: 0.9533\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 9.7081e-05 - acc: 1.0000 - val_loss: 0.1696 - val_acc: 0.9533\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 9.6141e-05 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 0.9533\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 8.8240e-05 - acc: 1.0000 - val_loss: 0.1722 - val_acc: 0.9533\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 9.2082e-05 - acc: 1.0000 - val_loss: 0.1695 - val_acc: 0.9533\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 9.4792e-05 - acc: 1.0000 - val_loss: 0.1697 - val_acc: 0.9533\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 9.4219e-05 - acc: 1.0000 - val_loss: 0.1719 - val_acc: 0.9533\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 9.1148e-05 - acc: 1.0000 - val_loss: 0.1727 - val_acc: 0.9533\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 9.3257e-05 - acc: 1.0000 - val_loss: 0.1703 - val_acc: 0.9533\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 8.9298e-05 - acc: 1.0000 - val_loss: 0.1701 - val_acc: 0.9533\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 9.1910e-05 - acc: 1.0000 - val_loss: 0.1694 - val_acc: 0.9533\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 8.8239e-05 - acc: 1.0000 - val_loss: 0.1715 - val_acc: 0.9533\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 8.9623e-05 - acc: 1.0000 - val_loss: 0.1741 - val_acc: 0.9533\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.8631e-05 - acc: 1.0000 - val_loss: 0.1707 - val_acc: 0.9533\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 9.1493e-05 - acc: 1.0000 - val_loss: 0.1703 - val_acc: 0.9533\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.6112e-05 - acc: 1.0000 - val_loss: 0.1711 - val_acc: 0.9533\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 9.0927e-05 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 0.9533\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.5479e-05 - acc: 1.0000 - val_loss: 0.1720 - val_acc: 0.9533\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 8.4142e-05 - acc: 1.0000 - val_loss: 0.1711 - val_acc: 0.9533\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 8.1348e-05 - acc: 1.0000 - val_loss: 0.1720 - val_acc: 0.9533\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 8.3843e-05 - acc: 1.0000 - val_loss: 0.1739 - val_acc: 0.9533\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 8.3011e-05 - acc: 1.0000 - val_loss: 0.1740 - val_acc: 0.9533\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 8.3836e-05 - acc: 1.0000 - val_loss: 0.1696 - val_acc: 0.9533\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.6651e-05 - acc: 1.0000 - val_loss: 0.1693 - val_acc: 0.9533\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 7.9872e-05 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 0.9533\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 8.4596e-05 - acc: 1.0000 - val_loss: 0.1739 - val_acc: 0.9533\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 8.2487e-05 - acc: 1.0000 - val_loss: 0.1746 - val_acc: 0.9533\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.8604e-05 - acc: 1.0000 - val_loss: 0.1721 - val_acc: 0.9533\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 8.2944e-05 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.9533\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.3350e-05 - acc: 1.0000 - val_loss: 0.1711 - val_acc: 0.9533\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 8.0409e-05 - acc: 1.0000 - val_loss: 0.1731 - val_acc: 0.9533\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 8.0187e-05 - acc: 1.0000 - val_loss: 0.1732 - val_acc: 0.9533\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.0509e-05 - acc: 1.0000 - val_loss: 0.1722 - val_acc: 0.9533\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 7.8618e-05 - acc: 1.0000 - val_loss: 0.1715 - val_acc: 0.9533\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.7547e-05 - acc: 1.0000 - val_loss: 0.1717 - val_acc: 0.9533\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.9615e-05 - acc: 1.0000 - val_loss: 0.1719 - val_acc: 0.9533\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 7.6529e-05 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 0.9533\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 7.9876e-05 - acc: 1.0000 - val_loss: 0.1744 - val_acc: 0.9533\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 7.7742e-05 - acc: 1.0000 - val_loss: 0.1730 - val_acc: 0.9533\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 7.5896e-05 - acc: 1.0000 - val_loss: 0.1709 - val_acc: 0.9533\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 7.1833e-05 - acc: 1.0000 - val_loss: 0.1709 - val_acc: 0.9533\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.3747e-05 - acc: 1.0000 - val_loss: 0.1731 - val_acc: 0.9533\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 7.3370e-05 - acc: 1.0000 - val_loss: 0.1746 - val_acc: 0.9533\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 7.9227e-05 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9533\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 7.5937e-05 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9533\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 7.3669e-05 - acc: 1.0000 - val_loss: 0.1735 - val_acc: 0.9533\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 7.4008e-05 - acc: 1.0000 - val_loss: 0.1743 - val_acc: 0.9533\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 7.2388e-05 - acc: 1.0000 - val_loss: 0.1738 - val_acc: 0.9533\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 7.2624e-05 - acc: 1.0000 - val_loss: 0.1715 - val_acc: 0.9533\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 6.9788e-05 - acc: 1.0000 - val_loss: 0.1718 - val_acc: 0.9533\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 6.8785e-05 - acc: 1.0000 - val_loss: 0.1731 - val_acc: 0.9533\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 7.1377e-05 - acc: 1.0000 - val_loss: 0.1732 - val_acc: 0.9533\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.3829e-05 - acc: 1.0000 - val_loss: 0.1726 - val_acc: 0.9533\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 6.9446e-05 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9533\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 7.1026e-05 - acc: 1.0000 - val_loss: 0.1735 - val_acc: 0.9533\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 7.2174e-05 - acc: 1.0000 - val_loss: 0.1720 - val_acc: 0.9533\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 6.7141e-05 - acc: 1.0000 - val_loss: 0.1729 - val_acc: 0.9533\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 6.7284e-05 - acc: 1.0000 - val_loss: 0.1740 - val_acc: 0.9533\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 7.1526e-05 - acc: 1.0000 - val_loss: 0.1756 - val_acc: 0.9533\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 6.8403e-05 - acc: 1.0000 - val_loss: 0.1735 - val_acc: 0.9533\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.0701e-05 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9533\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 6.8395e-05 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9533\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 6.8723e-05 - acc: 1.0000 - val_loss: 0.1733 - val_acc: 0.9533\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 6.9331e-05 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 0.9533\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 6.8612e-05 - acc: 1.0000 - val_loss: 0.1746 - val_acc: 0.9533\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 6.6529e-05 - acc: 1.0000 - val_loss: 0.1729 - val_acc: 0.9533\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 6.7405e-05 - acc: 1.0000 - val_loss: 0.1735 - val_acc: 0.9533\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.8452e-05 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 0.9533\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 6.2399e-05 - acc: 1.0000 - val_loss: 0.1743 - val_acc: 0.9533\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 6.6612e-05 - acc: 1.0000 - val_loss: 0.1727 - val_acc: 0.9533\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 6.6244e-05 - acc: 1.0000 - val_loss: 0.1735 - val_acc: 0.9533\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.4130e-05 - acc: 1.0000 - val_loss: 0.1732 - val_acc: 0.9533\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.4360e-05 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 0.9533\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 6.5777e-05 - acc: 1.0000 - val_loss: 0.1740 - val_acc: 0.9533\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 5.9695e-05 - acc: 1.0000 - val_loss: 0.1744 - val_acc: 0.9533\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 6.4373e-05 - acc: 1.0000 - val_loss: 0.1751 - val_acc: 0.9533\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 5.9984e-05 - acc: 1.0000 - val_loss: 0.1750 - val_acc: 0.9533\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 6.2953e-05 - acc: 1.0000 - val_loss: 0.1738 - val_acc: 0.9533\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.2225e-05 - acc: 1.0000 - val_loss: 0.1722 - val_acc: 0.9533\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 6.1135e-05 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9533\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 6.3697e-05 - acc: 1.0000 - val_loss: 0.1742 - val_acc: 0.9533\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 6.5436e-05 - acc: 1.0000 - val_loss: 0.1755 - val_acc: 0.9533\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 6.0334e-05 - acc: 1.0000 - val_loss: 0.1772 - val_acc: 0.9533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qzK4SJB5y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "eea3ef27-faea-4c03-a615-179dbad4405e"
      },
      "source": [
        "plt.figure(figsize =(5,3))\n",
        "plt.plot(history.history['acc'], marker='.', label='tune')\n",
        "plt.plot(history.history['val_acc'], marker='.', label='test')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
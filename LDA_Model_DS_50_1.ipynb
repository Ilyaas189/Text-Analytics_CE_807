{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA Model_DS_50_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ilyaas189/Text-Analytics_CE_807/blob/main/LDA_Model_DS_50_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "h48neXM-ANwE",
        "outputId": "ce96cc30-db76-44ab-9d3a-41fd98408402"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from google.colab import files\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import random\n",
        "uploaded = files.upload()\n",
        "files = list(uploaded.keys())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7cd9c13b-8c56-4d56-87ce-20cc3afee552\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7cd9c13b-8c56-4d56-87ce-20cc3afee552\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcrJU_pzAhOm",
        "outputId": "27a40ff1-8afd-4e56-9c1f-b8c4a53f0ab8"
      },
      "source": [
        "# Import Dataset\n",
        "data = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "print(data.target_names.unique())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
            " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
            " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
            " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
            " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
            " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "SnGiNUYGAtLQ",
        "outputId": "f4704d18-cbfb-4bc1-fc99-52f64c231efe"
      },
      "source": [
        "data.head(20)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
              "      <td>16</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
              "      <td>13</td>\n",
              "      <td>sci.med</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
              "      <td>3</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
              "      <td>8</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>From: david@terminus.ericsson.se (David Bold)\\...</td>\n",
              "      <td>19</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>From: dbm0000@tm0006.lerc.nasa.gov (David B. M...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...</td>\n",
              "      <td>6</td>\n",
              "      <td>misc.forsale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...</td>\n",
              "      <td>12</td>\n",
              "      <td>sci.electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>From: abarden@tybse1.uucp (Ann Marie Barden)\\n...</td>\n",
              "      <td>5</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              content  ...              target_names\n",
              "0   From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...                 rec.autos\n",
              "1   From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...     comp.sys.mac.hardware\n",
              "2   From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...     comp.sys.mac.hardware\n",
              "3   From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...             comp.graphics\n",
              "4   From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...                 sci.space\n",
              "5   From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...  ...        talk.politics.guns\n",
              "6   From: bmdelane@quads.uchicago.edu (brian manni...  ...                   sci.med\n",
              "7   From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...  ...  comp.sys.ibm.pc.hardware\n",
              "8   From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...  ...   comp.os.ms-windows.misc\n",
              "9   From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...  ...     comp.sys.mac.hardware\n",
              "10  From: irwin@cmptrc.lonestar.org (Irwin Arnstei...  ...           rec.motorcycles\n",
              "11  From: david@terminus.ericsson.se (David Bold)\\...  ...        talk.religion.misc\n",
              "12  From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...  ...     comp.sys.mac.hardware\n",
              "13  From: dbm0000@tm0006.lerc.nasa.gov (David B. M...  ...                 sci.space\n",
              "14  From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...  ...              misc.forsale\n",
              "15  From: mathew <mathew@mantis.co.uk>\\nSubject: R...  ...               alt.atheism\n",
              "16  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...  ...             comp.graphics\n",
              "17  From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...  ...                 rec.autos\n",
              "18  From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...  ...           sci.electronics\n",
              "19  From: abarden@tybse1.uucp (Ann Marie Barden)\\n...  ...            comp.windows.x\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1t4Hd65BKo4",
        "outputId": "6fd81ecd-00b2-49c0-be80-077d9796a07c"
      },
      "source": [
        "data_clusterization = data[['content', 'target_names']]\n",
        "data_clusterization.dropna(inplace=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "0xRJ8_03Bd1W",
        "outputId": "fd2c2b6e-41bb-493d-abc1-479db6b3be4d"
      },
      "source": [
        "data_clusterization.head(2)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content           target_names\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...              rec.autos\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  comp.sys.mac.hardware"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iUh1DoLBmXP",
        "outputId": "b8d88817-c565-4ff2-8529-47a18015d3cb"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7hwfWd1Bw8S"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        " stemmer = SnowballStemmer(language='english')\n",
        " return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        " result = []\n",
        " for token in gensim.utils.simple_preprocess(text):\n",
        "   if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "     result.append(lemmatize_stemming(token))\n",
        " return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJfVX8biB_Sa"
      },
      "source": [
        "processed_docs = data_clusterization['content'].map(preprocess)\n",
        "data_processed = processed_docs.to_frame()\n",
        "data_processed['content'] = data_processed.content.apply(lambda x: ' '.join(x))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCHPTBYJClMy",
        "outputId": "6a06686b-0770-47a5-acc9-fc0694c33a33"
      },
      "source": [
        "!pip install tokenize_uk\n",
        "from collections import Counter\n",
        "from tokenize_uk.tokenize_uk import tokenize_words"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenize_uk\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/21/72abb0304b532e1b2d2473b50d8063ddd0943e3b3fe7e86b366bc4d02aa2/tokenize_uk-0.2.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tokenize_uk) (1.15.0)\n",
            "Building wheels for collected packages: tokenize-uk\n",
            "  Building wheel for tokenize-uk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tokenize-uk: filename=tokenize_uk-0.2.0-py2.py3-none-any.whl size=4565 sha256=987b627a8cf894e2806e746b5166f1b45e20c86849b9fda7ec29157dc5b58e88\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/e1/95/fd8af5b40aeebdc4e178974e7f638f5553aa8772117054db9e\n",
            "Successfully built tokenize-uk\n",
            "Installing collected packages: tokenize-uk\n",
            "Successfully installed tokenize-uk-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "94mq8WUoCqHq",
        "outputId": "291415c1-b069-4419-ae5c-3af8eba23b88"
      },
      "source": [
        "def display_words(data, title, ax):\n",
        " count = Counter(sum(map(lambda text: tokenize_words(text), data), []))\n",
        " popular = np.array(sorted(count.items(), key=lambda x: x[1], reverse=True)[:20])\n",
        " plt.sca(ax)\n",
        " plt.title(title)\n",
        " plt.bar(popular[:,0], np.int32(popular[:,1]))\n",
        " plt.xticks(rotation=\"vertical\")\n",
        "fig, ax = plt.subplots(figsize=(16, 5))\n",
        "display_words(data_processed.sample(1000).content, \"The most popular words]\", ax)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCM4qevNC5Ty"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMnRgz3aC8f5",
        "outputId": "67697e65-850f-4827-be96-d795b9ebf211"
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "count_data = count_vectorizer.fit_transform(data_processed['content'])\n",
        "count_data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11314x61410 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 934270 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TmSX73jDEJS"
      },
      "source": [
        "likelihood = []\n",
        "n_clusters = []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9uTcUJlDHT0"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hki6oWR0DLwb"
      },
      "source": [
        "def estimate_number_clusters(data, nclusters):\n",
        " for n in nclusters:\n",
        "   likelihood.append(LDA(n_components=n, n_jobs=-1).fit(data).score(data))\n",
        " n_clusters.append(n)\n",
        " print(\"Sccesfully estimated \", n)\n",
        " fig, ax = plt.subplots(figsize=(15, 5))\n",
        " sns.lineplot(x=n_clusters, y=likelihood, ax=ax)\n",
        " ax.set_title('Elbow method for choosing n, likelihood')\n",
        " ax.set_ylabel('Likelihood')\n",
        " ax.set_xlabel('n')\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CBG_y1fJszZ"
      },
      "source": [
        "# estimate_number_clusters(count_data, [10, 15, 20, 50])\n",
        " \n",
        " "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XNMixjQJuYE"
      },
      "source": [
        "def print_topics(model, count_vectorizer, n_top_words):\n",
        "  words = count_vectorizer.get_feature_names()\n",
        "  for topic_idx, topic in enumerate(model.components_):\n",
        "    print(\"\\nTopic #%d:\" % topic_idx)\n",
        "    print(\" \".join([words[i]\n",
        "  for i in topic.argsort()[:-n_top_words - 1:-1]]))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugizp_hhFpzm"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWtTkYX1Ftia",
        "outputId": "16cd824d-c13e-4040-caf4-6210e6506a3e"
      },
      "source": [
        "number_topics = 50\n",
        "number_words = 10\n",
        "# Create and fit the LDA model\n",
        "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
        "lda.fit(count_data)\n",
        "# Print the topics found by the LDA model\n",
        "print(\"Topics found via LDA:\")\n",
        "print_topics(lda, count_vectorizer, number_words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topics found via LDA:\n",
            "\n",
            "Topic #0:\n",
            "card line subject organ thank driver univers window problem video\n",
            "\n",
            "Topic #1:\n",
            "moral write uiuc keith caltech object subject line organ think\n",
            "\n",
            "Topic #2:\n",
            "wire subject line organ post need write like printer articl\n",
            "\n",
            "Topic #3:\n",
            "access digex insur subject post line organ host nntp write\n",
            "\n",
            "Topic #4:\n",
            "encrypt chip clipper secur govern key escrow privaci phone line\n",
            "\n",
            "Topic #5:\n",
            "line organ subject engin write cost like window softwar program\n",
            "\n",
            "Topic #6:\n",
            "year game line organ subject team player basebal good pitch\n",
            "\n",
            "Topic #7:\n",
            "sale line subject organ univers post columbia host nntp sell\n",
            "\n",
            "Topic #8:\n",
            "subject line organ write univers articl indiana post hang jewish\n",
            "\n",
            "Topic #9:\n",
            "line bike organ subject like write articl good drive look\n",
            "\n",
            "Topic #10:\n",
            "line organ subject post write david nntp host articl know\n",
            "\n",
            "Topic #11:\n",
            "armenian armenia write know henrik azerbaijan subject say articl line\n",
            "\n",
            "Topic #12:\n",
            "european father spirit time line subject organ monash american franci\n",
            "\n",
            "Topic #13:\n",
            "jpeg imag berkeley keyboard mark appear post line color subject\n",
            "\n",
            "Topic #14:\n",
            "entri file output program line number section stream build char\n",
            "\n",
            "Topic #15:\n",
            "window subject henri line toronto xterm work organ font articl\n",
            "\n",
            "Topic #16:\n",
            "israel isra say arab peopl jew go know come tell\n",
            "\n",
            "Topic #17:\n",
            "widget applic display resourc window valu visual point colormap string\n",
            "\n",
            "Topic #18:\n",
            "right militia organ line peopl colorado write state subject articl\n",
            "\n",
            "Topic #19:\n",
            "space nasa center univers research inform april satellit nation technolog\n",
            "\n",
            "Topic #20:\n",
            "andrew line organ subject virginia post univers nntp host mellon\n",
            "\n",
            "Topic #21:\n",
            "pitt write articl bank organ subject line gordon scienc know\n",
            "\n",
            "Topic #22:\n",
            "uchicago univers midway line subject purdu organ flyer chicago church\n",
            "\n",
            "Topic #23:\n",
            "write articl cramer optilink subject organ homosexu line slave clayton\n",
            "\n",
            "Topic #24:\n",
            "write islam articl line sandvik organ subject kent appl muslim\n",
            "\n",
            "Topic #25:\n",
            "file window program imag mail avail softwar graphic user includ\n",
            "\n",
            "Topic #26:\n",
            "write line organ articl subject post batf udel koresh right\n",
            "\n",
            "Topic #27:\n",
            "peopl think govern right go time know say presid like\n",
            "\n",
            "Topic #28:\n",
            "period play power sweden ericsson second shot finland scorer goal\n",
            "\n",
            "Topic #29:\n",
            "articl write organ line subject post uoknor rise callison jam\n",
            "\n",
            "Topic #30:\n",
            "window subject line cwru organ cleveland post freenet host nntp\n",
            "\n",
            "Topic #31:\n",
            "team game hockey play player line year season subject organ\n",
            "\n",
            "Topic #32:\n",
            "stratus write organ articl subject line post host nntp irvin\n",
            "\n",
            "Topic #33:\n",
            "orbit space nasa earth moon launch mission lunar rocket probe\n",
            "\n",
            "Topic #34:\n",
            "dresden motorcycl revolv semi organ navi auto mask beck oasi\n",
            "\n",
            "Topic #35:\n",
            "gatech prism organ line subject georgia technolog write institut articl\n",
            "\n",
            "Topic #36:\n",
            "water health cancer arizona medic research center number dept report\n",
            "\n",
            "Topic #37:\n",
            "armenian turkish turk greek turkey argic serdar genocid armenia peopl\n",
            "\n",
            "Topic #38:\n",
            "write articl subject organ line post cornel like thor steve\n",
            "\n",
            "Topic #39:\n",
            "line grind subject organ wire write ingr post circuit articl\n",
            "\n",
            "Topic #40:\n",
            "diseas doctor patient organ subject line medic pain post caus\n",
            "\n",
            "Topic #41:\n",
            "jesus christian christ come peopl say write know bibl church\n",
            "\n",
            "Topic #42:\n",
            "weapon gun firearm crime state file polic control crimin like\n",
            "\n",
            "Topic #43:\n",
            "write line subject organ articl post know stanford appl like\n",
            "\n",
            "Topic #44:\n",
            "drive scsi disk control hard problem power line time work\n",
            "\n",
            "Topic #45:\n",
            "atheist exist religion atheism believ subject post religi belief write\n",
            "\n",
            "Topic #46:\n",
            "ohio state articl write line organ subject magnus post netcom\n",
            "\n",
            "Topic #47:\n",
            "cryptographi crypt cipher attack plaintext organ cryptosystem lopez ciphertext public\n",
            "\n",
            "Topic #48:\n",
            "nrhj bit wwiz byte gizw bhjn hiram bxom pnei nriz\n",
            "\n",
            "Topic #49:\n",
            "christian think question believ know write truth reason claim evid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "LrPaQEiuGRt3",
        "outputId": "d0872c76-ee58-45eb-f52c-a60d43ec8db3"
      },
      "source": [
        "cluster_probabilities = lda.transform(count_data)\n",
        "data_processed['target'] = np.argmax(cluster_probabilities, axis=1)\n",
        "data_processed.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lerxst thing subject nntp post host organ univ...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>guykuo carson washington subject clock poll fi...</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twilli purdu thoma willi subject question orga...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jgreen amber green subject weitek organ harri ...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>head harvard jonathan mcdowel subject shuttl l...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  target\n",
              "0  lerxst thing subject nntp post host organ univ...       9\n",
              "1  guykuo carson washington subject clock poll fi...      44\n",
              "2  twilli purdu thoma willi subject question orga...       9\n",
              "3  jgreen amber green subject weitek organ harri ...      26\n",
              "4  head harvard jonathan mcdowel subject shuttl l...       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJNJOHB9GkKP"
      },
      "source": [
        "import seaborn as sns\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "At3W9AMVGnga",
        "outputId": "0cbede5e-36d9-411c-9b44-c68782955ade"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "sns.countplot(x=data_processed.target);\n",
        "ax.set_title(\"Number of articles that correspond to the topic\");\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ07JMrCRAYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db0cb9d-2246-4956-d328-3e15dab1e9b4"
      },
      "source": [
        "#Loading the data set - training data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "mydata_train = fetch_20newsgroups(subset='train', shuffle=True, remove = ('headers', 'footers', 'quotes'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpyae_wBRHIU",
        "outputId": "8a42c739-7f17-4d39-9dcc-4396a118f22d"
      },
      "source": [
        "list(mydata_train)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'filenames', 'target_names', 'target', 'DESCR']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsmrhUPeRJ9l",
        "outputId": "3df6bc2b-756c-43f4-8df6-ab7f0e816d26"
      },
      "source": [
        "print('Training data size:', len(mydata_train['data']))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size: 11314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv1WrOdSRONT",
        "outputId": "44080083-92e8-4693-e37d-29ea2420a213"
      },
      "source": [
        "# Printing all the categories\n",
        "mydata_train.target_names"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krZedPVlRRxL",
        "outputId": "025b180a-beb8-41cf-c368-4e470c6117e5"
      },
      "source": [
        "\n",
        "# Finding frequency of each category\n",
        "targets, frequency = np.unique(mydata_train.target, return_counts=True)\n",
        "targets, frequency"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "        17, 18, 19]),\n",
              " array([480, 584, 591, 590, 578, 593, 585, 594, 598, 597, 600, 595, 591,\n",
              "        594, 593, 599, 546, 564, 465, 377]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSr8qhRVRWTb",
        "outputId": "c714cac8-62e0-41b4-98d5-03b896ccd51b"
      },
      "source": [
        "targets_str = np.array(mydata_train.target_names)\n",
        "print(list(zip(targets_str, frequency)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('alt.atheism', 480), ('comp.graphics', 584), ('comp.os.ms-windows.misc', 591), ('comp.sys.ibm.pc.hardware', 590), ('comp.sys.mac.hardware', 578), ('comp.windows.x', 593), ('misc.forsale', 585), ('rec.autos', 594), ('rec.motorcycles', 598), ('rec.sport.baseball', 597), ('rec.sport.hockey', 600), ('sci.crypt', 595), ('sci.electronics', 591), ('sci.med', 594), ('sci.space', 593), ('soc.religion.christian', 599), ('talk.politics.guns', 546), ('talk.politics.mideast', 564), ('talk.politics.misc', 465), ('talk.religion.misc', 377)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pZ_KnVPRZSm"
      },
      "source": [
        "mydata_test = fetch_20newsgroups(subset='test', shuffle=True, remove = ('headers', 'footers', 'quotes'))\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEcSYoJmRcUc",
        "outputId": "e287d3b2-3f37-4e46-c86b-a24410003c2e"
      },
      "source": [
        "print('Testing data size:', len(mydata_test['data']))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing data size: 7532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "_aSKch0QRf_o",
        "outputId": "25534e1c-2178-4462-b6ec-ab4c374462e3"
      },
      "source": [
        "mydata_train_df = pd.DataFrame({'data': mydata_train.data, 'target': mydata_train.target})\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I was wondering if anyone out there could enli...       7\n",
              "1  A fair number of brave souls who upgraded thei...       4\n",
              "2  well folks, my mac plus finally gave up the gh...       4\n",
              "3  \\nDo you have Weitek's address/phone number?  ...       1\n",
              "4  From article <C5owCB.n3p@world.std.com>, by to...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "ttru-cT7Rj9K",
        "outputId": "ca6373da-8493-48c0-8b9a-50835ef66f7e"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "import re\n",
        "import string\n",
        "\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_train_df['data'] = mydata_train_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks  my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\ndo you have weitek s address phone number   ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>from article      world std com   by tombaker ...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i was wondering if anyone out there could enli...       7\n",
              "1  a fair number of brave souls who upgraded thei...       4\n",
              "2  well folks  my mac plus finally gave up the gh...       4\n",
              "3  \\ndo you have weitek s address phone number   ...       1\n",
              "4  from article      world std com   by tombaker ...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "8f6jlH07RoBH",
        "outputId": "f54e0ee1-ba26-4d38-c489-d0173b4c020c"
      },
      "source": [
        "mydata_test_df = pd.DataFrame({'data': mydata_test.data, 'target': mydata_test.target})\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIn a word, yes.\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThey were attacking the Iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nI've just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I am a little confused on all of the models of...       7\n",
              "1  I'm not familiar at all with the format of the...       5\n",
              "2                                \\nIn a word, yes.\\n       0\n",
              "3  \\nThey were attacking the Iraqis to drive them...      17\n",
              "4  \\nI've just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "tUjU5KP5RrlP",
        "outputId": "62cbafc4-d65a-4ae9-9212-c822ae755639"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_test_df['data'] = mydata_test_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i m not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nin a word  yes \\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nthey were attacking the iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\ni ve just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i am a little confused on all of the models of...       7\n",
              "1  i m not familiar at all with the format of the...       5\n",
              "2                                \\nin a word  yes \\n       0\n",
              "3  \\nthey were attacking the iraqis to drive them...      17\n",
              "4  \\ni ve just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUELDX2-bNNg",
        "outputId": "08ecb454-d176-46fe-e637-4695e563c6b2"
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "X_train_cv = count_vect.fit_transform(mydata_train_df.data) # fit_transform learns the\n",
        "X_test_cv = count_vect.transform(mydata_test_df.data) # transform uses the same vocab an\n",
        "print(X_train_cv.shape)\n",
        "print(type(X_train_cv))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11314, 67822)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRUtZ9-VAkiY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
        "from keras.models import Model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Oz3FjnHAqOw",
        "outputId": "f08579e8-090a-4b9a-fe19-6e8483da78a3"
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian'] \n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, \n",
        "                                      categories=categories,)\n",
        "\n",
        "print (newsgroups_train.target_names)\n",
        "print (len(newsgroups_train.data))\n",
        "\n",
        "#print (newsgroups_train.data[1])\n",
        "print(\"\\n\".join(newsgroups_train.data[0].split(\"\\n\")[10:15]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'soc.religion.christian']\n",
            "1079\n",
            "   WASHINGTON, April 19  -- A symposium on the Dead Sea \n",
            "Scrolls will be held at the Library of Congress on Wednesday,\n",
            "April 21, and Thursday, April 22.  The two-day program, cosponsored\n",
            "by the library and Baltimore Hebrew University, with additional\n",
            "support from the Project Judaica Foundation, will be held in the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9VVEyQWAu6m",
        "outputId": "aa281b6c-1672-4230-8654-081807a4c453"
      },
      "source": [
        "%%time\n",
        "\n",
        "texts = []\n",
        "\n",
        "labels=newsgroups_train.target\n",
        "texts = newsgroups_train.data\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NB_WORDS = 20000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "print (sequences[0][:10])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19, 8762, 3621, 11894, 58, 8762, 3621, 43, 1472, 2]\n",
            "CPU times: user 435 ms, sys: 3.82 ms, total: 438 ms\n",
            "Wall time: 444 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C-jZJV1Ay0E",
        "outputId": "be70effa-625d-4e62-8ede-631b52589b5f"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20030 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3leeqbJA1-q",
        "outputId": "86e58abf-c661-4357-f61e-ebfc807a346d"
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print (data.shape)\n",
        "print (data[0][200:250])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1079, 1000)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0    19  8762  3621 11894    58  8762  3621\n",
            "    43  1472     2  2130     3   189   450  1001  3622  2980  1682   476\n",
            "   627    50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TATKrjgmA6lK",
        "outputId": "a4fdea08-1400-42d5-9dcc-d0e6541282df"
      },
      "source": [
        "labels = to_categorical(np.array(labels))\n",
        "\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1079, 1000)\n",
            "Shape of label tensor: (1079, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKD1nppNA_cG",
        "outputId": "72c86f34-b4d0-4ca7-e484-dd02fd387279"
      },
      "source": [
        "VALIDATION_SPLIT = 0.1\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices) \n",
        "data = data[indices] \n",
        "labels = labels[indices] \n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples] \n",
        "y_train = labels[:-nb_validation_samples] \n",
        "x_val = data[-nb_validation_samples:] \n",
        "y_val = labels[-nb_validation_samples:] \n",
        "\n",
        "print (x_train.shape)\n",
        "print (y_train.shape)\n",
        "\n",
        "print('Number of positive and negative reviews in traing and validation set ') \n",
        "print (y_train.sum(axis=0))\n",
        "print (y_val.sum(axis=0))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(972, 1000)\n",
            "(972, 2)\n",
            "Number of positive and negative reviews in traing and validation set \n",
            "[439. 533.]\n",
            "[41. 66.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "1jN7GicoBSkh",
        "outputId": "3928739a-688b-4d30-a6c8-0961dd983faf"
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros.\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print (embedding_matrix.shape)\n",
        "\n",
        "print (embedding_matrix[0][:10])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6fb53264530f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# words not found in embedding index will be all-zeros.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StT4yPYaBUgr",
        "outputId": "07899651-fc96-4af4-f531-a4b8f5c88818"
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix], \n",
        "                            input_length=MAX_SEQUENCE_LENGTH, \n",
        "                            trainable=False)\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32') \n",
        "embedded_sequences = embedding_layer(sequence_input) \n",
        "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences) \n",
        "l_pool1 = MaxPooling1D(5)(l_cov1) \n",
        "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1) \n",
        "l_pool2 = MaxPooling1D(5)(l_cov2) \n",
        "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2) \n",
        "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
        "\n",
        "l_flat = Flatten()(l_pool3) \n",
        "l_dense = Dense(128, activation='relu')(l_flat) \n",
        "preds = Dense(2, activation='softmax')(l_dense)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1000)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1000, 100)         2003100   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 996, 128)          64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 199, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 195, 128)          82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 39, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 35, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 2,248,094\n",
            "Trainable params: 244,994\n",
            "Non-trainable params: 2,003,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohWKe6xrBfGj",
        "outputId": "90c501d6-37d9-4e43-d6be-816d6629d8f6"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "                    epochs=500, batch_size=512)   "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 35s 1s/step - loss: 0.8411 - acc: 0.4580 - val_loss: 0.6679 - val_acc: 0.6168\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.7293 - acc: 0.4880 - val_loss: 0.7175 - val_acc: 0.3832\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.7005 - acc: 0.4736 - val_loss: 0.6705 - val_acc: 0.6168\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.6898 - acc: 0.5453 - val_loss: 0.6697 - val_acc: 0.6168\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.6863 - acc: 0.5524 - val_loss: 0.6805 - val_acc: 0.6168\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6876 - acc: 0.5511 - val_loss: 0.6748 - val_acc: 0.6168\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6864 - acc: 0.5492 - val_loss: 0.6730 - val_acc: 0.6168\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6864 - acc: 0.5459 - val_loss: 0.6766 - val_acc: 0.6168\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6853 - acc: 0.5446 - val_loss: 0.6697 - val_acc: 0.6168\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6853 - acc: 0.5466 - val_loss: 0.6777 - val_acc: 0.6168\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6834 - acc: 0.5550 - val_loss: 0.6769 - val_acc: 0.6168\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.6825 - acc: 0.5505 - val_loss: 0.6746 - val_acc: 0.6168\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6815 - acc: 0.5498 - val_loss: 0.6729 - val_acc: 0.6168\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 0.6806 - acc: 0.5554 - val_loss: 0.6722 - val_acc: 0.6262\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6787 - acc: 0.5527 - val_loss: 0.6688 - val_acc: 0.6168\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6756 - acc: 0.5628 - val_loss: 0.6822 - val_acc: 0.5888\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 157ms/step - loss: 0.6770 - acc: 0.5919 - val_loss: 0.6710 - val_acc: 0.6075\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 157ms/step - loss: 0.6715 - acc: 0.6078 - val_loss: 0.6641 - val_acc: 0.6262\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.6720 - acc: 0.5650 - val_loss: 0.7016 - val_acc: 0.4019\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.6816 - acc: 0.5112 - val_loss: 0.6607 - val_acc: 0.6168\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 0.6691 - acc: 0.5577 - val_loss: 0.6741 - val_acc: 0.6075\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6629 - acc: 0.6515 - val_loss: 0.6758 - val_acc: 0.5794\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6614 - acc: 0.6552 - val_loss: 0.6601 - val_acc: 0.6355\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6581 - acc: 0.6304 - val_loss: 0.6667 - val_acc: 0.5888\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6537 - acc: 0.6212 - val_loss: 0.6578 - val_acc: 0.6262\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6483 - acc: 0.6533 - val_loss: 0.6576 - val_acc: 0.6542\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.6449 - acc: 0.6716 - val_loss: 0.6426 - val_acc: 0.6262\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.6436 - acc: 0.6194 - val_loss: 0.6743 - val_acc: 0.6075\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6443 - acc: 0.7432 - val_loss: 0.6525 - val_acc: 0.6822\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6311 - acc: 0.6930 - val_loss: 0.6318 - val_acc: 0.6262\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6338 - acc: 0.5928 - val_loss: 0.6938 - val_acc: 0.4019\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6306 - acc: 0.5662 - val_loss: 0.6156 - val_acc: 0.6636\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6098 - acc: 0.6913 - val_loss: 0.6581 - val_acc: 0.5607\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6289 - acc: 0.6921 - val_loss: 0.6212 - val_acc: 0.7570\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.5890 - acc: 0.7986 - val_loss: 0.5928 - val_acc: 0.7757\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.5791 - acc: 0.7032 - val_loss: 0.6191 - val_acc: 0.7290\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.5669 - acc: 0.8693 - val_loss: 0.5652 - val_acc: 0.7944\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.5508 - acc: 0.7616 - val_loss: 0.6121 - val_acc: 0.6542\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.5414 - acc: 0.8072 - val_loss: 0.5395 - val_acc: 0.8505\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.5155 - acc: 0.8457 - val_loss: 0.5369 - val_acc: 0.7009\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.5750 - acc: 0.6204 - val_loss: 0.4947 - val_acc: 0.8131\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.4921 - acc: 0.7619 - val_loss: 0.6280 - val_acc: 0.4579\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.5186 - acc: 0.6983 - val_loss: 0.4637 - val_acc: 0.8224\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.4607 - acc: 0.8307 - val_loss: 0.4541 - val_acc: 0.9159\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.4230 - acc: 0.8791 - val_loss: 0.4664 - val_acc: 0.8598\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.4049 - acc: 0.9211 - val_loss: 0.4004 - val_acc: 0.9159\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.3862 - acc: 0.8910 - val_loss: 0.4163 - val_acc: 0.7944\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.4257 - acc: 0.7787 - val_loss: 0.3578 - val_acc: 0.9159\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.3490 - acc: 0.8892 - val_loss: 0.3849 - val_acc: 0.8879\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.3276 - acc: 0.9222 - val_loss: 0.4217 - val_acc: 0.8318\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.3464 - acc: 0.8962 - val_loss: 0.4871 - val_acc: 0.7290\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.3428 - acc: 0.8667 - val_loss: 0.2912 - val_acc: 0.9346\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.2817 - acc: 0.9166 - val_loss: 0.2844 - val_acc: 0.9159\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.2728 - acc: 0.8976 - val_loss: 0.5907 - val_acc: 0.5794\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.4713 - acc: 0.7392 - val_loss: 0.2984 - val_acc: 0.8692\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.4160 - acc: 0.7504 - val_loss: 0.2668 - val_acc: 0.9346\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.2957 - acc: 0.8942 - val_loss: 0.2840 - val_acc: 0.8785\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.3027 - acc: 0.8906 - val_loss: 0.4799 - val_acc: 0.7477\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.3122 - acc: 0.8947 - val_loss: 0.2900 - val_acc: 0.8785\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.3148 - acc: 0.8660 - val_loss: 0.2786 - val_acc: 0.9533\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.2708 - acc: 0.9282 - val_loss: 0.2891 - val_acc: 0.9439\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.2397 - acc: 0.9369 - val_loss: 0.2508 - val_acc: 0.9252\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.2553 - acc: 0.8993 - val_loss: 0.3699 - val_acc: 0.7944\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.2399 - acc: 0.9328 - val_loss: 0.2229 - val_acc: 0.9346\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.2154 - acc: 0.9218 - val_loss: 0.2209 - val_acc: 0.9439\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.1849 - acc: 0.9549 - val_loss: 0.3033 - val_acc: 0.9252\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.1922 - acc: 0.9548 - val_loss: 0.2079 - val_acc: 0.9346\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.1790 - acc: 0.9386 - val_loss: 0.2653 - val_acc: 0.9439\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.1726 - acc: 0.9642 - val_loss: 0.1952 - val_acc: 0.9439\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.1643 - acc: 0.9433 - val_loss: 0.1975 - val_acc: 0.9626\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1539 - acc: 0.9576 - val_loss: 0.2012 - val_acc: 0.9626\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.1450 - acc: 0.9562 - val_loss: 0.1769 - val_acc: 0.9439\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.1439 - acc: 0.9577 - val_loss: 0.2266 - val_acc: 0.9439\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.1277 - acc: 0.9676 - val_loss: 0.1687 - val_acc: 0.9533\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.1397 - acc: 0.9537 - val_loss: 0.1814 - val_acc: 0.9626\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1102 - acc: 0.9669 - val_loss: 0.1778 - val_acc: 0.9626\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.1000 - acc: 0.9716 - val_loss: 0.1780 - val_acc: 0.9533\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1004 - acc: 0.9677 - val_loss: 0.1597 - val_acc: 0.9626\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0866 - acc: 0.9709 - val_loss: 0.2430 - val_acc: 0.9439\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1116 - acc: 0.9750 - val_loss: 0.1508 - val_acc: 0.9626\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0897 - acc: 0.9725 - val_loss: 0.1507 - val_acc: 0.9626\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0813 - acc: 0.9690 - val_loss: 0.1642 - val_acc: 0.9533\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0732 - acc: 0.9798 - val_loss: 0.1481 - val_acc: 0.9626\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0702 - acc: 0.9738 - val_loss: 0.1536 - val_acc: 0.9626\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0631 - acc: 0.9832 - val_loss: 0.1458 - val_acc: 0.9626\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0574 - acc: 0.9845 - val_loss: 0.1507 - val_acc: 0.9533\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0512 - acc: 0.9871 - val_loss: 0.1881 - val_acc: 0.9533\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0587 - acc: 0.9891 - val_loss: 0.1453 - val_acc: 0.9626\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0540 - acc: 0.9893 - val_loss: 0.1477 - val_acc: 0.9626\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0565 - acc: 0.9771 - val_loss: 0.2286 - val_acc: 0.9439\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0660 - acc: 0.9884 - val_loss: 0.1441 - val_acc: 0.9626\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0751 - acc: 0.9703 - val_loss: 0.1933 - val_acc: 0.9439\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.1094 - acc: 0.9517 - val_loss: 0.3626 - val_acc: 0.8224\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.1164 - acc: 0.9676 - val_loss: 0.1812 - val_acc: 0.9626\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0713 - acc: 0.9712 - val_loss: 0.5139 - val_acc: 0.7196\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.2193 - acc: 0.8949 - val_loss: 0.2859 - val_acc: 0.9065\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.1848 - acc: 0.9285 - val_loss: 1.0595 - val_acc: 0.5047\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.4741 - acc: 0.7468 - val_loss: 0.7554 - val_acc: 0.7757\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.7009 - acc: 0.7613 - val_loss: 0.1568 - val_acc: 0.9626\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.2319 - acc: 0.8811 - val_loss: 0.3195 - val_acc: 0.8318\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1444 - acc: 0.9588 - val_loss: 0.2054 - val_acc: 0.9159\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.2537 - acc: 0.8846 - val_loss: 0.1596 - val_acc: 0.9439\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1366 - acc: 0.9523 - val_loss: 0.3240 - val_acc: 0.8505\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.1829 - acc: 0.9602 - val_loss: 0.2047 - val_acc: 0.9439\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.1079 - acc: 0.9743 - val_loss: 0.1570 - val_acc: 0.9626\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.1189 - acc: 0.9602 - val_loss: 0.1669 - val_acc: 0.9533\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0998 - acc: 0.9690 - val_loss: 0.2292 - val_acc: 0.9439\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.1060 - acc: 0.9758 - val_loss: 0.1718 - val_acc: 0.9533\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0859 - acc: 0.9723 - val_loss: 0.1595 - val_acc: 0.9439\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0771 - acc: 0.9731 - val_loss: 0.1928 - val_acc: 0.9439\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0720 - acc: 0.9879 - val_loss: 0.1697 - val_acc: 0.9533\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0603 - acc: 0.9844 - val_loss: 0.1560 - val_acc: 0.9439\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0604 - acc: 0.9785 - val_loss: 0.1680 - val_acc: 0.9533\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.0540 - acc: 0.9899 - val_loss: 0.1752 - val_acc: 0.9533\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0476 - acc: 0.9926 - val_loss: 0.1536 - val_acc: 0.9533\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0485 - acc: 0.9805 - val_loss: 0.1594 - val_acc: 0.9533\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0378 - acc: 0.9919 - val_loss: 0.1825 - val_acc: 0.9533\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0370 - acc: 0.9973 - val_loss: 0.1689 - val_acc: 0.9533\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0339 - acc: 0.9926 - val_loss: 0.1658 - val_acc: 0.9533\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0293 - acc: 0.9960 - val_loss: 0.1805 - val_acc: 0.9533\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0283 - acc: 0.9986 - val_loss: 0.1707 - val_acc: 0.9533\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0265 - acc: 0.9973 - val_loss: 0.1700 - val_acc: 0.9533\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0247 - acc: 0.9980 - val_loss: 0.1788 - val_acc: 0.9533\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0222 - acc: 0.9980 - val_loss: 0.1718 - val_acc: 0.9533\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0208 - acc: 0.9980 - val_loss: 0.1763 - val_acc: 0.9533\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0183 - acc: 0.9993 - val_loss: 0.1800 - val_acc: 0.9533\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0194 - acc: 0.9987 - val_loss: 0.1773 - val_acc: 0.9533\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0171 - acc: 0.9986 - val_loss: 0.1806 - val_acc: 0.9533\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0174 - acc: 0.9987 - val_loss: 0.1819 - val_acc: 0.9533\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0158 - acc: 0.9986 - val_loss: 0.1746 - val_acc: 0.9533\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0146 - acc: 0.9993 - val_loss: 0.1873 - val_acc: 0.9626\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0150 - acc: 0.9993 - val_loss: 0.1757 - val_acc: 0.9533\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0134 - acc: 0.9980 - val_loss: 0.1843 - val_acc: 0.9533\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.1897 - val_acc: 0.9533\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.1811 - val_acc: 0.9533\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.1964 - val_acc: 0.9626\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.1833 - val_acc: 0.9533\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.1826 - val_acc: 0.9533\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9533\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9533\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1915 - val_acc: 0.9533\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.2013 - val_acc: 0.9533\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.1918 - val_acc: 0.9533\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.1952 - val_acc: 0.9533\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.1996 - val_acc: 0.9533\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.1972 - val_acc: 0.9533\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.2000 - val_acc: 0.9533\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.2066 - val_acc: 0.9533\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1991 - val_acc: 0.9533\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.2009 - val_acc: 0.9533\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.2088 - val_acc: 0.9533\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.2029 - val_acc: 0.9533\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9533\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2114 - val_acc: 0.9533\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2094 - val_acc: 0.9533\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.2109 - val_acc: 0.9533\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2135 - val_acc: 0.9533\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.2136 - val_acc: 0.9533\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.2140 - val_acc: 0.9533\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2156 - val_acc: 0.9533\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2179 - val_acc: 0.9533\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2179 - val_acc: 0.9533\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2194 - val_acc: 0.9533\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2221 - val_acc: 0.9533\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2216 - val_acc: 0.9533\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2226 - val_acc: 0.9533\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2243 - val_acc: 0.9533\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2247 - val_acc: 0.9533\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2258 - val_acc: 0.9533\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2270 - val_acc: 0.9533\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2279 - val_acc: 0.9533\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2291 - val_acc: 0.9533\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2304 - val_acc: 0.9533\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2315 - val_acc: 0.9533\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2324 - val_acc: 0.9533\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2334 - val_acc: 0.9533\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2343 - val_acc: 0.9533\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2353 - val_acc: 0.9533\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2363 - val_acc: 0.9533\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.2373 - val_acc: 0.9533\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.2380 - val_acc: 0.9533\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 9.8537e-04 - acc: 1.0000 - val_loss: 0.2391 - val_acc: 0.9533\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 9.5819e-04 - acc: 1.0000 - val_loss: 0.2401 - val_acc: 0.9533\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 8.6760e-04 - acc: 1.0000 - val_loss: 0.2412 - val_acc: 0.9533\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 9.3113e-04 - acc: 1.0000 - val_loss: 0.2420 - val_acc: 0.9533\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 8.6186e-04 - acc: 1.0000 - val_loss: 0.2428 - val_acc: 0.9533\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 8.3437e-04 - acc: 1.0000 - val_loss: 0.2433 - val_acc: 0.9533\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 8.1435e-04 - acc: 1.0000 - val_loss: 0.2436 - val_acc: 0.9533\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 7.5623e-04 - acc: 1.0000 - val_loss: 0.2443 - val_acc: 0.9533\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 7.0542e-04 - acc: 1.0000 - val_loss: 0.2449 - val_acc: 0.9533\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 7.2155e-04 - acc: 1.0000 - val_loss: 0.2455 - val_acc: 0.9533\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 6.7456e-04 - acc: 1.0000 - val_loss: 0.2463 - val_acc: 0.9533\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 7.0497e-04 - acc: 1.0000 - val_loss: 0.2473 - val_acc: 0.9533\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 6.4077e-04 - acc: 1.0000 - val_loss: 0.2477 - val_acc: 0.9533\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 6.3241e-04 - acc: 1.0000 - val_loss: 0.2484 - val_acc: 0.9533\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 6.0722e-04 - acc: 1.0000 - val_loss: 0.2495 - val_acc: 0.9533\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 5.8388e-04 - acc: 1.0000 - val_loss: 0.2505 - val_acc: 0.9533\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 5.7334e-04 - acc: 1.0000 - val_loss: 0.2509 - val_acc: 0.9533\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 5.6685e-04 - acc: 1.0000 - val_loss: 0.2517 - val_acc: 0.9533\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 5.5207e-04 - acc: 1.0000 - val_loss: 0.2525 - val_acc: 0.9533\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 5.5396e-04 - acc: 1.0000 - val_loss: 0.2531 - val_acc: 0.9533\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 5.0821e-04 - acc: 1.0000 - val_loss: 0.2537 - val_acc: 0.9533\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.1178e-04 - acc: 1.0000 - val_loss: 0.2542 - val_acc: 0.9533\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 4.9309e-04 - acc: 1.0000 - val_loss: 0.2550 - val_acc: 0.9533\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.6631e-04 - acc: 1.0000 - val_loss: 0.2556 - val_acc: 0.9533\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.6540e-04 - acc: 1.0000 - val_loss: 0.2561 - val_acc: 0.9533\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 4.3944e-04 - acc: 1.0000 - val_loss: 0.2567 - val_acc: 0.9533\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.5647e-04 - acc: 1.0000 - val_loss: 0.2574 - val_acc: 0.9533\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 4.5673e-04 - acc: 1.0000 - val_loss: 0.2580 - val_acc: 0.9533\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 4.4935e-04 - acc: 1.0000 - val_loss: 0.2585 - val_acc: 0.9533\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 4.0660e-04 - acc: 1.0000 - val_loss: 0.2591 - val_acc: 0.9533\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 4.0958e-04 - acc: 1.0000 - val_loss: 0.2597 - val_acc: 0.9533\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.8768e-04 - acc: 1.0000 - val_loss: 0.2603 - val_acc: 0.9533\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 3.7904e-04 - acc: 1.0000 - val_loss: 0.2606 - val_acc: 0.9533\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.9247e-04 - acc: 1.0000 - val_loss: 0.2613 - val_acc: 0.9533\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.6241e-04 - acc: 1.0000 - val_loss: 0.2617 - val_acc: 0.9533\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.6252e-04 - acc: 1.0000 - val_loss: 0.2623 - val_acc: 0.9533\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 3.6218e-04 - acc: 1.0000 - val_loss: 0.2629 - val_acc: 0.9533\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.5684e-04 - acc: 1.0000 - val_loss: 0.2635 - val_acc: 0.9533\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.3965e-04 - acc: 1.0000 - val_loss: 0.2636 - val_acc: 0.9533\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.2908e-04 - acc: 1.0000 - val_loss: 0.2642 - val_acc: 0.9533\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.4629e-04 - acc: 1.0000 - val_loss: 0.2652 - val_acc: 0.9533\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.2192e-04 - acc: 1.0000 - val_loss: 0.2657 - val_acc: 0.9533\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.1357e-04 - acc: 1.0000 - val_loss: 0.2657 - val_acc: 0.9533\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 3.0751e-04 - acc: 1.0000 - val_loss: 0.2658 - val_acc: 0.9533\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.0481e-04 - acc: 1.0000 - val_loss: 0.2667 - val_acc: 0.9533\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.0704e-04 - acc: 1.0000 - val_loss: 0.2677 - val_acc: 0.9533\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.9785e-04 - acc: 1.0000 - val_loss: 0.2679 - val_acc: 0.9533\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.9837e-04 - acc: 1.0000 - val_loss: 0.2677 - val_acc: 0.9533\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.9199e-04 - acc: 1.0000 - val_loss: 0.2683 - val_acc: 0.9533\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.8688e-04 - acc: 1.0000 - val_loss: 0.2693 - val_acc: 0.9533\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 2.8980e-04 - acc: 1.0000 - val_loss: 0.2699 - val_acc: 0.9533\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 2.8172e-04 - acc: 1.0000 - val_loss: 0.2701 - val_acc: 0.9533\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.6344e-04 - acc: 1.0000 - val_loss: 0.2705 - val_acc: 0.9533\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.5846e-04 - acc: 1.0000 - val_loss: 0.2708 - val_acc: 0.9533\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.5290e-04 - acc: 1.0000 - val_loss: 0.2713 - val_acc: 0.9533\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 2.5280e-04 - acc: 1.0000 - val_loss: 0.2720 - val_acc: 0.9533\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.4597e-04 - acc: 1.0000 - val_loss: 0.2727 - val_acc: 0.9533\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.4346e-04 - acc: 1.0000 - val_loss: 0.2728 - val_acc: 0.9533\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.3011e-04 - acc: 1.0000 - val_loss: 0.2728 - val_acc: 0.9533\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.5519e-04 - acc: 1.0000 - val_loss: 0.2733 - val_acc: 0.9533\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.3466e-04 - acc: 1.0000 - val_loss: 0.2744 - val_acc: 0.9533\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.2338e-04 - acc: 1.0000 - val_loss: 0.2748 - val_acc: 0.9533\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 2.2423e-04 - acc: 1.0000 - val_loss: 0.2749 - val_acc: 0.9533\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.1610e-04 - acc: 1.0000 - val_loss: 0.2749 - val_acc: 0.9533\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 2.1026e-04 - acc: 1.0000 - val_loss: 0.2755 - val_acc: 0.9533\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.2010e-04 - acc: 1.0000 - val_loss: 0.2763 - val_acc: 0.9533\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.1041e-04 - acc: 1.0000 - val_loss: 0.2770 - val_acc: 0.9533\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.2820e-04 - acc: 1.0000 - val_loss: 0.2770 - val_acc: 0.9533\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.0318e-04 - acc: 1.0000 - val_loss: 0.2775 - val_acc: 0.9533\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.0011e-04 - acc: 1.0000 - val_loss: 0.2777 - val_acc: 0.9533\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.0790e-04 - acc: 1.0000 - val_loss: 0.2782 - val_acc: 0.9533\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.9463e-04 - acc: 1.0000 - val_loss: 0.2789 - val_acc: 0.9533\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.8959e-04 - acc: 1.0000 - val_loss: 0.2794 - val_acc: 0.9533\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.9103e-04 - acc: 1.0000 - val_loss: 0.2794 - val_acc: 0.9533\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.9466e-04 - acc: 1.0000 - val_loss: 0.2795 - val_acc: 0.9533\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.7652e-04 - acc: 1.0000 - val_loss: 0.2802 - val_acc: 0.9533\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.9034e-04 - acc: 1.0000 - val_loss: 0.2813 - val_acc: 0.9533\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.7521e-04 - acc: 1.0000 - val_loss: 0.2816 - val_acc: 0.9533\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.8237e-04 - acc: 1.0000 - val_loss: 0.2809 - val_acc: 0.9533\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.7816e-04 - acc: 1.0000 - val_loss: 0.2812 - val_acc: 0.9533\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.6852e-04 - acc: 1.0000 - val_loss: 0.2821 - val_acc: 0.9533\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.7914e-04 - acc: 1.0000 - val_loss: 0.2831 - val_acc: 0.9533\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.6375e-04 - acc: 1.0000 - val_loss: 0.2836 - val_acc: 0.9533\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.6957e-04 - acc: 1.0000 - val_loss: 0.2832 - val_acc: 0.9533\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.6316e-04 - acc: 1.0000 - val_loss: 0.2832 - val_acc: 0.9533\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.6286e-04 - acc: 1.0000 - val_loss: 0.2838 - val_acc: 0.9533\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.6164e-04 - acc: 1.0000 - val_loss: 0.2847 - val_acc: 0.9533\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 1.5822e-04 - acc: 1.0000 - val_loss: 0.2850 - val_acc: 0.9533\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.5753e-04 - acc: 1.0000 - val_loss: 0.2851 - val_acc: 0.9533\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.4613e-04 - acc: 1.0000 - val_loss: 0.2852 - val_acc: 0.9533\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.5105e-04 - acc: 1.0000 - val_loss: 0.2859 - val_acc: 0.9533\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.5345e-04 - acc: 1.0000 - val_loss: 0.2864 - val_acc: 0.9533\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.4587e-04 - acc: 1.0000 - val_loss: 0.2868 - val_acc: 0.9533\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.4442e-04 - acc: 1.0000 - val_loss: 0.2869 - val_acc: 0.9533\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.3424e-04 - acc: 1.0000 - val_loss: 0.2870 - val_acc: 0.9533\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.3936e-04 - acc: 1.0000 - val_loss: 0.2877 - val_acc: 0.9533\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.4260e-04 - acc: 1.0000 - val_loss: 0.2883 - val_acc: 0.9533\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.3689e-04 - acc: 1.0000 - val_loss: 0.2886 - val_acc: 0.9533\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.4017e-04 - acc: 1.0000 - val_loss: 0.2887 - val_acc: 0.9533\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.4404e-04 - acc: 1.0000 - val_loss: 0.2887 - val_acc: 0.9533\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.4004e-04 - acc: 1.0000 - val_loss: 0.2894 - val_acc: 0.9533\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.3490e-04 - acc: 1.0000 - val_loss: 0.2903 - val_acc: 0.9533\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.3532e-04 - acc: 1.0000 - val_loss: 0.2904 - val_acc: 0.9533\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.3689e-04 - acc: 1.0000 - val_loss: 0.2900 - val_acc: 0.9533\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.2614e-04 - acc: 1.0000 - val_loss: 0.2902 - val_acc: 0.9533\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.3101e-04 - acc: 1.0000 - val_loss: 0.2910 - val_acc: 0.9533\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.2932e-04 - acc: 1.0000 - val_loss: 0.2919 - val_acc: 0.9533\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.2358e-04 - acc: 1.0000 - val_loss: 0.2922 - val_acc: 0.9533\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.2052e-04 - acc: 1.0000 - val_loss: 0.2921 - val_acc: 0.9533\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.2065e-04 - acc: 1.0000 - val_loss: 0.2922 - val_acc: 0.9533\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.2050e-04 - acc: 1.0000 - val_loss: 0.2927 - val_acc: 0.9533\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.1539e-04 - acc: 1.0000 - val_loss: 0.2930 - val_acc: 0.9533\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.1728e-04 - acc: 1.0000 - val_loss: 0.2934 - val_acc: 0.9533\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.0895e-04 - acc: 1.0000 - val_loss: 0.2937 - val_acc: 0.9533\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.1075e-04 - acc: 1.0000 - val_loss: 0.2940 - val_acc: 0.9533\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.1251e-04 - acc: 1.0000 - val_loss: 0.2941 - val_acc: 0.9533\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.1467e-04 - acc: 1.0000 - val_loss: 0.2944 - val_acc: 0.9533\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.1312e-04 - acc: 1.0000 - val_loss: 0.2949 - val_acc: 0.9533\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.1015e-04 - acc: 1.0000 - val_loss: 0.2954 - val_acc: 0.9533\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.1005e-04 - acc: 1.0000 - val_loss: 0.2956 - val_acc: 0.9533\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.0919e-04 - acc: 1.0000 - val_loss: 0.2957 - val_acc: 0.9533\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.0503e-04 - acc: 1.0000 - val_loss: 0.2957 - val_acc: 0.9533\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.0799e-04 - acc: 1.0000 - val_loss: 0.2963 - val_acc: 0.9533\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.0659e-04 - acc: 1.0000 - val_loss: 0.2967 - val_acc: 0.9533\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.0782e-04 - acc: 1.0000 - val_loss: 0.2972 - val_acc: 0.9533\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 1.0779e-04 - acc: 1.0000 - val_loss: 0.2998 - val_acc: 0.9533\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 9.9767e-05 - acc: 1.0000 - val_loss: 0.3011 - val_acc: 0.9533\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.0095e-04 - acc: 1.0000 - val_loss: 0.2993 - val_acc: 0.9533\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 9.7836e-05 - acc: 1.0000 - val_loss: 0.3014 - val_acc: 0.9533\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 9.7810e-05 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.9533\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 9.4833e-05 - acc: 1.0000 - val_loss: 0.3040 - val_acc: 0.9533\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 9.2831e-05 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.9533\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 8.9653e-05 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.9533\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 9.8264e-05 - acc: 1.0000 - val_loss: 0.3049 - val_acc: 0.9533\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 9.1875e-05 - acc: 1.0000 - val_loss: 0.3059 - val_acc: 0.9533\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 8.5880e-05 - acc: 1.0000 - val_loss: 0.3073 - val_acc: 0.9533\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 8.6723e-05 - acc: 1.0000 - val_loss: 0.3074 - val_acc: 0.9533\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 9.0357e-05 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.9533\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.6085e-05 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.9533\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.2853e-05 - acc: 1.0000 - val_loss: 0.3102 - val_acc: 0.9533\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 7.7663e-05 - acc: 1.0000 - val_loss: 0.3102 - val_acc: 0.9533\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 8.5988e-05 - acc: 1.0000 - val_loss: 0.3107 - val_acc: 0.9533\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 8.1592e-05 - acc: 1.0000 - val_loss: 0.3139 - val_acc: 0.9533\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 7.8724e-05 - acc: 1.0000 - val_loss: 0.3132 - val_acc: 0.9533\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 7.4046e-05 - acc: 1.0000 - val_loss: 0.3122 - val_acc: 0.9533\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 7.8793e-05 - acc: 1.0000 - val_loss: 0.3136 - val_acc: 0.9533\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 7.6735e-05 - acc: 1.0000 - val_loss: 0.3161 - val_acc: 0.9533\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 7.1843e-05 - acc: 1.0000 - val_loss: 0.3162 - val_acc: 0.9533\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.2438e-05 - acc: 1.0000 - val_loss: 0.3148 - val_acc: 0.9533\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 6.8852e-05 - acc: 1.0000 - val_loss: 0.3171 - val_acc: 0.9533\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 7.5450e-05 - acc: 1.0000 - val_loss: 0.3194 - val_acc: 0.9533\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 7.1585e-05 - acc: 1.0000 - val_loss: 0.3188 - val_acc: 0.9533\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 6.8533e-05 - acc: 1.0000 - val_loss: 0.3184 - val_acc: 0.9533\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 6.9968e-05 - acc: 1.0000 - val_loss: 0.3208 - val_acc: 0.9533\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 6.1473e-05 - acc: 1.0000 - val_loss: 0.3227 - val_acc: 0.9533\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.1209e-05 - acc: 1.0000 - val_loss: 0.3216 - val_acc: 0.9533\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 6.2751e-05 - acc: 1.0000 - val_loss: 0.3231 - val_acc: 0.9533\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.5511e-05 - acc: 1.0000 - val_loss: 0.3243 - val_acc: 0.9533\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.1197e-05 - acc: 1.0000 - val_loss: 0.3236 - val_acc: 0.9533\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.2832e-05 - acc: 1.0000 - val_loss: 0.3236 - val_acc: 0.9533\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 6.4752e-05 - acc: 1.0000 - val_loss: 0.3267 - val_acc: 0.9533\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 6.2613e-05 - acc: 1.0000 - val_loss: 0.3272 - val_acc: 0.9533\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 6.1929e-05 - acc: 1.0000 - val_loss: 0.3252 - val_acc: 0.9533\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 6.1159e-05 - acc: 1.0000 - val_loss: 0.3269 - val_acc: 0.9533\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.1941e-05 - acc: 1.0000 - val_loss: 0.3293 - val_acc: 0.9533\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 5.9454e-05 - acc: 1.0000 - val_loss: 0.3295 - val_acc: 0.9533\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 5.5004e-05 - acc: 1.0000 - val_loss: 0.3280 - val_acc: 0.9533\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 5.7596e-05 - acc: 1.0000 - val_loss: 0.3298 - val_acc: 0.9533\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 5.3036e-05 - acc: 1.0000 - val_loss: 0.3320 - val_acc: 0.9533\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.6226e-05 - acc: 1.0000 - val_loss: 0.3318 - val_acc: 0.9533\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.5437e-05 - acc: 1.0000 - val_loss: 0.3308 - val_acc: 0.9533\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 5.2654e-05 - acc: 1.0000 - val_loss: 0.3328 - val_acc: 0.9533\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 5.4755e-05 - acc: 1.0000 - val_loss: 0.3347 - val_acc: 0.9533\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.0096e-05 - acc: 1.0000 - val_loss: 0.3338 - val_acc: 0.9533\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 5.1663e-05 - acc: 1.0000 - val_loss: 0.3334 - val_acc: 0.9533\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.9558e-05 - acc: 1.0000 - val_loss: 0.3366 - val_acc: 0.9533\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 5.1315e-05 - acc: 1.0000 - val_loss: 0.3372 - val_acc: 0.9533\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.7099e-05 - acc: 1.0000 - val_loss: 0.3348 - val_acc: 0.9533\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 4.9408e-05 - acc: 1.0000 - val_loss: 0.3367 - val_acc: 0.9533\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.8182e-05 - acc: 1.0000 - val_loss: 0.3389 - val_acc: 0.9533\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.7694e-05 - acc: 1.0000 - val_loss: 0.3382 - val_acc: 0.9533\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.5597e-05 - acc: 1.0000 - val_loss: 0.3382 - val_acc: 0.9533\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.8370e-05 - acc: 1.0000 - val_loss: 0.3391 - val_acc: 0.9533\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 4.4968e-05 - acc: 1.0000 - val_loss: 0.3411 - val_acc: 0.9533\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.2851e-05 - acc: 1.0000 - val_loss: 0.3404 - val_acc: 0.9533\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.2846e-05 - acc: 1.0000 - val_loss: 0.3395 - val_acc: 0.9533\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.4776e-05 - acc: 1.0000 - val_loss: 0.3417 - val_acc: 0.9533\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.0962e-05 - acc: 1.0000 - val_loss: 0.3418 - val_acc: 0.9533\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 4.2646e-05 - acc: 1.0000 - val_loss: 0.3421 - val_acc: 0.9533\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 4.2246e-05 - acc: 1.0000 - val_loss: 0.3438 - val_acc: 0.9533\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.0404e-05 - acc: 1.0000 - val_loss: 0.3447 - val_acc: 0.9533\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.1220e-05 - acc: 1.0000 - val_loss: 0.3442 - val_acc: 0.9533\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.1424e-05 - acc: 1.0000 - val_loss: 0.3438 - val_acc: 0.9533\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.9516e-05 - acc: 1.0000 - val_loss: 0.3463 - val_acc: 0.9533\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.0665e-05 - acc: 1.0000 - val_loss: 0.3462 - val_acc: 0.9533\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.9296e-05 - acc: 1.0000 - val_loss: 0.3451 - val_acc: 0.9533\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.9395e-05 - acc: 1.0000 - val_loss: 0.3462 - val_acc: 0.9533\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.0483e-05 - acc: 1.0000 - val_loss: 0.3481 - val_acc: 0.9533\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.0588e-05 - acc: 1.0000 - val_loss: 0.3468 - val_acc: 0.9533\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.8051e-05 - acc: 1.0000 - val_loss: 0.3470 - val_acc: 0.9533\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.7180e-05 - acc: 1.0000 - val_loss: 0.3493 - val_acc: 0.9533\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.6861e-05 - acc: 1.0000 - val_loss: 0.3490 - val_acc: 0.9533\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.3357e-05 - acc: 1.0000 - val_loss: 0.3484 - val_acc: 0.9533\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.6508e-05 - acc: 1.0000 - val_loss: 0.3493 - val_acc: 0.9533\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.7163e-05 - acc: 1.0000 - val_loss: 0.3494 - val_acc: 0.9533\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.1962e-05 - acc: 1.0000 - val_loss: 0.3501 - val_acc: 0.9533\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.5299e-05 - acc: 1.0000 - val_loss: 0.3506 - val_acc: 0.9533\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.3309e-05 - acc: 1.0000 - val_loss: 0.3500 - val_acc: 0.9533\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 3.3973e-05 - acc: 1.0000 - val_loss: 0.3507 - val_acc: 0.9533\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.2176e-05 - acc: 1.0000 - val_loss: 0.3513 - val_acc: 0.9533\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.0228e-05 - acc: 1.0000 - val_loss: 0.3509 - val_acc: 0.9533\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.2560e-05 - acc: 1.0000 - val_loss: 0.3512 - val_acc: 0.9533\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.2440e-05 - acc: 1.0000 - val_loss: 0.3527 - val_acc: 0.9533\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.9889e-05 - acc: 1.0000 - val_loss: 0.3517 - val_acc: 0.9533\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 3.0441e-05 - acc: 1.0000 - val_loss: 0.3521 - val_acc: 0.9533\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.2096e-05 - acc: 1.0000 - val_loss: 0.3537 - val_acc: 0.9533\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.0556e-05 - acc: 1.0000 - val_loss: 0.3541 - val_acc: 0.9533\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.9711e-05 - acc: 1.0000 - val_loss: 0.3537 - val_acc: 0.9533\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.8128e-05 - acc: 1.0000 - val_loss: 0.3539 - val_acc: 0.9533\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.0128e-05 - acc: 1.0000 - val_loss: 0.3548 - val_acc: 0.9533\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.9091e-05 - acc: 1.0000 - val_loss: 0.3562 - val_acc: 0.9533\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.9953e-05 - acc: 1.0000 - val_loss: 0.3555 - val_acc: 0.9533\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.9970e-05 - acc: 1.0000 - val_loss: 0.3557 - val_acc: 0.9533\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.7809e-05 - acc: 1.0000 - val_loss: 0.3571 - val_acc: 0.9533\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.8862e-05 - acc: 1.0000 - val_loss: 0.3573 - val_acc: 0.9533\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.9140e-05 - acc: 1.0000 - val_loss: 0.3550 - val_acc: 0.9533\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 2.9089e-05 - acc: 1.0000 - val_loss: 0.3571 - val_acc: 0.9533\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.8166e-05 - acc: 1.0000 - val_loss: 0.3595 - val_acc: 0.9533\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.9370e-05 - acc: 1.0000 - val_loss: 0.3567 - val_acc: 0.9533\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 184ms/step - loss: 2.7443e-05 - acc: 1.0000 - val_loss: 0.3571 - val_acc: 0.9533\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.6478e-05 - acc: 1.0000 - val_loss: 0.3600 - val_acc: 0.9533\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.6123e-05 - acc: 1.0000 - val_loss: 0.3597 - val_acc: 0.9533\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 186ms/step - loss: 2.4997e-05 - acc: 1.0000 - val_loss: 0.3585 - val_acc: 0.9533\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.6642e-05 - acc: 1.0000 - val_loss: 0.3591 - val_acc: 0.9533\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.5161e-05 - acc: 1.0000 - val_loss: 0.3621 - val_acc: 0.9533\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.6670e-05 - acc: 1.0000 - val_loss: 0.3621 - val_acc: 0.9533\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.5904e-05 - acc: 1.0000 - val_loss: 0.3602 - val_acc: 0.9533\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.5924e-05 - acc: 1.0000 - val_loss: 0.3614 - val_acc: 0.9533\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.5574e-05 - acc: 1.0000 - val_loss: 0.3642 - val_acc: 0.9533\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.3009e-05 - acc: 1.0000 - val_loss: 0.3634 - val_acc: 0.9533\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.4477e-05 - acc: 1.0000 - val_loss: 0.3617 - val_acc: 0.9533\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.4650e-05 - acc: 1.0000 - val_loss: 0.3633 - val_acc: 0.9533\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.3759e-05 - acc: 1.0000 - val_loss: 0.3665 - val_acc: 0.9533\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 2.6454e-05 - acc: 1.0000 - val_loss: 0.3646 - val_acc: 0.9533\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.1629e-05 - acc: 1.0000 - val_loss: 0.3636 - val_acc: 0.9533\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.2620e-05 - acc: 1.0000 - val_loss: 0.3651 - val_acc: 0.9533\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.3429e-05 - acc: 1.0000 - val_loss: 0.3666 - val_acc: 0.9533\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.3069e-05 - acc: 1.0000 - val_loss: 0.3658 - val_acc: 0.9533\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.2587e-05 - acc: 1.0000 - val_loss: 0.3659 - val_acc: 0.9533\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.1942e-05 - acc: 1.0000 - val_loss: 0.3668 - val_acc: 0.9533\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 2.1756e-05 - acc: 1.0000 - val_loss: 0.3679 - val_acc: 0.9533\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.2741e-05 - acc: 1.0000 - val_loss: 0.3673 - val_acc: 0.9533\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.1194e-05 - acc: 1.0000 - val_loss: 0.3679 - val_acc: 0.9533\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.1510e-05 - acc: 1.0000 - val_loss: 0.3690 - val_acc: 0.9533\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.0402e-05 - acc: 1.0000 - val_loss: 0.3687 - val_acc: 0.9533\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.9341e-05 - acc: 1.0000 - val_loss: 0.3687 - val_acc: 0.9533\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.0115e-05 - acc: 1.0000 - val_loss: 0.3701 - val_acc: 0.9533\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.1559e-05 - acc: 1.0000 - val_loss: 0.3704 - val_acc: 0.9533\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.0357e-05 - acc: 1.0000 - val_loss: 0.3698 - val_acc: 0.9533\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.0783e-05 - acc: 1.0000 - val_loss: 0.3713 - val_acc: 0.9533\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 2.0715e-05 - acc: 1.0000 - val_loss: 0.3720 - val_acc: 0.9533\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.9580e-05 - acc: 1.0000 - val_loss: 0.3715 - val_acc: 0.9533\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.0071e-05 - acc: 1.0000 - val_loss: 0.3720 - val_acc: 0.9533\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.0692e-05 - acc: 1.0000 - val_loss: 0.3732 - val_acc: 0.9533\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.9924e-05 - acc: 1.0000 - val_loss: 0.3730 - val_acc: 0.9533\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.8462e-05 - acc: 1.0000 - val_loss: 0.3738 - val_acc: 0.9533\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.9527e-05 - acc: 1.0000 - val_loss: 0.3737 - val_acc: 0.9533\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.8625e-05 - acc: 1.0000 - val_loss: 0.3748 - val_acc: 0.9533\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.8436e-05 - acc: 1.0000 - val_loss: 0.3743 - val_acc: 0.9533\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 1.7663e-05 - acc: 1.0000 - val_loss: 0.3750 - val_acc: 0.9533\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.9714e-05 - acc: 1.0000 - val_loss: 0.3758 - val_acc: 0.9533\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.8913e-05 - acc: 1.0000 - val_loss: 0.3757 - val_acc: 0.9533\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.8498e-05 - acc: 1.0000 - val_loss: 0.3757 - val_acc: 0.9533\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.8155e-05 - acc: 1.0000 - val_loss: 0.3770 - val_acc: 0.9533\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.9155e-05 - acc: 1.0000 - val_loss: 0.3783 - val_acc: 0.9533\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.7767e-05 - acc: 1.0000 - val_loss: 0.3779 - val_acc: 0.9533\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.7612e-05 - acc: 1.0000 - val_loss: 0.3769 - val_acc: 0.9533\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.7757e-05 - acc: 1.0000 - val_loss: 0.3781 - val_acc: 0.9533\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.6929e-05 - acc: 1.0000 - val_loss: 0.3792 - val_acc: 0.9533\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.7823e-05 - acc: 1.0000 - val_loss: 0.3794 - val_acc: 0.9533\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.7002e-05 - acc: 1.0000 - val_loss: 0.3797 - val_acc: 0.9533\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.7480e-05 - acc: 1.0000 - val_loss: 0.3801 - val_acc: 0.9533\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 1.6809e-05 - acc: 1.0000 - val_loss: 0.3806 - val_acc: 0.9533\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.6588e-05 - acc: 1.0000 - val_loss: 0.3802 - val_acc: 0.9533\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.7333e-05 - acc: 1.0000 - val_loss: 0.3813 - val_acc: 0.9533\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.7369e-05 - acc: 1.0000 - val_loss: 0.3821 - val_acc: 0.9533\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.6485e-05 - acc: 1.0000 - val_loss: 0.3821 - val_acc: 0.9533\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.6194e-05 - acc: 1.0000 - val_loss: 0.3817 - val_acc: 0.9533\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.6065e-05 - acc: 1.0000 - val_loss: 0.3824 - val_acc: 0.9533\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.6530e-05 - acc: 1.0000 - val_loss: 0.3835 - val_acc: 0.9533\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.5362e-05 - acc: 1.0000 - val_loss: 0.3833 - val_acc: 0.9533\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.5476e-05 - acc: 1.0000 - val_loss: 0.3833 - val_acc: 0.9533\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.6389e-05 - acc: 1.0000 - val_loss: 0.3840 - val_acc: 0.9533\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.5853e-05 - acc: 1.0000 - val_loss: 0.3846 - val_acc: 0.9533\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.5628e-05 - acc: 1.0000 - val_loss: 0.3851 - val_acc: 0.9533\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.5495e-05 - acc: 1.0000 - val_loss: 0.3854 - val_acc: 0.9533\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.5691e-05 - acc: 1.0000 - val_loss: 0.3851 - val_acc: 0.9533\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.5241e-05 - acc: 1.0000 - val_loss: 0.3857 - val_acc: 0.9533\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 1.4610e-05 - acc: 1.0000 - val_loss: 0.3862 - val_acc: 0.9533\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 1.5934e-05 - acc: 1.0000 - val_loss: 0.3870 - val_acc: 0.9533\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.4918e-05 - acc: 1.0000 - val_loss: 0.3870 - val_acc: 0.9533\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.4871e-05 - acc: 1.0000 - val_loss: 0.3870 - val_acc: 0.9533\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 1.4730e-05 - acc: 1.0000 - val_loss: 0.3879 - val_acc: 0.9533\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.4152e-05 - acc: 1.0000 - val_loss: 0.3880 - val_acc: 0.9533\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.4366e-05 - acc: 1.0000 - val_loss: 0.3877 - val_acc: 0.9533\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.4362e-05 - acc: 1.0000 - val_loss: 0.3888 - val_acc: 0.9533\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.3072e-05 - acc: 1.0000 - val_loss: 0.3898 - val_acc: 0.9533\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.3276e-05 - acc: 1.0000 - val_loss: 0.3898 - val_acc: 0.9533\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.3886e-05 - acc: 1.0000 - val_loss: 0.3894 - val_acc: 0.9533\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.4580e-05 - acc: 1.0000 - val_loss: 0.3907 - val_acc: 0.9533\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.4495e-05 - acc: 1.0000 - val_loss: 0.3915 - val_acc: 0.9533\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.3253e-05 - acc: 1.0000 - val_loss: 0.3909 - val_acc: 0.9533\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.3456e-05 - acc: 1.0000 - val_loss: 0.3908 - val_acc: 0.9533\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.3381e-05 - acc: 1.0000 - val_loss: 0.3922 - val_acc: 0.9533\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.3252e-05 - acc: 1.0000 - val_loss: 0.3930 - val_acc: 0.9533\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.3358e-05 - acc: 1.0000 - val_loss: 0.3925 - val_acc: 0.9533\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.3291e-05 - acc: 1.0000 - val_loss: 0.3922 - val_acc: 0.9533\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.2711e-05 - acc: 1.0000 - val_loss: 0.3935 - val_acc: 0.9533\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.2749e-05 - acc: 1.0000 - val_loss: 0.3940 - val_acc: 0.9533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qzK4SJB5y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "2668f117-cb8b-41e8-c3f6-929582225ac1"
      },
      "source": [
        "plt.figure(figsize =(5,3))\n",
        "plt.plot(history.history['acc'], marker='.', label='tune')\n",
        "plt.plot(history.history['val_acc'], marker='.', label='test')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA Model_DS_60_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ilyaas189/Text-Analytics_CE_807/blob/main/LDA_Model_DS_60_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "h48neXM-ANwE",
        "outputId": "0b2b6fbe-fd48-43b6-b8d9-a189265fedc4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from google.colab import files\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import random\n",
        "uploaded = files.upload()\n",
        "files = list(uploaded.keys())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cd00d7da-b885-4759-9e6a-c87ca24deca4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cd00d7da-b885-4759-9e6a-c87ca24deca4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcrJU_pzAhOm",
        "outputId": "2128993d-aae7-49c3-f741-63e43ea19f44"
      },
      "source": [
        "# Import Dataset\n",
        "data = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "print(data.target_names.unique())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
            " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
            " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
            " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
            " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
            " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "SnGiNUYGAtLQ",
        "outputId": "3f711fb6-228c-4bde-c542-17981da4156a"
      },
      "source": [
        "data.head(20)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
              "      <td>16</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
              "      <td>13</td>\n",
              "      <td>sci.med</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
              "      <td>3</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
              "      <td>8</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>From: david@terminus.ericsson.se (David Bold)\\...</td>\n",
              "      <td>19</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>From: dbm0000@tm0006.lerc.nasa.gov (David B. M...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...</td>\n",
              "      <td>6</td>\n",
              "      <td>misc.forsale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...</td>\n",
              "      <td>12</td>\n",
              "      <td>sci.electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>From: abarden@tybse1.uucp (Ann Marie Barden)\\n...</td>\n",
              "      <td>5</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              content  ...              target_names\n",
              "0   From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...                 rec.autos\n",
              "1   From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...     comp.sys.mac.hardware\n",
              "2   From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...     comp.sys.mac.hardware\n",
              "3   From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...             comp.graphics\n",
              "4   From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...                 sci.space\n",
              "5   From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...  ...        talk.politics.guns\n",
              "6   From: bmdelane@quads.uchicago.edu (brian manni...  ...                   sci.med\n",
              "7   From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...  ...  comp.sys.ibm.pc.hardware\n",
              "8   From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...  ...   comp.os.ms-windows.misc\n",
              "9   From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...  ...     comp.sys.mac.hardware\n",
              "10  From: irwin@cmptrc.lonestar.org (Irwin Arnstei...  ...           rec.motorcycles\n",
              "11  From: david@terminus.ericsson.se (David Bold)\\...  ...        talk.religion.misc\n",
              "12  From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...  ...     comp.sys.mac.hardware\n",
              "13  From: dbm0000@tm0006.lerc.nasa.gov (David B. M...  ...                 sci.space\n",
              "14  From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...  ...              misc.forsale\n",
              "15  From: mathew <mathew@mantis.co.uk>\\nSubject: R...  ...               alt.atheism\n",
              "16  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...  ...             comp.graphics\n",
              "17  From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...  ...                 rec.autos\n",
              "18  From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...  ...           sci.electronics\n",
              "19  From: abarden@tybse1.uucp (Ann Marie Barden)\\n...  ...            comp.windows.x\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1t4Hd65BKo4",
        "outputId": "cb776e24-aff2-4227-c90b-093a8a8b43f4"
      },
      "source": [
        "data_clusterization = data[['content', 'target_names']]\n",
        "data_clusterization.dropna(inplace=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "0xRJ8_03Bd1W",
        "outputId": "2b0d3fef-40ad-4bec-db7d-63a4429bd06c"
      },
      "source": [
        "data_clusterization.head(2)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content           target_names\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...              rec.autos\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  comp.sys.mac.hardware"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iUh1DoLBmXP",
        "outputId": "2ecde699-ac4b-453d-832e-50e760be950a"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7hwfWd1Bw8S"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        " stemmer = SnowballStemmer(language='english')\n",
        " return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        " result = []\n",
        " for token in gensim.utils.simple_preprocess(text):\n",
        "   if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "     result.append(lemmatize_stemming(token))\n",
        " return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJfVX8biB_Sa"
      },
      "source": [
        "processed_docs = data_clusterization['content'].map(preprocess)\n",
        "data_processed = processed_docs.to_frame()\n",
        "data_processed['content'] = data_processed.content.apply(lambda x: ' '.join(x))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCHPTBYJClMy",
        "outputId": "39bebccc-fb0e-434d-92c8-b15ae85e4ac7"
      },
      "source": [
        "!pip install tokenize_uk\n",
        "from collections import Counter\n",
        "from tokenize_uk.tokenize_uk import tokenize_words"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenize_uk\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/21/72abb0304b532e1b2d2473b50d8063ddd0943e3b3fe7e86b366bc4d02aa2/tokenize_uk-0.2.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tokenize_uk) (1.15.0)\n",
            "Building wheels for collected packages: tokenize-uk\n",
            "  Building wheel for tokenize-uk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tokenize-uk: filename=tokenize_uk-0.2.0-py2.py3-none-any.whl size=4565 sha256=a8d588e89765c72810a3e61d1c728731af30ec3c01ad2a91acdb581d0549899a\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/e1/95/fd8af5b40aeebdc4e178974e7f638f5553aa8772117054db9e\n",
            "Successfully built tokenize-uk\n",
            "Installing collected packages: tokenize-uk\n",
            "Successfully installed tokenize-uk-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "94mq8WUoCqHq",
        "outputId": "8bf799c6-bb3e-4f1b-93d1-71401447a429"
      },
      "source": [
        "def display_words(data, title, ax):\n",
        " count = Counter(sum(map(lambda text: tokenize_words(text), data), []))\n",
        " popular = np.array(sorted(count.items(), key=lambda x: x[1], reverse=True)[:20])\n",
        " plt.sca(ax)\n",
        " plt.title(title)\n",
        " plt.bar(popular[:,0], np.int32(popular[:,1]))\n",
        " plt.xticks(rotation=\"vertical\")\n",
        "fig, ax = plt.subplots(figsize=(16, 5))\n",
        "display_words(data_processed.sample(1000).content, \"The most popular words]\", ax)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCM4qevNC5Ty"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMnRgz3aC8f5",
        "outputId": "1a5cf6ef-9303-4f94-b681-85d80e77947e"
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "count_data = count_vectorizer.fit_transform(data_processed['content'])\n",
        "count_data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11314x61410 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 934270 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TmSX73jDEJS"
      },
      "source": [
        "likelihood = []\n",
        "n_clusters = []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9uTcUJlDHT0"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hki6oWR0DLwb"
      },
      "source": [
        "def estimate_number_clusters(data, nclusters):\n",
        " for n in nclusters:\n",
        "   likelihood.append(LDA(n_components=n, n_jobs=-1).fit(data).score(data))\n",
        " n_clusters.append(n)\n",
        " print(\"Sccesfully estimated \", n)\n",
        " fig, ax = plt.subplots(figsize=(15, 5))\n",
        " sns.lineplot(x=n_clusters, y=likelihood, ax=ax)\n",
        " ax.set_title('Elbow method for choosing n, likelihood')\n",
        " ax.set_ylabel('Likelihood')\n",
        " ax.set_xlabel('n')\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CBG_y1fJszZ"
      },
      "source": [
        "# estimate_number_clusters(count_data, [10, 15, 20, 50])\n",
        " \n",
        " "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XNMixjQJuYE"
      },
      "source": [
        "def print_topics(model, count_vectorizer, n_top_words):\n",
        "  words = count_vectorizer.get_feature_names()\n",
        "  for topic_idx, topic in enumerate(model.components_):\n",
        "    print(\"\\nTopic #%d:\" % topic_idx)\n",
        "    print(\" \".join([words[i]\n",
        "  for i in topic.argsort()[:-n_top_words - 1:-1]]))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugizp_hhFpzm"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWtTkYX1Ftia",
        "outputId": "21623f1d-9783-4cde-9788-a06a9dc6db30"
      },
      "source": [
        "number_topics = 60\n",
        "number_words = 10\n",
        "# Create and fit the LDA model\n",
        "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
        "lda.fit(count_data)\n",
        "# Print the topics found by the LDA model\n",
        "print(\"Topics found via LDA:\")\n",
        "print_topics(lda, count_vectorizer, number_words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topics found via LDA:\n",
            "\n",
            "Topic #0:\n",
            "uiuc austin write line utexa subject organ texa articl illinoi\n",
            "\n",
            "Topic #1:\n",
            "moral cwru write subject post object cleveland line organ keith\n",
            "\n",
            "Topic #2:\n",
            "andrew pitt bank subject organ line gordon pittsburgh write articl\n",
            "\n",
            "Topic #3:\n",
            "access digex line post subject organ write host nntp audio\n",
            "\n",
            "Topic #4:\n",
            "netcom line organ subject communic write phone clipper brad servic\n",
            "\n",
            "Topic #5:\n",
            "line subject organ engin write softwar nasa like post nntp\n",
            "\n",
            "Topic #6:\n",
            "line organ subject univers pitch articl ball write year john\n",
            "\n",
            "Topic #7:\n",
            "sale line subject organ columbia univers post sell host nntp\n",
            "\n",
            "Topic #8:\n",
            "state ohio write articl magnus line subject organ univers princeton\n",
            "\n",
            "Topic #9:\n",
            "bike wire like line subject good time organ drive look\n",
            "\n",
            "Topic #10:\n",
            "line subject organ nasa post articl larc write david nntp\n",
            "\n",
            "Topic #11:\n",
            "write armenia armenian line henrik articl organ subject mormon say\n",
            "\n",
            "Topic #12:\n",
            "european south time american world nuclear rockefel island franci british\n",
            "\n",
            "Topic #13:\n",
            "imag file format graphic jpeg color convert program keyboard display\n",
            "\n",
            "Topic #14:\n",
            "encrypt chip secur clipper key govern escrow privaci public technolog\n",
            "\n",
            "Topic #15:\n",
            "navi subject organ line center articl research write cancer oasi\n",
            "\n",
            "Topic #16:\n",
            "israel isra say arab peopl jew go know come think\n",
            "\n",
            "Topic #17:\n",
            "card port line subject modem organ driver board univers serial\n",
            "\n",
            "Topic #18:\n",
            "militia right organ peopl write articl second subject arm amend\n",
            "\n",
            "Topic #19:\n",
            "univers nation institut center research inform confer studi april organ\n",
            "\n",
            "Topic #20:\n",
            "line subject organ articl write freenet carleton post washington nntp\n",
            "\n",
            "Topic #21:\n",
            "write articl subject organ line know food post like year\n",
            "\n",
            "Topic #22:\n",
            "flyer mike clarkson rochest john line lindro michael zone play\n",
            "\n",
            "Topic #23:\n",
            "jake boni master marriag marri slave write subject opinion jumper\n",
            "\n",
            "Topic #24:\n",
            "appl sandvik kent write organ line articl subject monash newton\n",
            "\n",
            "Topic #25:\n",
            "avail mail includ user server data list inform program file\n",
            "\n",
            "Topic #26:\n",
            "line write organ subject think post harri right articl host\n",
            "\n",
            "Topic #27:\n",
            "peopl right govern state think countri like want person polit\n",
            "\n",
            "Topic #28:\n",
            "period play power king sweden second goal scorer shot line\n",
            "\n",
            "Topic #29:\n",
            "articl write organ subject toronto henri line cramer optilink clayton\n",
            "\n",
            "Topic #30:\n",
            "window subject line organ post buffalo nntp host write captain\n",
            "\n",
            "Topic #31:\n",
            "game team play player hockey season year line score leagu\n",
            "\n",
            "Topic #32:\n",
            "stratus write koresh articl start line subject organ compound batf\n",
            "\n",
            "Topic #33:\n",
            "vote contact mail send version hiram post type avail univers\n",
            "\n",
            "Topic #34:\n",
            "oracl dresden amherst andr line wagon organ beck eliot subject\n",
            "\n",
            "Topic #35:\n",
            "colorado gatech prism subject line organ write boulder georgia articl\n",
            "\n",
            "Topic #36:\n",
            "virginia line organ subject univers arizona water food smoke write\n",
            "\n",
            "Topic #37:\n",
            "armenian turkish turk greek turkey argic serdar genocid armenia peopl\n",
            "\n",
            "Topic #38:\n",
            "write articl organ helmet line subject like ingr behanna post\n",
            "\n",
            "Topic #39:\n",
            "line organ subject mcgill write hawk articl adob post nntp\n",
            "\n",
            "Topic #40:\n",
            "diseas doctor medic patient treatment pain organ problem time caus\n",
            "\n",
            "Topic #41:\n",
            "jesus christian christ come say know write church peopl bibl\n",
            "\n",
            "Topic #42:\n",
            "gun firearm weapon crime crimin control handgun polic like file\n",
            "\n",
            "Topic #43:\n",
            "write subject line organ articl post know think nntp host\n",
            "\n",
            "Topic #44:\n",
            "drive scsi disk control hard problem line floppi subject organ\n",
            "\n",
            "Topic #45:\n",
            "atheism atheist post subject exist write line organ pope articl\n",
            "\n",
            "Topic #46:\n",
            "subject line articl organ write year child children stein post\n",
            "\n",
            "Topic #47:\n",
            "nrhj wwiz link alloc subject harvard unit gizw bhjn organ\n",
            "\n",
            "Topic #48:\n",
            "islam muslim jaeger rushdi gregg byte line bit buphi organ\n",
            "\n",
            "Topic #49:\n",
            "christian believ peopl think question exist know reason write claim\n",
            "\n",
            "Topic #50:\n",
            "line subject organ point govern libertarian steve write thor univers\n",
            "\n",
            "Topic #51:\n",
            "window line subject organ post problem thank host nntp univers\n",
            "\n",
            "Topic #52:\n",
            "drug tobacco health legal report articl state cigarett like smokeless\n",
            "\n",
            "Topic #53:\n",
            "organ line subject anti write bellcor say francisco muenchen semit\n",
            "\n",
            "Topic #54:\n",
            "year line organ subject like articl think write univers know\n",
            "\n",
            "Topic #55:\n",
            "subject problem line organ water motif lose post host nntp\n",
            "\n",
            "Topic #56:\n",
            "line write subject organ insur need articl nore post batf\n",
            "\n",
            "Topic #57:\n",
            "presid stephanopoulo go say know work think time clinton job\n",
            "\n",
            "Topic #58:\n",
            "file window program entri output line widget return write applic\n",
            "\n",
            "Topic #59:\n",
            "space nasa orbit launch earth satellit moon mission lunar year\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "LrPaQEiuGRt3",
        "outputId": "fd0f9824-39c1-40dd-dba1-7581a65ff0ca"
      },
      "source": [
        "cluster_probabilities = lda.transform(count_data)\n",
        "data_processed['target'] = np.argmax(cluster_probabilities, axis=1)\n",
        "data_processed.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lerxst thing subject nntp post host organ univ...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>guykuo carson washington subject clock poll fi...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twilli purdu thoma willi subject question orga...</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jgreen amber green subject weitek organ harri ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>head harvard jonathan mcdowel subject shuttl l...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  target\n",
              "0  lerxst thing subject nntp post host organ univ...      21\n",
              "1  guykuo carson washington subject clock poll fi...      18\n",
              "2  twilli purdu thoma willi subject question orga...      51\n",
              "3  jgreen amber green subject weitek organ harri ...       5\n",
              "4  head harvard jonathan mcdowel subject shuttl l...       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJNJOHB9GkKP"
      },
      "source": [
        "import seaborn as sns\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "At3W9AMVGnga",
        "outputId": "9a5f11d8-a65e-4a1b-d8e0-ef48b6158996"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "sns.countplot(x=data_processed.target);\n",
        "ax.set_title(\"Number of articles that correspond to the topic\");\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ07JMrCRAYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b435591-247c-4a94-c2ad-dc4166b6e6d9"
      },
      "source": [
        "#Loading the data set - training data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "mydata_train = fetch_20newsgroups(subset='train', shuffle=True, remove = ('headers', 'footers', 'quotes'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpyae_wBRHIU",
        "outputId": "d60c92a5-c01f-48c0-e1a5-fe8c1f19c440"
      },
      "source": [
        "list(mydata_train)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'filenames', 'target_names', 'target', 'DESCR']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsmrhUPeRJ9l",
        "outputId": "5f5f5c20-2b90-4385-8c7e-19d967440ff7"
      },
      "source": [
        "print('Training data size:', len(mydata_train['data']))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size: 11314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv1WrOdSRONT",
        "outputId": "7cf94f7a-7d10-45fc-df11-17cdd83e6812"
      },
      "source": [
        "# Printing all the categories\n",
        "mydata_train.target_names"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krZedPVlRRxL",
        "outputId": "21228280-b58e-4275-f93a-61d2d9d5b124"
      },
      "source": [
        "\n",
        "# Finding frequency of each category\n",
        "targets, frequency = np.unique(mydata_train.target, return_counts=True)\n",
        "targets, frequency"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "        17, 18, 19]),\n",
              " array([480, 584, 591, 590, 578, 593, 585, 594, 598, 597, 600, 595, 591,\n",
              "        594, 593, 599, 546, 564, 465, 377]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSr8qhRVRWTb",
        "outputId": "b4dba0d2-01d6-49b4-c623-a2a09367fc19"
      },
      "source": [
        "targets_str = np.array(mydata_train.target_names)\n",
        "print(list(zip(targets_str, frequency)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('alt.atheism', 480), ('comp.graphics', 584), ('comp.os.ms-windows.misc', 591), ('comp.sys.ibm.pc.hardware', 590), ('comp.sys.mac.hardware', 578), ('comp.windows.x', 593), ('misc.forsale', 585), ('rec.autos', 594), ('rec.motorcycles', 598), ('rec.sport.baseball', 597), ('rec.sport.hockey', 600), ('sci.crypt', 595), ('sci.electronics', 591), ('sci.med', 594), ('sci.space', 593), ('soc.religion.christian', 599), ('talk.politics.guns', 546), ('talk.politics.mideast', 564), ('talk.politics.misc', 465), ('talk.religion.misc', 377)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pZ_KnVPRZSm"
      },
      "source": [
        "mydata_test = fetch_20newsgroups(subset='test', shuffle=True, remove = ('headers', 'footers', 'quotes'))\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEcSYoJmRcUc",
        "outputId": "038be8db-12c9-4903-c44e-103341d9e9c5"
      },
      "source": [
        "print('Testing data size:', len(mydata_test['data']))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing data size: 7532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "_aSKch0QRf_o",
        "outputId": "1b468966-fd2b-4bf1-deb2-9aab7c8bebd0"
      },
      "source": [
        "mydata_train_df = pd.DataFrame({'data': mydata_train.data, 'target': mydata_train.target})\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I was wondering if anyone out there could enli...       7\n",
              "1  A fair number of brave souls who upgraded thei...       4\n",
              "2  well folks, my mac plus finally gave up the gh...       4\n",
              "3  \\nDo you have Weitek's address/phone number?  ...       1\n",
              "4  From article <C5owCB.n3p@world.std.com>, by to...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "ttru-cT7Rj9K",
        "outputId": "c7b6dd96-b65c-4da1-d48c-80e50024ec3d"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "import re\n",
        "import string\n",
        "\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_train_df['data'] = mydata_train_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks  my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\ndo you have weitek s address phone number   ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>from article      world std com   by tombaker ...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i was wondering if anyone out there could enli...       7\n",
              "1  a fair number of brave souls who upgraded thei...       4\n",
              "2  well folks  my mac plus finally gave up the gh...       4\n",
              "3  \\ndo you have weitek s address phone number   ...       1\n",
              "4  from article      world std com   by tombaker ...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "8f6jlH07RoBH",
        "outputId": "09e750aa-e2a1-4ef4-bd71-3091eca793cc"
      },
      "source": [
        "mydata_test_df = pd.DataFrame({'data': mydata_test.data, 'target': mydata_test.target})\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIn a word, yes.\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThey were attacking the Iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nI've just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I am a little confused on all of the models of...       7\n",
              "1  I'm not familiar at all with the format of the...       5\n",
              "2                                \\nIn a word, yes.\\n       0\n",
              "3  \\nThey were attacking the Iraqis to drive them...      17\n",
              "4  \\nI've just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "tUjU5KP5RrlP",
        "outputId": "78b08acb-35e0-4072-86e4-f21c9215483f"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_test_df['data'] = mydata_test_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i m not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nin a word  yes \\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nthey were attacking the iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\ni ve just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i am a little confused on all of the models of...       7\n",
              "1  i m not familiar at all with the format of the...       5\n",
              "2                                \\nin a word  yes \\n       0\n",
              "3  \\nthey were attacking the iraqis to drive them...      17\n",
              "4  \\ni ve just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUELDX2-bNNg",
        "outputId": "ce906897-7caa-4e5f-bd14-3b478bad1702"
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "X_train_cv = count_vect.fit_transform(mydata_train_df.data) # fit_transform learns the\n",
        "X_test_cv = count_vect.transform(mydata_test_df.data) # transform uses the same vocab an\n",
        "print(X_train_cv.shape)\n",
        "print(type(X_train_cv))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11314, 67822)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRUtZ9-VAkiY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
        "from keras.models import Model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Oz3FjnHAqOw",
        "outputId": "7292b537-cd5b-4766-e36e-7994df6a838a"
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian'] \n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, \n",
        "                                      categories=categories,)\n",
        "\n",
        "print (newsgroups_train.target_names)\n",
        "print (len(newsgroups_train.data))\n",
        "\n",
        "#print (newsgroups_train.data[1])\n",
        "print(\"\\n\".join(newsgroups_train.data[0].split(\"\\n\")[10:15]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'soc.religion.christian']\n",
            "1079\n",
            "   WASHINGTON, April 19  -- A symposium on the Dead Sea \n",
            "Scrolls will be held at the Library of Congress on Wednesday,\n",
            "April 21, and Thursday, April 22.  The two-day program, cosponsored\n",
            "by the library and Baltimore Hebrew University, with additional\n",
            "support from the Project Judaica Foundation, will be held in the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9VVEyQWAu6m",
        "outputId": "d1f16f98-c4c2-4976-f792-8cf5dfe3c774"
      },
      "source": [
        "%%time\n",
        "\n",
        "texts = []\n",
        "\n",
        "labels=newsgroups_train.target\n",
        "texts = newsgroups_train.data\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NB_WORDS = 20000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "print (sequences[0][:10])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19, 8762, 3621, 11894, 58, 8762, 3621, 43, 1472, 2]\n",
            "CPU times: user 435 ms, sys: 820 s, total: 436 ms\n",
            "Wall time: 437 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C-jZJV1Ay0E",
        "outputId": "902f1913-6d44-4bea-db5a-c66784581eb3"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20030 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3leeqbJA1-q",
        "outputId": "e7e9534f-695f-45af-d388-40e9f24f3f42"
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print (data.shape)\n",
        "print (data[0][200:250])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1079, 1000)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0    19  8762  3621 11894    58  8762  3621\n",
            "    43  1472     2  2130     3   189   450  1001  3622  2980  1682   476\n",
            "   627    50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TATKrjgmA6lK",
        "outputId": "905e230a-924f-4b8d-d322-3d2719b93600"
      },
      "source": [
        "labels = to_categorical(np.array(labels))\n",
        "\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1079, 1000)\n",
            "Shape of label tensor: (1079, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKD1nppNA_cG",
        "outputId": "cf64dc7d-7f7a-46f3-f95e-c8f9bef774bd"
      },
      "source": [
        "VALIDATION_SPLIT = 0.1\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices) \n",
        "data = data[indices] \n",
        "labels = labels[indices] \n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples] \n",
        "y_train = labels[:-nb_validation_samples] \n",
        "x_val = data[-nb_validation_samples:] \n",
        "y_val = labels[-nb_validation_samples:] \n",
        "\n",
        "print (x_train.shape)\n",
        "print (y_train.shape)\n",
        "\n",
        "print('Number of positive and negative reviews in traing and validation set ') \n",
        "print (y_train.sum(axis=0))\n",
        "print (y_val.sum(axis=0))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(972, 1000)\n",
            "(972, 2)\n",
            "Number of positive and negative reviews in traing and validation set \n",
            "[434. 538.]\n",
            "[46. 61.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "1jN7GicoBSkh",
        "outputId": "b8fb3d08-49a0-496e-ef54-45178c20d2ea"
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros.\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print (embedding_matrix.shape)\n",
        "\n",
        "print (embedding_matrix[0][:10])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6fb53264530f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# words not found in embedding index will be all-zeros.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StT4yPYaBUgr",
        "outputId": "08dbca62-23e1-4d7e-f682-f4416b406bd2"
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix], \n",
        "                            input_length=MAX_SEQUENCE_LENGTH, \n",
        "                            trainable=False)\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32') \n",
        "embedded_sequences = embedding_layer(sequence_input) \n",
        "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences) \n",
        "l_pool1 = MaxPooling1D(5)(l_cov1) \n",
        "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1) \n",
        "l_pool2 = MaxPooling1D(5)(l_cov2) \n",
        "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2) \n",
        "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
        "\n",
        "l_flat = Flatten()(l_pool3) \n",
        "l_dense = Dense(128, activation='relu')(l_flat) \n",
        "preds = Dense(2, activation='softmax')(l_dense)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1000)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1000, 100)         2003100   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 996, 128)          64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 199, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 195, 128)          82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 39, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 35, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 2,248,094\n",
            "Trainable params: 244,994\n",
            "Non-trainable params: 2,003,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohWKe6xrBfGj",
        "outputId": "1b950497-356e-46f3-d8a0-a895d5ee2034"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "                    epochs=500, batch_size=512)   "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 35s 1s/step - loss: 0.8099 - acc: 0.5512 - val_loss: 0.6828 - val_acc: 0.5701\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6967 - acc: 0.5210 - val_loss: 0.6909 - val_acc: 0.5234\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6897 - acc: 0.5499 - val_loss: 0.6869 - val_acc: 0.5701\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6914 - acc: 0.5493 - val_loss: 0.6859 - val_acc: 0.5701\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6865 - acc: 0.5578 - val_loss: 0.6829 - val_acc: 0.5701\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.6853 - acc: 0.5578 - val_loss: 0.6825 - val_acc: 0.5701\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.6846 - acc: 0.5558 - val_loss: 0.6827 - val_acc: 0.5701\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6859 - acc: 0.5643 - val_loss: 0.6811 - val_acc: 0.5701\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6818 - acc: 0.5598 - val_loss: 0.6857 - val_acc: 0.5701\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6846 - acc: 0.5579 - val_loss: 0.6802 - val_acc: 0.5701\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6831 - acc: 0.5532 - val_loss: 0.6792 - val_acc: 0.5701\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 0.6797 - acc: 0.5571 - val_loss: 0.6807 - val_acc: 0.5701\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6800 - acc: 0.5558 - val_loss: 0.6771 - val_acc: 0.5701\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6800 - acc: 0.5494 - val_loss: 0.6765 - val_acc: 0.5701\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6779 - acc: 0.5624 - val_loss: 0.6778 - val_acc: 0.5888\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6766 - acc: 0.5972 - val_loss: 0.6748 - val_acc: 0.5701\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6730 - acc: 0.5527 - val_loss: 0.6747 - val_acc: 0.5701\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6739 - acc: 0.5575 - val_loss: 0.6767 - val_acc: 0.6449\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6721 - acc: 0.6933 - val_loss: 0.6690 - val_acc: 0.5794\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6627 - acc: 0.5830 - val_loss: 0.6702 - val_acc: 0.6075\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6631 - acc: 0.6541 - val_loss: 0.6637 - val_acc: 0.5794\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6575 - acc: 0.6304 - val_loss: 0.6611 - val_acc: 0.6262\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6536 - acc: 0.6268 - val_loss: 0.6559 - val_acc: 0.5981\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6461 - acc: 0.6259 - val_loss: 0.6681 - val_acc: 0.5421\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.6486 - acc: 0.6342 - val_loss: 0.6577 - val_acc: 0.5701\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6584 - acc: 0.6238 - val_loss: 0.6393 - val_acc: 0.7009\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6239 - acc: 0.7568 - val_loss: 0.6315 - val_acc: 0.6075\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6150 - acc: 0.7012 - val_loss: 0.6264 - val_acc: 0.7757\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.6053 - acc: 0.8309 - val_loss: 0.6176 - val_acc: 0.5981\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.6094 - acc: 0.6352 - val_loss: 0.5962 - val_acc: 0.7477\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.5807 - acc: 0.7113 - val_loss: 0.6059 - val_acc: 0.6822\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.5706 - acc: 0.7798 - val_loss: 0.6271 - val_acc: 0.5888\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.5930 - acc: 0.6323 - val_loss: 0.5662 - val_acc: 0.7757\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.5566 - acc: 0.7938 - val_loss: 0.5383 - val_acc: 0.8318\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.5362 - acc: 0.7705 - val_loss: 0.5367 - val_acc: 0.7570\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.5217 - acc: 0.7417 - val_loss: 0.5134 - val_acc: 0.8785\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.4878 - acc: 0.9150 - val_loss: 0.5077 - val_acc: 0.7570\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.4753 - acc: 0.7904 - val_loss: 0.5232 - val_acc: 0.7196\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.4754 - acc: 0.8006 - val_loss: 0.4598 - val_acc: 0.8131\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.4760 - acc: 0.7611 - val_loss: 0.4909 - val_acc: 0.7570\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.4565 - acc: 0.7539 - val_loss: 0.5527 - val_acc: 0.5888\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.4753 - acc: 0.7354 - val_loss: 0.4852 - val_acc: 0.7664\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.4421 - acc: 0.7789 - val_loss: 0.4747 - val_acc: 0.7664\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.4133 - acc: 0.8583 - val_loss: 0.4228 - val_acc: 0.8224\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.3864 - acc: 0.8305 - val_loss: 0.4069 - val_acc: 0.8879\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.3578 - acc: 0.9339 - val_loss: 0.3823 - val_acc: 0.8224\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.3407 - acc: 0.8687 - val_loss: 0.3929 - val_acc: 0.8692\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.3348 - acc: 0.9247 - val_loss: 0.3754 - val_acc: 0.8224\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.3224 - acc: 0.8690 - val_loss: 0.3808 - val_acc: 0.8692\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.3079 - acc: 0.9240 - val_loss: 0.3528 - val_acc: 0.8224\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.3009 - acc: 0.8893 - val_loss: 0.3419 - val_acc: 0.9065\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.2860 - acc: 0.9257 - val_loss: 0.3012 - val_acc: 0.8785\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.2738 - acc: 0.9081 - val_loss: 0.2677 - val_acc: 0.9252\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.2255 - acc: 0.9371 - val_loss: 0.2556 - val_acc: 0.9252\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.2131 - acc: 0.9542 - val_loss: 0.2556 - val_acc: 0.8972\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.2090 - acc: 0.9259 - val_loss: 0.2565 - val_acc: 0.9159\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1923 - acc: 0.9629 - val_loss: 0.2585 - val_acc: 0.8972\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.1822 - acc: 0.9347 - val_loss: 0.2934 - val_acc: 0.8879\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.2169 - acc: 0.9478 - val_loss: 0.2425 - val_acc: 0.8972\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.1810 - acc: 0.9442 - val_loss: 0.2096 - val_acc: 0.9439\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.1618 - acc: 0.9492 - val_loss: 0.2031 - val_acc: 0.9346\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1551 - acc: 0.9596 - val_loss: 0.2188 - val_acc: 0.9252\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.1551 - acc: 0.9425 - val_loss: 0.1980 - val_acc: 0.9346\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.1459 - acc: 0.9670 - val_loss: 0.2041 - val_acc: 0.9252\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.1413 - acc: 0.9466 - val_loss: 0.1835 - val_acc: 0.9439\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.1149 - acc: 0.9831 - val_loss: 0.1790 - val_acc: 0.9439\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.1088 - acc: 0.9615 - val_loss: 0.1833 - val_acc: 0.9439\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0982 - acc: 0.9731 - val_loss: 0.1838 - val_acc: 0.9159\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.1026 - acc: 0.9803 - val_loss: 0.1819 - val_acc: 0.9439\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0967 - acc: 0.9712 - val_loss: 0.1699 - val_acc: 0.9159\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0845 - acc: 0.9804 - val_loss: 0.1807 - val_acc: 0.9439\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0780 - acc: 0.9758 - val_loss: 0.1761 - val_acc: 0.9252\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0773 - acc: 0.9877 - val_loss: 0.1754 - val_acc: 0.9439\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 0.0682 - acc: 0.9764 - val_loss: 0.1678 - val_acc: 0.9159\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0664 - acc: 0.9932 - val_loss: 0.1749 - val_acc: 0.9346\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0624 - acc: 0.9778 - val_loss: 0.1607 - val_acc: 0.9252\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0564 - acc: 0.9926 - val_loss: 0.1690 - val_acc: 0.9346\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0513 - acc: 0.9812 - val_loss: 0.1557 - val_acc: 0.9252\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0486 - acc: 0.9960 - val_loss: 0.1639 - val_acc: 0.9439\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0470 - acc: 0.9832 - val_loss: 0.1473 - val_acc: 0.9252\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 0.0407 - acc: 0.9966 - val_loss: 0.1484 - val_acc: 0.9346\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0383 - acc: 0.9906 - val_loss: 0.1476 - val_acc: 0.9346\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0349 - acc: 0.9953 - val_loss: 0.1446 - val_acc: 0.9346\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0303 - acc: 0.9960 - val_loss: 0.1519 - val_acc: 0.9346\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0312 - acc: 0.9960 - val_loss: 0.1453 - val_acc: 0.9346\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0282 - acc: 0.9980 - val_loss: 0.1453 - val_acc: 0.9439\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0261 - acc: 0.9973 - val_loss: 0.1496 - val_acc: 0.9346\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0240 - acc: 0.9979 - val_loss: 0.1431 - val_acc: 0.9439\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0204 - acc: 0.9993 - val_loss: 0.1421 - val_acc: 0.9439\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0213 - acc: 0.9980 - val_loss: 0.1567 - val_acc: 0.9346\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0185 - acc: 0.9993 - val_loss: 0.1414 - val_acc: 0.9439\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0176 - acc: 0.9993 - val_loss: 0.1611 - val_acc: 0.9346\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0175 - acc: 0.9987 - val_loss: 0.1439 - val_acc: 0.9439\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0146 - acc: 0.9993 - val_loss: 0.1525 - val_acc: 0.9439\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0135 - acc: 0.9993 - val_loss: 0.1483 - val_acc: 0.9439\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.1501 - val_acc: 0.9439\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.1544 - val_acc: 0.9439\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9439\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.1582 - val_acc: 0.9439\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.1516 - val_acc: 0.9346\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.9439\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.9439\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1449 - val_acc: 0.9346\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1683 - val_acc: 0.9439\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1479 - val_acc: 0.9346\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9439\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9346\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1496 - val_acc: 0.9346\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.1615 - val_acc: 0.9439\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.1696 - val_acc: 0.9439\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1527 - val_acc: 0.9346\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1644 - val_acc: 0.9439\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1710 - val_acc: 0.9439\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1605 - val_acc: 0.9439\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1649 - val_acc: 0.9439\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1678 - val_acc: 0.9439\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1684 - val_acc: 0.9439\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1691 - val_acc: 0.9439\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1658 - val_acc: 0.9439\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 0.9439\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1697 - val_acc: 0.9439\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1657 - val_acc: 0.9346\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1772 - val_acc: 0.9439\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1767 - val_acc: 0.9439\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 0.9346\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1793 - val_acc: 0.9439\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1791 - val_acc: 0.9439\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1676 - val_acc: 0.9346\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1733 - val_acc: 0.9346\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1889 - val_acc: 0.9439\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 0.9439\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1677 - val_acc: 0.9346\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1881 - val_acc: 0.9439\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1884 - val_acc: 0.9439\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1706 - val_acc: 0.9346\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 0.9346\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1914 - val_acc: 0.9439\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1864 - val_acc: 0.9439\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1769 - val_acc: 0.9346\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1831 - val_acc: 0.9439\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1897 - val_acc: 0.9439\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1886 - val_acc: 0.9439\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1813 - val_acc: 0.9346\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1836 - val_acc: 0.9346\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1932 - val_acc: 0.9439\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1912 - val_acc: 0.9439\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 9.8001e-04 - acc: 1.0000 - val_loss: 0.1814 - val_acc: 0.9346\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1852 - val_acc: 0.9346\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 9.8085e-04 - acc: 1.0000 - val_loss: 0.1939 - val_acc: 0.9439\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 9.7680e-04 - acc: 1.0000 - val_loss: 0.1897 - val_acc: 0.9439\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 9.0795e-04 - acc: 1.0000 - val_loss: 0.1880 - val_acc: 0.9346\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 8.9477e-04 - acc: 1.0000 - val_loss: 0.1864 - val_acc: 0.9346\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 8.4691e-04 - acc: 1.0000 - val_loss: 0.1981 - val_acc: 0.9439\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 8.8540e-04 - acc: 1.0000 - val_loss: 0.1940 - val_acc: 0.9439\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 8.2243e-04 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9346\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 8.2826e-04 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9346\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 8.1382e-04 - acc: 1.0000 - val_loss: 0.1942 - val_acc: 0.9439\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 8.2417e-04 - acc: 1.0000 - val_loss: 0.1967 - val_acc: 0.9439\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 8.0062e-04 - acc: 1.0000 - val_loss: 0.1953 - val_acc: 0.9439\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 7.6288e-04 - acc: 1.0000 - val_loss: 0.1944 - val_acc: 0.9439\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 7.0698e-04 - acc: 1.0000 - val_loss: 0.1967 - val_acc: 0.9439\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 7.1585e-04 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9439\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.0852e-04 - acc: 1.0000 - val_loss: 0.1979 - val_acc: 0.9439\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 6.9012e-04 - acc: 1.0000 - val_loss: 0.1934 - val_acc: 0.9346\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 6.4502e-04 - acc: 1.0000 - val_loss: 0.1957 - val_acc: 0.9346\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.3647e-04 - acc: 1.0000 - val_loss: 0.2011 - val_acc: 0.9439\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 6.3179e-04 - acc: 1.0000 - val_loss: 0.1993 - val_acc: 0.9439\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 6.2736e-04 - acc: 1.0000 - val_loss: 0.1971 - val_acc: 0.9346\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.8221e-04 - acc: 1.0000 - val_loss: 0.1992 - val_acc: 0.9439\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 6.0580e-04 - acc: 1.0000 - val_loss: 0.2023 - val_acc: 0.9439\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.8079e-04 - acc: 1.0000 - val_loss: 0.2023 - val_acc: 0.9439\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 5.3396e-04 - acc: 1.0000 - val_loss: 0.2005 - val_acc: 0.9346\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 5.6380e-04 - acc: 1.0000 - val_loss: 0.1996 - val_acc: 0.9346\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 5.4144e-04 - acc: 1.0000 - val_loss: 0.2016 - val_acc: 0.9439\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 5.5175e-04 - acc: 1.0000 - val_loss: 0.2027 - val_acc: 0.9439\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 5.0788e-04 - acc: 1.0000 - val_loss: 0.2033 - val_acc: 0.9439\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 4.9443e-04 - acc: 1.0000 - val_loss: 0.2032 - val_acc: 0.9439\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 5.0056e-04 - acc: 1.0000 - val_loss: 0.2034 - val_acc: 0.9439\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 4.8791e-04 - acc: 1.0000 - val_loss: 0.2023 - val_acc: 0.9346\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.6707e-04 - acc: 1.0000 - val_loss: 0.2023 - val_acc: 0.9346\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 4.7384e-04 - acc: 1.0000 - val_loss: 0.2057 - val_acc: 0.9439\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 4.8669e-04 - acc: 1.0000 - val_loss: 0.2056 - val_acc: 0.9439\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 4.5755e-04 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9439\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 4.3875e-04 - acc: 1.0000 - val_loss: 0.2051 - val_acc: 0.9346\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 4.3589e-04 - acc: 1.0000 - val_loss: 0.2056 - val_acc: 0.9346\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 4.2594e-04 - acc: 1.0000 - val_loss: 0.2083 - val_acc: 0.9439\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.3001e-04 - acc: 1.0000 - val_loss: 0.2069 - val_acc: 0.9346\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 4.2897e-04 - acc: 1.0000 - val_loss: 0.2058 - val_acc: 0.9346\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 3.9384e-04 - acc: 1.0000 - val_loss: 0.2066 - val_acc: 0.9346\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.9820e-04 - acc: 1.0000 - val_loss: 0.2093 - val_acc: 0.9439\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.8674e-04 - acc: 1.0000 - val_loss: 0.2105 - val_acc: 0.9439\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.9655e-04 - acc: 1.0000 - val_loss: 0.2095 - val_acc: 0.9439\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 3.7378e-04 - acc: 1.0000 - val_loss: 0.2095 - val_acc: 0.9439\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.7548e-04 - acc: 1.0000 - val_loss: 0.2094 - val_acc: 0.9346\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.5328e-04 - acc: 1.0000 - val_loss: 0.2093 - val_acc: 0.9346\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.6094e-04 - acc: 1.0000 - val_loss: 0.2089 - val_acc: 0.9346\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.6034e-04 - acc: 1.0000 - val_loss: 0.2103 - val_acc: 0.9346\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.4968e-04 - acc: 1.0000 - val_loss: 0.2103 - val_acc: 0.9346\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.4012e-04 - acc: 1.0000 - val_loss: 0.2129 - val_acc: 0.9439\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.3820e-04 - acc: 1.0000 - val_loss: 0.2131 - val_acc: 0.9439\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.4562e-04 - acc: 1.0000 - val_loss: 0.2104 - val_acc: 0.9346\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.2154e-04 - acc: 1.0000 - val_loss: 0.2115 - val_acc: 0.9346\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.3155e-04 - acc: 1.0000 - val_loss: 0.2137 - val_acc: 0.9439\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.0484e-04 - acc: 1.0000 - val_loss: 0.2155 - val_acc: 0.9439\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.1131e-04 - acc: 1.0000 - val_loss: 0.2130 - val_acc: 0.9346\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.0833e-04 - acc: 1.0000 - val_loss: 0.2119 - val_acc: 0.9346\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.0885e-04 - acc: 1.0000 - val_loss: 0.2126 - val_acc: 0.9346\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.0073e-04 - acc: 1.0000 - val_loss: 0.2139 - val_acc: 0.9346\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.9071e-04 - acc: 1.0000 - val_loss: 0.2161 - val_acc: 0.9439\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.8144e-04 - acc: 1.0000 - val_loss: 0.2179 - val_acc: 0.9439\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 3.0073e-04 - acc: 1.0000 - val_loss: 0.2148 - val_acc: 0.9346\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 2.8068e-04 - acc: 1.0000 - val_loss: 0.2146 - val_acc: 0.9346\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.7179e-04 - acc: 1.0000 - val_loss: 0.2169 - val_acc: 0.9439\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.8058e-04 - acc: 1.0000 - val_loss: 0.2179 - val_acc: 0.9439\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.5824e-04 - acc: 1.0000 - val_loss: 0.2165 - val_acc: 0.9346\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.6134e-04 - acc: 1.0000 - val_loss: 0.2161 - val_acc: 0.9346\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.5645e-04 - acc: 1.0000 - val_loss: 0.2157 - val_acc: 0.9346\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.6310e-04 - acc: 1.0000 - val_loss: 0.2165 - val_acc: 0.9346\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.4635e-04 - acc: 1.0000 - val_loss: 0.2189 - val_acc: 0.9439\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.5443e-04 - acc: 1.0000 - val_loss: 0.2187 - val_acc: 0.9346\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.4718e-04 - acc: 1.0000 - val_loss: 0.2178 - val_acc: 0.9346\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.4349e-04 - acc: 1.0000 - val_loss: 0.2196 - val_acc: 0.9439\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 2.3711e-04 - acc: 1.0000 - val_loss: 0.2197 - val_acc: 0.9439\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 2.5007e-04 - acc: 1.0000 - val_loss: 0.2200 - val_acc: 0.9439\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 2.3655e-04 - acc: 1.0000 - val_loss: 0.2212 - val_acc: 0.9439\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 2.3257e-04 - acc: 1.0000 - val_loss: 0.2203 - val_acc: 0.9346\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 2.3104e-04 - acc: 1.0000 - val_loss: 0.2193 - val_acc: 0.9346\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.2120e-04 - acc: 1.0000 - val_loss: 0.2197 - val_acc: 0.9346\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.2708e-04 - acc: 1.0000 - val_loss: 0.2207 - val_acc: 0.9346\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.1651e-04 - acc: 1.0000 - val_loss: 0.2219 - val_acc: 0.9439\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.2444e-04 - acc: 1.0000 - val_loss: 0.2207 - val_acc: 0.9346\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.1752e-04 - acc: 1.0000 - val_loss: 0.2215 - val_acc: 0.9346\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.2110e-04 - acc: 1.0000 - val_loss: 0.2233 - val_acc: 0.9439\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.0054e-04 - acc: 1.0000 - val_loss: 0.2223 - val_acc: 0.9346\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.1084e-04 - acc: 1.0000 - val_loss: 0.2210 - val_acc: 0.9346\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.0193e-04 - acc: 1.0000 - val_loss: 0.2224 - val_acc: 0.9346\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.0906e-04 - acc: 1.0000 - val_loss: 0.2238 - val_acc: 0.9346\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.9947e-04 - acc: 1.0000 - val_loss: 0.2250 - val_acc: 0.9439\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.0680e-04 - acc: 1.0000 - val_loss: 0.2230 - val_acc: 0.9346\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.0000e-04 - acc: 1.0000 - val_loss: 0.2244 - val_acc: 0.9346\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.8938e-04 - acc: 1.0000 - val_loss: 0.2247 - val_acc: 0.9346\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.8819e-04 - acc: 1.0000 - val_loss: 0.2245 - val_acc: 0.9346\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.9016e-04 - acc: 1.0000 - val_loss: 0.2241 - val_acc: 0.9346\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.9060e-04 - acc: 1.0000 - val_loss: 0.2257 - val_acc: 0.9346\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.8487e-04 - acc: 1.0000 - val_loss: 0.2267 - val_acc: 0.9439\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.8866e-04 - acc: 1.0000 - val_loss: 0.2247 - val_acc: 0.9346\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.8121e-04 - acc: 1.0000 - val_loss: 0.2250 - val_acc: 0.9346\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.7809e-04 - acc: 1.0000 - val_loss: 0.2259 - val_acc: 0.9346\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.6986e-04 - acc: 1.0000 - val_loss: 0.2272 - val_acc: 0.9346\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.7385e-04 - acc: 1.0000 - val_loss: 0.2267 - val_acc: 0.9346\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 1.7873e-04 - acc: 1.0000 - val_loss: 0.2255 - val_acc: 0.9346\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.6332e-04 - acc: 1.0000 - val_loss: 0.2255 - val_acc: 0.9346\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.6977e-04 - acc: 1.0000 - val_loss: 0.2269 - val_acc: 0.9346\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.6948e-04 - acc: 1.0000 - val_loss: 0.2287 - val_acc: 0.9439\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.6118e-04 - acc: 1.0000 - val_loss: 0.2289 - val_acc: 0.9439\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.5995e-04 - acc: 1.0000 - val_loss: 0.2274 - val_acc: 0.9346\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.6079e-04 - acc: 1.0000 - val_loss: 0.2263 - val_acc: 0.9346\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.5507e-04 - acc: 1.0000 - val_loss: 0.2270 - val_acc: 0.9346\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.5612e-04 - acc: 1.0000 - val_loss: 0.2295 - val_acc: 0.9346\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.5733e-04 - acc: 1.0000 - val_loss: 0.2312 - val_acc: 0.9439\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.5300e-04 - acc: 1.0000 - val_loss: 0.2310 - val_acc: 0.9439\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.5311e-04 - acc: 1.0000 - val_loss: 0.2277 - val_acc: 0.9346\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 1.4804e-04 - acc: 1.0000 - val_loss: 0.2277 - val_acc: 0.9346\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.4417e-04 - acc: 1.0000 - val_loss: 0.2301 - val_acc: 0.9346\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.3887e-04 - acc: 1.0000 - val_loss: 0.2316 - val_acc: 0.9439\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.4312e-04 - acc: 1.0000 - val_loss: 0.2317 - val_acc: 0.9346\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.3691e-04 - acc: 1.0000 - val_loss: 0.2305 - val_acc: 0.9346\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 1.4119e-04 - acc: 1.0000 - val_loss: 0.2301 - val_acc: 0.9346\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.4013e-04 - acc: 1.0000 - val_loss: 0.2289 - val_acc: 0.9346\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.3489e-04 - acc: 1.0000 - val_loss: 0.2320 - val_acc: 0.9346\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.3576e-04 - acc: 1.0000 - val_loss: 0.2329 - val_acc: 0.9346\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.3420e-04 - acc: 1.0000 - val_loss: 0.2333 - val_acc: 0.9439\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.3682e-04 - acc: 1.0000 - val_loss: 0.2317 - val_acc: 0.9346\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.3414e-04 - acc: 1.0000 - val_loss: 0.2306 - val_acc: 0.9346\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.3283e-04 - acc: 1.0000 - val_loss: 0.2311 - val_acc: 0.9346\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.2802e-04 - acc: 1.0000 - val_loss: 0.2325 - val_acc: 0.9346\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.3108e-04 - acc: 1.0000 - val_loss: 0.2343 - val_acc: 0.9346\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.2900e-04 - acc: 1.0000 - val_loss: 0.2340 - val_acc: 0.9346\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.2953e-04 - acc: 1.0000 - val_loss: 0.2329 - val_acc: 0.9346\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.3079e-04 - acc: 1.0000 - val_loss: 0.2332 - val_acc: 0.9346\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.2492e-04 - acc: 1.0000 - val_loss: 0.2333 - val_acc: 0.9346\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.2851e-04 - acc: 1.0000 - val_loss: 0.2342 - val_acc: 0.9346\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.2165e-04 - acc: 1.0000 - val_loss: 0.2360 - val_acc: 0.9439\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 1.1998e-04 - acc: 1.0000 - val_loss: 0.2350 - val_acc: 0.9346\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.1981e-04 - acc: 1.0000 - val_loss: 0.2328 - val_acc: 0.9346\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2416e-04 - acc: 1.0000 - val_loss: 0.2332 - val_acc: 0.9346\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.1986e-04 - acc: 1.0000 - val_loss: 0.2351 - val_acc: 0.9346\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 1.1801e-04 - acc: 1.0000 - val_loss: 0.2370 - val_acc: 0.9439\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.1896e-04 - acc: 1.0000 - val_loss: 0.2372 - val_acc: 0.9439\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.1283e-04 - acc: 1.0000 - val_loss: 0.2364 - val_acc: 0.9346\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.1230e-04 - acc: 1.0000 - val_loss: 0.2346 - val_acc: 0.9346\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.1612e-04 - acc: 1.0000 - val_loss: 0.2341 - val_acc: 0.9346\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.1161e-04 - acc: 1.0000 - val_loss: 0.2354 - val_acc: 0.9346\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.0995e-04 - acc: 1.0000 - val_loss: 0.2373 - val_acc: 0.9346\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.0818e-04 - acc: 1.0000 - val_loss: 0.2383 - val_acc: 0.9346\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.1579e-04 - acc: 1.0000 - val_loss: 0.2379 - val_acc: 0.9346\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.0792e-04 - acc: 1.0000 - val_loss: 0.2365 - val_acc: 0.9346\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 1.0799e-04 - acc: 1.0000 - val_loss: 0.2359 - val_acc: 0.9346\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.0987e-04 - acc: 1.0000 - val_loss: 0.2362 - val_acc: 0.9346\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.0576e-04 - acc: 1.0000 - val_loss: 0.2387 - val_acc: 0.9346\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.0373e-04 - acc: 1.0000 - val_loss: 0.2406 - val_acc: 0.9439\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.0435e-04 - acc: 1.0000 - val_loss: 0.2396 - val_acc: 0.9346\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 9.8743e-05 - acc: 1.0000 - val_loss: 0.2380 - val_acc: 0.9346\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.0478e-04 - acc: 1.0000 - val_loss: 0.2361 - val_acc: 0.9346\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 9.7129e-05 - acc: 1.0000 - val_loss: 0.2365 - val_acc: 0.9346\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.0226e-04 - acc: 1.0000 - val_loss: 0.2376 - val_acc: 0.9346\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.0068e-04 - acc: 1.0000 - val_loss: 0.2400 - val_acc: 0.9346\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 9.6965e-05 - acc: 1.0000 - val_loss: 0.2415 - val_acc: 0.9439\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 9.6493e-05 - acc: 1.0000 - val_loss: 0.2415 - val_acc: 0.9439\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 9.7095e-05 - acc: 1.0000 - val_loss: 0.2393 - val_acc: 0.9346\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 9.9192e-05 - acc: 1.0000 - val_loss: 0.2373 - val_acc: 0.9346\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 9.7301e-05 - acc: 1.0000 - val_loss: 0.2391 - val_acc: 0.9346\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 9.1791e-05 - acc: 1.0000 - val_loss: 0.2406 - val_acc: 0.9346\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 9.1168e-05 - acc: 1.0000 - val_loss: 0.2422 - val_acc: 0.9346\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 9.4044e-05 - acc: 1.0000 - val_loss: 0.2422 - val_acc: 0.9346\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 9.4024e-05 - acc: 1.0000 - val_loss: 0.2409 - val_acc: 0.9346\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 9.4702e-05 - acc: 1.0000 - val_loss: 0.2399 - val_acc: 0.9346\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 8.7873e-05 - acc: 1.0000 - val_loss: 0.2406 - val_acc: 0.9346\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.8777e-05 - acc: 1.0000 - val_loss: 0.2416 - val_acc: 0.9346\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.9107e-05 - acc: 1.0000 - val_loss: 0.2417 - val_acc: 0.9346\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 8.4931e-05 - acc: 1.0000 - val_loss: 0.2427 - val_acc: 0.9346\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.9948e-05 - acc: 1.0000 - val_loss: 0.2439 - val_acc: 0.9346\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 8.9642e-05 - acc: 1.0000 - val_loss: 0.2429 - val_acc: 0.9346\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 8.8617e-05 - acc: 1.0000 - val_loss: 0.2408 - val_acc: 0.9346\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 8.6698e-05 - acc: 1.0000 - val_loss: 0.2417 - val_acc: 0.9346\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 8.6799e-05 - acc: 1.0000 - val_loss: 0.2431 - val_acc: 0.9346\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 8.5989e-05 - acc: 1.0000 - val_loss: 0.2439 - val_acc: 0.9346\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 8.2662e-05 - acc: 1.0000 - val_loss: 0.2440 - val_acc: 0.9346\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.1782e-05 - acc: 1.0000 - val_loss: 0.2437 - val_acc: 0.9346\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 8.4219e-05 - acc: 1.0000 - val_loss: 0.2426 - val_acc: 0.9346\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 8.3283e-05 - acc: 1.0000 - val_loss: 0.2432 - val_acc: 0.9346\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.2099e-05 - acc: 1.0000 - val_loss: 0.2436 - val_acc: 0.9346\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 8.1322e-05 - acc: 1.0000 - val_loss: 0.2448 - val_acc: 0.9346\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 7.9381e-05 - acc: 1.0000 - val_loss: 0.2455 - val_acc: 0.9346\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 7.9524e-05 - acc: 1.0000 - val_loss: 0.2446 - val_acc: 0.9346\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 8.1032e-05 - acc: 1.0000 - val_loss: 0.2431 - val_acc: 0.9346\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.6290e-05 - acc: 1.0000 - val_loss: 0.2430 - val_acc: 0.9346\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 7.4813e-05 - acc: 1.0000 - val_loss: 0.2446 - val_acc: 0.9346\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 7.8519e-05 - acc: 1.0000 - val_loss: 0.2458 - val_acc: 0.9346\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 7.6207e-05 - acc: 1.0000 - val_loss: 0.2463 - val_acc: 0.9346\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 7.2963e-05 - acc: 1.0000 - val_loss: 0.2457 - val_acc: 0.9346\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 7.4967e-05 - acc: 1.0000 - val_loss: 0.2446 - val_acc: 0.9346\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 7.2927e-05 - acc: 1.0000 - val_loss: 0.2450 - val_acc: 0.9346\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 7.7012e-05 - acc: 1.0000 - val_loss: 0.2452 - val_acc: 0.9346\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 7.3474e-05 - acc: 1.0000 - val_loss: 0.2463 - val_acc: 0.9346\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 7.1617e-05 - acc: 1.0000 - val_loss: 0.2477 - val_acc: 0.9346\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 7.2147e-05 - acc: 1.0000 - val_loss: 0.2474 - val_acc: 0.9346\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.4654e-05 - acc: 1.0000 - val_loss: 0.2460 - val_acc: 0.9346\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 7.1582e-05 - acc: 1.0000 - val_loss: 0.2453 - val_acc: 0.9346\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 7.1579e-05 - acc: 1.0000 - val_loss: 0.2459 - val_acc: 0.9346\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 7.0339e-05 - acc: 1.0000 - val_loss: 0.2472 - val_acc: 0.9346\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.8220e-05 - acc: 1.0000 - val_loss: 0.2478 - val_acc: 0.9346\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 6.7412e-05 - acc: 1.0000 - val_loss: 0.2486 - val_acc: 0.9346\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 6.8141e-05 - acc: 1.0000 - val_loss: 0.2481 - val_acc: 0.9346\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 6.8264e-05 - acc: 1.0000 - val_loss: 0.2476 - val_acc: 0.9346\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 6.6589e-05 - acc: 1.0000 - val_loss: 0.2476 - val_acc: 0.9346\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.9474e-05 - acc: 1.0000 - val_loss: 0.2470 - val_acc: 0.9346\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.4880e-05 - acc: 1.0000 - val_loss: 0.2480 - val_acc: 0.9346\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 6.4109e-05 - acc: 1.0000 - val_loss: 0.2490 - val_acc: 0.9346\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.2852e-05 - acc: 1.0000 - val_loss: 0.2492 - val_acc: 0.9346\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.7765e-05 - acc: 1.0000 - val_loss: 0.2485 - val_acc: 0.9346\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.3236e-05 - acc: 1.0000 - val_loss: 0.2481 - val_acc: 0.9346\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 6.2740e-05 - acc: 1.0000 - val_loss: 0.2487 - val_acc: 0.9346\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.7612e-05 - acc: 1.0000 - val_loss: 0.2491 - val_acc: 0.9346\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.8634e-05 - acc: 1.0000 - val_loss: 0.2498 - val_acc: 0.9346\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.6302e-05 - acc: 1.0000 - val_loss: 0.2500 - val_acc: 0.9346\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.0468e-05 - acc: 1.0000 - val_loss: 0.2504 - val_acc: 0.9346\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.2621e-05 - acc: 1.0000 - val_loss: 0.2499 - val_acc: 0.9346\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 5.9762e-05 - acc: 1.0000 - val_loss: 0.2502 - val_acc: 0.9346\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.4864e-05 - acc: 1.0000 - val_loss: 0.2498 - val_acc: 0.9346\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 5.8301e-05 - acc: 1.0000 - val_loss: 0.2501 - val_acc: 0.9346\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 5.7664e-05 - acc: 1.0000 - val_loss: 0.2505 - val_acc: 0.9346\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 5.9452e-05 - acc: 1.0000 - val_loss: 0.2510 - val_acc: 0.9346\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 6.2112e-05 - acc: 1.0000 - val_loss: 0.2511 - val_acc: 0.9346\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 6.1314e-05 - acc: 1.0000 - val_loss: 0.2517 - val_acc: 0.9346\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 5.8269e-05 - acc: 1.0000 - val_loss: 0.2515 - val_acc: 0.9346\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 5.7781e-05 - acc: 1.0000 - val_loss: 0.2514 - val_acc: 0.9346\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 5.6570e-05 - acc: 1.0000 - val_loss: 0.2515 - val_acc: 0.9346\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 5.8292e-05 - acc: 1.0000 - val_loss: 0.2510 - val_acc: 0.9346\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 5.7490e-05 - acc: 1.0000 - val_loss: 0.2516 - val_acc: 0.9346\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 5.4841e-05 - acc: 1.0000 - val_loss: 0.2522 - val_acc: 0.9346\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 5.6485e-05 - acc: 1.0000 - val_loss: 0.2530 - val_acc: 0.9346\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 5.7991e-05 - acc: 1.0000 - val_loss: 0.2531 - val_acc: 0.9346\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 5.6810e-05 - acc: 1.0000 - val_loss: 0.2527 - val_acc: 0.9346\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 5.9429e-05 - acc: 1.0000 - val_loss: 0.2516 - val_acc: 0.9346\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 5.6107e-05 - acc: 1.0000 - val_loss: 0.2517 - val_acc: 0.9346\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.6441e-05 - acc: 1.0000 - val_loss: 0.2529 - val_acc: 0.9346\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 5.5946e-05 - acc: 1.0000 - val_loss: 0.2541 - val_acc: 0.9346\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 5.3247e-05 - acc: 1.0000 - val_loss: 0.2552 - val_acc: 0.9346\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.2104e-05 - acc: 1.0000 - val_loss: 0.2543 - val_acc: 0.9346\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 5.2989e-05 - acc: 1.0000 - val_loss: 0.2534 - val_acc: 0.9346\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.2218e-05 - acc: 1.0000 - val_loss: 0.2524 - val_acc: 0.9346\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 5.3664e-05 - acc: 1.0000 - val_loss: 0.2524 - val_acc: 0.9346\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 5.2984e-05 - acc: 1.0000 - val_loss: 0.2527 - val_acc: 0.9346\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 5.2370e-05 - acc: 1.0000 - val_loss: 0.2534 - val_acc: 0.9346\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 5.1257e-05 - acc: 1.0000 - val_loss: 0.2546 - val_acc: 0.9346\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.0916e-05 - acc: 1.0000 - val_loss: 0.2556 - val_acc: 0.9346\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 5.0160e-05 - acc: 1.0000 - val_loss: 0.2557 - val_acc: 0.9346\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 5.3458e-05 - acc: 1.0000 - val_loss: 0.2544 - val_acc: 0.9346\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 4.9605e-05 - acc: 1.0000 - val_loss: 0.2537 - val_acc: 0.9346\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 5.0398e-05 - acc: 1.0000 - val_loss: 0.2545 - val_acc: 0.9346\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 4.8153e-05 - acc: 1.0000 - val_loss: 0.2553 - val_acc: 0.9346\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 4.9041e-05 - acc: 1.0000 - val_loss: 0.2559 - val_acc: 0.9346\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 5.1793e-05 - acc: 1.0000 - val_loss: 0.2558 - val_acc: 0.9346\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 4.7169e-05 - acc: 1.0000 - val_loss: 0.2563 - val_acc: 0.9346\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.8036e-05 - acc: 1.0000 - val_loss: 0.2559 - val_acc: 0.9346\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 4.7168e-05 - acc: 1.0000 - val_loss: 0.2554 - val_acc: 0.9346\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 4.9365e-05 - acc: 1.0000 - val_loss: 0.2552 - val_acc: 0.9346\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 4.7094e-05 - acc: 1.0000 - val_loss: 0.2556 - val_acc: 0.9346\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 4.9233e-05 - acc: 1.0000 - val_loss: 0.2557 - val_acc: 0.9346\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 4.6899e-05 - acc: 1.0000 - val_loss: 0.2562 - val_acc: 0.9346\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.6267e-05 - acc: 1.0000 - val_loss: 0.2563 - val_acc: 0.9346\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.6927e-05 - acc: 1.0000 - val_loss: 0.2570 - val_acc: 0.9346\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.5891e-05 - acc: 1.0000 - val_loss: 0.2572 - val_acc: 0.9346\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 4.6137e-05 - acc: 1.0000 - val_loss: 0.2579 - val_acc: 0.9346\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.6050e-05 - acc: 1.0000 - val_loss: 0.2574 - val_acc: 0.9346\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.4336e-05 - acc: 1.0000 - val_loss: 0.2569 - val_acc: 0.9346\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 4.5059e-05 - acc: 1.0000 - val_loss: 0.2570 - val_acc: 0.9346\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 4.6288e-05 - acc: 1.0000 - val_loss: 0.2571 - val_acc: 0.9346\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.5754e-05 - acc: 1.0000 - val_loss: 0.2575 - val_acc: 0.9346\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 4.5075e-05 - acc: 1.0000 - val_loss: 0.2578 - val_acc: 0.9346\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 4.5393e-05 - acc: 1.0000 - val_loss: 0.2581 - val_acc: 0.9346\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 4.4877e-05 - acc: 1.0000 - val_loss: 0.2584 - val_acc: 0.9346\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 4.5658e-05 - acc: 1.0000 - val_loss: 0.2583 - val_acc: 0.9346\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.4059e-05 - acc: 1.0000 - val_loss: 0.2586 - val_acc: 0.9346\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.3478e-05 - acc: 1.0000 - val_loss: 0.2586 - val_acc: 0.9346\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 186ms/step - loss: 4.2893e-05 - acc: 1.0000 - val_loss: 0.2591 - val_acc: 0.9346\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.2928e-05 - acc: 1.0000 - val_loss: 0.2590 - val_acc: 0.9346\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.2946e-05 - acc: 1.0000 - val_loss: 0.2588 - val_acc: 0.9346\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.2121e-05 - acc: 1.0000 - val_loss: 0.2585 - val_acc: 0.9346\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 4.2861e-05 - acc: 1.0000 - val_loss: 0.2593 - val_acc: 0.9346\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 4.1646e-05 - acc: 1.0000 - val_loss: 0.2597 - val_acc: 0.9346\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.2016e-05 - acc: 1.0000 - val_loss: 0.2597 - val_acc: 0.9346\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.9955e-05 - acc: 1.0000 - val_loss: 0.2588 - val_acc: 0.9346\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 4.0657e-05 - acc: 1.0000 - val_loss: 0.2593 - val_acc: 0.9346\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.1784e-05 - acc: 1.0000 - val_loss: 0.2595 - val_acc: 0.9346\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 4.2311e-05 - acc: 1.0000 - val_loss: 0.2596 - val_acc: 0.9346\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.9938e-05 - acc: 1.0000 - val_loss: 0.2598 - val_acc: 0.9346\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.8773e-05 - acc: 1.0000 - val_loss: 0.2604 - val_acc: 0.9346\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 187ms/step - loss: 4.0503e-05 - acc: 1.0000 - val_loss: 0.2611 - val_acc: 0.9346\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 4.1346e-05 - acc: 1.0000 - val_loss: 0.2608 - val_acc: 0.9346\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.9685e-05 - acc: 1.0000 - val_loss: 0.2610 - val_acc: 0.9346\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.7569e-05 - acc: 1.0000 - val_loss: 0.2605 - val_acc: 0.9346\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.8679e-05 - acc: 1.0000 - val_loss: 0.2606 - val_acc: 0.9346\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.0951e-05 - acc: 1.0000 - val_loss: 0.2609 - val_acc: 0.9346\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 3.7225e-05 - acc: 1.0000 - val_loss: 0.2613 - val_acc: 0.9346\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 3.7777e-05 - acc: 1.0000 - val_loss: 0.2615 - val_acc: 0.9346\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.7530e-05 - acc: 1.0000 - val_loss: 0.2615 - val_acc: 0.9346\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.7060e-05 - acc: 1.0000 - val_loss: 0.2614 - val_acc: 0.9346\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.7503e-05 - acc: 1.0000 - val_loss: 0.2611 - val_acc: 0.9346\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.3185e-05 - acc: 1.0000 - val_loss: 0.2612 - val_acc: 0.9346\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.8308e-05 - acc: 1.0000 - val_loss: 0.2613 - val_acc: 0.9346\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.7894e-05 - acc: 1.0000 - val_loss: 0.2617 - val_acc: 0.9346\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.6791e-05 - acc: 1.0000 - val_loss: 0.2619 - val_acc: 0.9346\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 3.6139e-05 - acc: 1.0000 - val_loss: 0.2625 - val_acc: 0.9346\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.6429e-05 - acc: 1.0000 - val_loss: 0.2631 - val_acc: 0.9346\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.5548e-05 - acc: 1.0000 - val_loss: 0.2625 - val_acc: 0.9346\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.4491e-05 - acc: 1.0000 - val_loss: 0.2629 - val_acc: 0.9346\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.4725e-05 - acc: 1.0000 - val_loss: 0.2627 - val_acc: 0.9346\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 3.4935e-05 - acc: 1.0000 - val_loss: 0.2626 - val_acc: 0.9346\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.5928e-05 - acc: 1.0000 - val_loss: 0.2629 - val_acc: 0.9346\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.4422e-05 - acc: 1.0000 - val_loss: 0.2633 - val_acc: 0.9346\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.4485e-05 - acc: 1.0000 - val_loss: 0.2632 - val_acc: 0.9346\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.4876e-05 - acc: 1.0000 - val_loss: 0.2635 - val_acc: 0.9346\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.3992e-05 - acc: 1.0000 - val_loss: 0.2637 - val_acc: 0.9346\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.6053e-05 - acc: 1.0000 - val_loss: 0.2632 - val_acc: 0.9346\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.6330e-05 - acc: 1.0000 - val_loss: 0.2633 - val_acc: 0.9346\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.3910e-05 - acc: 1.0000 - val_loss: 0.2634 - val_acc: 0.9346\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.4681e-05 - acc: 1.0000 - val_loss: 0.2639 - val_acc: 0.9346\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.2735e-05 - acc: 1.0000 - val_loss: 0.2649 - val_acc: 0.9346\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.4109e-05 - acc: 1.0000 - val_loss: 0.2647 - val_acc: 0.9346\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.3824e-05 - acc: 1.0000 - val_loss: 0.2654 - val_acc: 0.9346\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.3767e-05 - acc: 1.0000 - val_loss: 0.2650 - val_acc: 0.9346\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.3609e-05 - acc: 1.0000 - val_loss: 0.2646 - val_acc: 0.9346\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.4184e-05 - acc: 1.0000 - val_loss: 0.2637 - val_acc: 0.9346\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.2728e-05 - acc: 1.0000 - val_loss: 0.2639 - val_acc: 0.9346\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.3597e-05 - acc: 1.0000 - val_loss: 0.2650 - val_acc: 0.9346\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 3.1629e-05 - acc: 1.0000 - val_loss: 0.2658 - val_acc: 0.9346\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.2942e-05 - acc: 1.0000 - val_loss: 0.2659 - val_acc: 0.9346\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.1743e-05 - acc: 1.0000 - val_loss: 0.2658 - val_acc: 0.9346\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.1483e-05 - acc: 1.0000 - val_loss: 0.2658 - val_acc: 0.9346\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.2219e-05 - acc: 1.0000 - val_loss: 0.2657 - val_acc: 0.9346\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 3.0329e-05 - acc: 1.0000 - val_loss: 0.2657 - val_acc: 0.9346\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.2063e-05 - acc: 1.0000 - val_loss: 0.2655 - val_acc: 0.9346\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.1919e-05 - acc: 1.0000 - val_loss: 0.2657 - val_acc: 0.9346\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.2801e-05 - acc: 1.0000 - val_loss: 0.2658 - val_acc: 0.9346\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.0140e-05 - acc: 1.0000 - val_loss: 0.2667 - val_acc: 0.9346\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.0932e-05 - acc: 1.0000 - val_loss: 0.2667 - val_acc: 0.9346\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.0586e-05 - acc: 1.0000 - val_loss: 0.2668 - val_acc: 0.9346\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.0931e-05 - acc: 1.0000 - val_loss: 0.2671 - val_acc: 0.9346\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.0730e-05 - acc: 1.0000 - val_loss: 0.2670 - val_acc: 0.9346\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 2.8060e-05 - acc: 1.0000 - val_loss: 0.2671 - val_acc: 0.9346\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 2.9458e-05 - acc: 1.0000 - val_loss: 0.2667 - val_acc: 0.9346\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.9330e-05 - acc: 1.0000 - val_loss: 0.2668 - val_acc: 0.9346\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 2.9946e-05 - acc: 1.0000 - val_loss: 0.2671 - val_acc: 0.9346\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 3.0082e-05 - acc: 1.0000 - val_loss: 0.2669 - val_acc: 0.9346\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.0311e-05 - acc: 1.0000 - val_loss: 0.2668 - val_acc: 0.9346\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.0209e-05 - acc: 1.0000 - val_loss: 0.2669 - val_acc: 0.9346\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 2.7911e-05 - acc: 1.0000 - val_loss: 0.2680 - val_acc: 0.9346\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.7096e-05 - acc: 1.0000 - val_loss: 0.2691 - val_acc: 0.9346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qzK4SJB5y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "c9f01096-058a-410f-bfbf-1499540fad02"
      },
      "source": [
        "plt.figure(figsize =(5,3))\n",
        "plt.plot(history.history['acc'], marker='.', label='tune')\n",
        "plt.plot(history.history['val_acc'], marker='.', label='test')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGBi22ZGy38"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
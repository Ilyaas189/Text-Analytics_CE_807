{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA Model_DS_30_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ilyaas189/Text-Analytics_CE_807/blob/main/LDA_Model_DS_30_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "h48neXM-ANwE",
        "outputId": "92a3089b-5901-4386-8b96-25b59e4e6e2a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from google.colab import files\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import random\n",
        "uploaded = files.upload()\n",
        "files = list(uploaded.keys())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-469e8729-7bd3-45b5-b5f1-8d629b4b3576\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-469e8729-7bd3-45b5-b5f1-8d629b4b3576\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcrJU_pzAhOm",
        "outputId": "ec4e5544-6aa3-4c0f-9c7a-677ea17da3b2"
      },
      "source": [
        "# Import Dataset\n",
        "data = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "print(data.target_names.unique())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
            " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
            " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
            " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
            " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
            " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "SnGiNUYGAtLQ",
        "outputId": "fdb179fb-c516-45c7-aebd-278307e2d2b5"
      },
      "source": [
        "data.head(20)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
              "      <td>16</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
              "      <td>13</td>\n",
              "      <td>sci.med</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
              "      <td>3</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
              "      <td>8</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>From: david@terminus.ericsson.se (David Bold)\\...</td>\n",
              "      <td>19</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>From: dbm0000@tm0006.lerc.nasa.gov (David B. M...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...</td>\n",
              "      <td>6</td>\n",
              "      <td>misc.forsale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...</td>\n",
              "      <td>12</td>\n",
              "      <td>sci.electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>From: abarden@tybse1.uucp (Ann Marie Barden)\\n...</td>\n",
              "      <td>5</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              content  ...              target_names\n",
              "0   From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...                 rec.autos\n",
              "1   From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...     comp.sys.mac.hardware\n",
              "2   From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...     comp.sys.mac.hardware\n",
              "3   From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...             comp.graphics\n",
              "4   From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...                 sci.space\n",
              "5   From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...  ...        talk.politics.guns\n",
              "6   From: bmdelane@quads.uchicago.edu (brian manni...  ...                   sci.med\n",
              "7   From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...  ...  comp.sys.ibm.pc.hardware\n",
              "8   From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...  ...   comp.os.ms-windows.misc\n",
              "9   From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...  ...     comp.sys.mac.hardware\n",
              "10  From: irwin@cmptrc.lonestar.org (Irwin Arnstei...  ...           rec.motorcycles\n",
              "11  From: david@terminus.ericsson.se (David Bold)\\...  ...        talk.religion.misc\n",
              "12  From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...  ...     comp.sys.mac.hardware\n",
              "13  From: dbm0000@tm0006.lerc.nasa.gov (David B. M...  ...                 sci.space\n",
              "14  From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...  ...              misc.forsale\n",
              "15  From: mathew <mathew@mantis.co.uk>\\nSubject: R...  ...               alt.atheism\n",
              "16  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...  ...             comp.graphics\n",
              "17  From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...  ...                 rec.autos\n",
              "18  From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...  ...           sci.electronics\n",
              "19  From: abarden@tybse1.uucp (Ann Marie Barden)\\n...  ...            comp.windows.x\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1t4Hd65BKo4",
        "outputId": "94c5cb6c-d8c7-459c-983a-f5d056d3c2ca"
      },
      "source": [
        "data_clusterization = data[['content', 'target_names']]\n",
        "data_clusterization.dropna(inplace=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "0xRJ8_03Bd1W",
        "outputId": "ebeaa8a4-e8ce-4141-92b4-d83dac3e72ff"
      },
      "source": [
        "data_clusterization.head(2)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content           target_names\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...              rec.autos\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  comp.sys.mac.hardware"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iUh1DoLBmXP",
        "outputId": "ba875e0a-ac12-47c8-e052-563b999fdb5c"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7hwfWd1Bw8S"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        " stemmer = SnowballStemmer(language='english')\n",
        " return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        " result = []\n",
        " for token in gensim.utils.simple_preprocess(text):\n",
        "   if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "     result.append(lemmatize_stemming(token))\n",
        " return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJfVX8biB_Sa"
      },
      "source": [
        "processed_docs = data_clusterization['content'].map(preprocess)\n",
        "data_processed = processed_docs.to_frame()\n",
        "data_processed['content'] = data_processed.content.apply(lambda x: ' '.join(x))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCHPTBYJClMy",
        "outputId": "c20df622-b43c-450c-c9d8-6ef18286ccea"
      },
      "source": [
        "!pip install tokenize_uk\n",
        "from collections import Counter\n",
        "from tokenize_uk.tokenize_uk import tokenize_words"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenize_uk\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/21/72abb0304b532e1b2d2473b50d8063ddd0943e3b3fe7e86b366bc4d02aa2/tokenize_uk-0.2.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tokenize_uk) (1.15.0)\n",
            "Building wheels for collected packages: tokenize-uk\n",
            "  Building wheel for tokenize-uk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tokenize-uk: filename=tokenize_uk-0.2.0-py2.py3-none-any.whl size=4565 sha256=22cec5de46845e657420717eada68b50e6c42ee5af88967d20ab444c6e8040c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/e1/95/fd8af5b40aeebdc4e178974e7f638f5553aa8772117054db9e\n",
            "Successfully built tokenize-uk\n",
            "Installing collected packages: tokenize-uk\n",
            "Successfully installed tokenize-uk-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "94mq8WUoCqHq",
        "outputId": "0a11e952-2844-4bb2-bef6-36d144e2fec6"
      },
      "source": [
        "def display_words(data, title, ax):\n",
        " count = Counter(sum(map(lambda text: tokenize_words(text), data), []))\n",
        " popular = np.array(sorted(count.items(), key=lambda x: x[1], reverse=True)[:20])\n",
        " plt.sca(ax)\n",
        " plt.title(title)\n",
        " plt.bar(popular[:,0], np.int32(popular[:,1]))\n",
        " plt.xticks(rotation=\"vertical\")\n",
        "fig, ax = plt.subplots(figsize=(16, 5))\n",
        "display_words(data_processed.sample(1000).content, \"The most popular words]\", ax)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCM4qevNC5Ty"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMnRgz3aC8f5",
        "outputId": "8ac99be8-6a76-474f-c5ea-2e39954ae341"
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "count_data = count_vectorizer.fit_transform(data_processed['content'])\n",
        "count_data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11314x61410 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 934270 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TmSX73jDEJS"
      },
      "source": [
        "likelihood = []\n",
        "n_clusters = []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9uTcUJlDHT0"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hki6oWR0DLwb"
      },
      "source": [
        "def estimate_number_clusters(data, nclusters):\n",
        " for n in nclusters:\n",
        "   likelihood.append(LDA(n_components=n, n_jobs=-1).fit(data).score(data))\n",
        " n_clusters.append(n)\n",
        " print(\"Sccesfully estimated \", n)\n",
        " fig, ax = plt.subplots(figsize=(15, 5))\n",
        " sns.lineplot(x=n_clusters, y=likelihood, ax=ax)\n",
        " ax.set_title('Elbow method for choosing n, likelihood')\n",
        " ax.set_ylabel('Likelihood')\n",
        " ax.set_xlabel('n')\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CBG_y1fJszZ"
      },
      "source": [
        "# estimate_number_clusters(count_data, [10, 15, 20, 50])\n",
        " \n",
        " "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XNMixjQJuYE"
      },
      "source": [
        "def print_topics(model, count_vectorizer, n_top_words):\n",
        "  words = count_vectorizer.get_feature_names()\n",
        "  for topic_idx, topic in enumerate(model.components_):\n",
        "    print(\"\\nTopic #%d:\" % topic_idx)\n",
        "    print(\" \".join([words[i]\n",
        "  for i in topic.argsort()[:-n_top_words - 1:-1]]))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugizp_hhFpzm"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWtTkYX1Ftia",
        "outputId": "bbcf0801-8778-4c0e-88cc-f4db69211ef5"
      },
      "source": [
        "number_topics = 30\n",
        "number_words = 10\n",
        "# Create and fit the LDA model\n",
        "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
        "lda.fit(count_data)\n",
        "# Print the topics found by the LDA model\n",
        "print(\"Topics found via LDA:\")\n",
        "print_topics(lda, count_vectorizer, number_words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topics found via LDA:\n",
            "\n",
            "Topic #0:\n",
            "card driver line subject organ video write mode post work\n",
            "\n",
            "Topic #1:\n",
            "write moral subject line organ think articl object post caltech\n",
            "\n",
            "Topic #2:\n",
            "organ line write subject pitt articl bank gordon post nntp\n",
            "\n",
            "Topic #3:\n",
            "access digex subject line organ post write nntp host insur\n",
            "\n",
            "Topic #4:\n",
            "line organ subject henri toronto post radar write detector netcom\n",
            "\n",
            "Topic #5:\n",
            "line subject organ know work problem drive write scsi appl\n",
            "\n",
            "Topic #6:\n",
            "game team year player line play think organ subject season\n",
            "\n",
            "Topic #7:\n",
            "line subject organ sale univers post host nntp columbia mail\n",
            "\n",
            "Topic #8:\n",
            "ohio cleveland cwru state subject organ line articl freenet write\n",
            "\n",
            "Topic #9:\n",
            "line subject organ like write bike articl drive good look\n",
            "\n",
            "Topic #10:\n",
            "organ subject line post articl write nntp david host know\n",
            "\n",
            "Topic #11:\n",
            "write know believ subject line bibl say think organ truth\n",
            "\n",
            "Topic #12:\n",
            "church cathol time pope american european organ south like think\n",
            "\n",
            "Topic #13:\n",
            "jpeg line subject imag organ post mark write articl berkeley\n",
            "\n",
            "Topic #14:\n",
            "encrypt chip secur clipper file key entri govern line escrow\n",
            "\n",
            "Topic #15:\n",
            "window line subject organ host mous problem univers font post\n",
            "\n",
            "Topic #16:\n",
            "israel isra say peopl arab jew know go think come\n",
            "\n",
            "Topic #17:\n",
            "widget line colormap valu visual color subject point applic organ\n",
            "\n",
            "Topic #18:\n",
            "exist question peopl reason think subject organ mean argument evid\n",
            "\n",
            "Topic #19:\n",
            "space nasa orbit launch satellit year center program earth moon\n",
            "\n",
            "Topic #20:\n",
            "line subject organ andrew post scsi host nntp univers write\n",
            "\n",
            "Topic #21:\n",
            "write organ subject post line articl like know peopl food\n",
            "\n",
            "Topic #22:\n",
            "line subject univers organ gatech georgia uchicago michael prism write\n",
            "\n",
            "Topic #23:\n",
            "write articl cramer optilink organ subject line clayton informatik opinion\n",
            "\n",
            "Topic #24:\n",
            "christian jesus peopl write religion think believ say know christ\n",
            "\n",
            "Topic #25:\n",
            "file program window mail imag avail disk version softwar data\n",
            "\n",
            "Topic #26:\n",
            "write line organ subject articl post clinton think nntp host\n",
            "\n",
            "Topic #27:\n",
            "peopl armenian state govern right turkish say think time weapon\n",
            "\n",
            "Topic #28:\n",
            "play team goal period hockey game score power player pittsburgh\n",
            "\n",
            "Topic #29:\n",
            "articl write organ subject line post drug nntp host good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "LrPaQEiuGRt3",
        "outputId": "c861c3b1-0e1e-48ad-e8d7-706f31616ff2"
      },
      "source": [
        "cluster_probabilities = lda.transform(count_data)\n",
        "data_processed['target'] = np.argmax(cluster_probabilities, axis=1)\n",
        "data_processed.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lerxst thing subject nntp post host organ univ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>guykuo carson washington subject clock poll fi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twilli purdu thoma willi subject question orga...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jgreen amber green subject weitek organ harri ...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>head harvard jonathan mcdowel subject shuttl l...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  target\n",
              "0  lerxst thing subject nntp post host organ univ...      15\n",
              "1  guykuo carson washington subject clock poll fi...       5\n",
              "2  twilli purdu thoma willi subject question orga...       5\n",
              "3  jgreen amber green subject weitek organ harri ...      26\n",
              "4  head harvard jonathan mcdowel subject shuttl l...      10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJNJOHB9GkKP"
      },
      "source": [
        "import seaborn as sns\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "At3W9AMVGnga",
        "outputId": "dcb5329b-5bc3-4851-e9a5-f94c9bb3fe43"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "sns.countplot(x=data_processed.target);\n",
        "ax.set_title(\"Number of articles that correspond to the topic\");\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ07JMrCRAYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887fa07e-df97-4c6b-a2f3-416675944d51"
      },
      "source": [
        "#Loading the data set - training data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "mydata_train = fetch_20newsgroups(subset='train', shuffle=True, remove = ('headers', 'footers', 'quotes'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpyae_wBRHIU",
        "outputId": "c69ee78d-7342-4270-d246-bee1bbb27d52"
      },
      "source": [
        "list(mydata_train)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'filenames', 'target_names', 'target', 'DESCR']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsmrhUPeRJ9l",
        "outputId": "f4c76b6c-4243-47c1-ceb6-c9f432304f87"
      },
      "source": [
        "print('Training data size:', len(mydata_train['data']))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size: 11314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv1WrOdSRONT",
        "outputId": "1e476c6e-d8a5-4546-8d0f-793b143c4855"
      },
      "source": [
        "# Printing all the categories\n",
        "mydata_train.target_names"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krZedPVlRRxL",
        "outputId": "c1486125-c7c5-422a-8b1c-f035d21d1ec8"
      },
      "source": [
        "\n",
        "# Finding frequency of each category\n",
        "targets, frequency = np.unique(mydata_train.target, return_counts=True)\n",
        "targets, frequency"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "        17, 18, 19]),\n",
              " array([480, 584, 591, 590, 578, 593, 585, 594, 598, 597, 600, 595, 591,\n",
              "        594, 593, 599, 546, 564, 465, 377]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSr8qhRVRWTb",
        "outputId": "2cb36f30-bc1f-4549-8610-8e5781d5c68d"
      },
      "source": [
        "targets_str = np.array(mydata_train.target_names)\n",
        "print(list(zip(targets_str, frequency)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('alt.atheism', 480), ('comp.graphics', 584), ('comp.os.ms-windows.misc', 591), ('comp.sys.ibm.pc.hardware', 590), ('comp.sys.mac.hardware', 578), ('comp.windows.x', 593), ('misc.forsale', 585), ('rec.autos', 594), ('rec.motorcycles', 598), ('rec.sport.baseball', 597), ('rec.sport.hockey', 600), ('sci.crypt', 595), ('sci.electronics', 591), ('sci.med', 594), ('sci.space', 593), ('soc.religion.christian', 599), ('talk.politics.guns', 546), ('talk.politics.mideast', 564), ('talk.politics.misc', 465), ('talk.religion.misc', 377)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pZ_KnVPRZSm"
      },
      "source": [
        "mydata_test = fetch_20newsgroups(subset='test', shuffle=True, remove = ('headers', 'footers', 'quotes'))\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEcSYoJmRcUc",
        "outputId": "be06cbb6-3c92-41da-dee2-5a0c28ad6951"
      },
      "source": [
        "print('Testing data size:', len(mydata_test['data']))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing data size: 7532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "_aSKch0QRf_o",
        "outputId": "70abb6c5-f128-463f-fdfc-43abd0a86a73"
      },
      "source": [
        "mydata_train_df = pd.DataFrame({'data': mydata_train.data, 'target': mydata_train.target})\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I was wondering if anyone out there could enli...       7\n",
              "1  A fair number of brave souls who upgraded thei...       4\n",
              "2  well folks, my mac plus finally gave up the gh...       4\n",
              "3  \\nDo you have Weitek's address/phone number?  ...       1\n",
              "4  From article <C5owCB.n3p@world.std.com>, by to...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "ttru-cT7Rj9K",
        "outputId": "e66007a6-0585-44c5-b5e8-a1545d717f95"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "import re\n",
        "import string\n",
        "\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_train_df['data'] = mydata_train_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks  my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\ndo you have weitek s address phone number   ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>from article      world std com   by tombaker ...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i was wondering if anyone out there could enli...       7\n",
              "1  a fair number of brave souls who upgraded thei...       4\n",
              "2  well folks  my mac plus finally gave up the gh...       4\n",
              "3  \\ndo you have weitek s address phone number   ...       1\n",
              "4  from article      world std com   by tombaker ...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "8f6jlH07RoBH",
        "outputId": "32971fad-8cd9-4a4e-d071-6cf430424c18"
      },
      "source": [
        "mydata_test_df = pd.DataFrame({'data': mydata_test.data, 'target': mydata_test.target})\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIn a word, yes.\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThey were attacking the Iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nI've just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I am a little confused on all of the models of...       7\n",
              "1  I'm not familiar at all with the format of the...       5\n",
              "2                                \\nIn a word, yes.\\n       0\n",
              "3  \\nThey were attacking the Iraqis to drive them...      17\n",
              "4  \\nI've just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "tUjU5KP5RrlP",
        "outputId": "392b1ea7-14bf-4164-bf42-60835dc99923"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_test_df['data'] = mydata_test_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i m not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nin a word  yes \\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nthey were attacking the iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\ni ve just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i am a little confused on all of the models of...       7\n",
              "1  i m not familiar at all with the format of the...       5\n",
              "2                                \\nin a word  yes \\n       0\n",
              "3  \\nthey were attacking the iraqis to drive them...      17\n",
              "4  \\ni ve just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUELDX2-bNNg",
        "outputId": "0a8a6d77-3e8e-42ce-fb1c-27fdf0c32095"
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "X_train_cv = count_vect.fit_transform(mydata_train_df.data) # fit_transform learns the\n",
        "X_test_cv = count_vect.transform(mydata_test_df.data) # transform uses the same vocab an\n",
        "print(X_train_cv.shape)\n",
        "print(type(X_train_cv))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11314, 67822)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRUtZ9-VAkiY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
        "from keras.models import Model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Oz3FjnHAqOw",
        "outputId": "5125ad12-d5e3-4d0e-d483-a2c3ca7922d6"
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian'] \n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, \n",
        "                                      categories=categories,)\n",
        "\n",
        "print (newsgroups_train.target_names)\n",
        "print (len(newsgroups_train.data))\n",
        "\n",
        "#print (newsgroups_train.data[1])\n",
        "print(\"\\n\".join(newsgroups_train.data[0].split(\"\\n\")[10:15]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'soc.religion.christian']\n",
            "1079\n",
            "   WASHINGTON, April 19  -- A symposium on the Dead Sea \n",
            "Scrolls will be held at the Library of Congress on Wednesday,\n",
            "April 21, and Thursday, April 22.  The two-day program, cosponsored\n",
            "by the library and Baltimore Hebrew University, with additional\n",
            "support from the Project Judaica Foundation, will be held in the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9VVEyQWAu6m",
        "outputId": "a0da991a-c3c1-4615-fd92-f65b95941203"
      },
      "source": [
        "%%time\n",
        "\n",
        "texts = []\n",
        "\n",
        "labels=newsgroups_train.target\n",
        "texts = newsgroups_train.data\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NB_WORDS = 20000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "print (sequences[0][:10])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19, 8762, 3621, 11894, 58, 8762, 3621, 43, 1472, 2]\n",
            "CPU times: user 425 ms, sys: 5.11 ms, total: 430 ms\n",
            "Wall time: 435 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C-jZJV1Ay0E",
        "outputId": "285275b2-96e0-4fcf-c51c-2b3ffe126375"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20030 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3leeqbJA1-q",
        "outputId": "fe9d8844-b105-491d-8f30-78a3ae437f9e"
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print (data.shape)\n",
        "print (data[0][200:250])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1079, 1000)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0    19  8762  3621 11894    58  8762  3621\n",
            "    43  1472     2  2130     3   189   450  1001  3622  2980  1682   476\n",
            "   627    50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TATKrjgmA6lK",
        "outputId": "de8f9a73-5c19-4eb6-da43-83319cc9ed5e"
      },
      "source": [
        "labels = to_categorical(np.array(labels))\n",
        "\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1079, 1000)\n",
            "Shape of label tensor: (1079, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKD1nppNA_cG",
        "outputId": "16869c0f-a3fa-4ffd-f347-387d2f6201f7"
      },
      "source": [
        "VALIDATION_SPLIT = 0.1\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices) \n",
        "data = data[indices] \n",
        "labels = labels[indices] \n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples] \n",
        "y_train = labels[:-nb_validation_samples] \n",
        "x_val = data[-nb_validation_samples:] \n",
        "y_val = labels[-nb_validation_samples:] \n",
        "\n",
        "print (x_train.shape)\n",
        "print (y_train.shape)\n",
        "\n",
        "print('Number of positive and negative reviews in traing and validation set ') \n",
        "print (y_train.sum(axis=0))\n",
        "print (y_val.sum(axis=0))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(972, 1000)\n",
            "(972, 2)\n",
            "Number of positive and negative reviews in traing and validation set \n",
            "[434. 538.]\n",
            "[46. 61.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "1jN7GicoBSkh",
        "outputId": "43a3ff98-917c-4021-9f7d-a8a91f5e3ab3"
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros.\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print (embedding_matrix.shape)\n",
        "\n",
        "print (embedding_matrix[0][:10])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6fb53264530f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# words not found in embedding index will be all-zeros.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StT4yPYaBUgr",
        "outputId": "193c929f-66c9-4c37-ea0f-ccb918c482bf"
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix], \n",
        "                            input_length=MAX_SEQUENCE_LENGTH, \n",
        "                            trainable=False)\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32') \n",
        "embedded_sequences = embedding_layer(sequence_input) \n",
        "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences) \n",
        "l_pool1 = MaxPooling1D(5)(l_cov1) \n",
        "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1) \n",
        "l_pool2 = MaxPooling1D(5)(l_cov2) \n",
        "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2) \n",
        "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
        "\n",
        "l_flat = Flatten()(l_pool3) \n",
        "l_dense = Dense(128, activation='relu')(l_flat) \n",
        "preds = Dense(2, activation='softmax')(l_dense)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1000)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1000, 100)         2003100   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 996, 128)          64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 199, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 195, 128)          82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 39, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 35, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 2,248,094\n",
            "Trainable params: 244,994\n",
            "Non-trainable params: 2,003,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohWKe6xrBfGj",
        "outputId": "f065fb81-bd2b-43e5-d682-bc5c020a38c7"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "                    epochs=500, batch_size=512)   "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 35s 1s/step - loss: 0.7746 - acc: 0.4851 - val_loss: 0.6963 - val_acc: 0.4766\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6936 - acc: 0.4684 - val_loss: 0.6884 - val_acc: 0.5701\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.6960 - acc: 0.5513 - val_loss: 0.6913 - val_acc: 0.5888\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6886 - acc: 0.5566 - val_loss: 0.6821 - val_acc: 0.5701\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6872 - acc: 0.5624 - val_loss: 0.6825 - val_acc: 0.5701\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6894 - acc: 0.5096 - val_loss: 0.6870 - val_acc: 0.6075\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 0.6865 - acc: 0.5819 - val_loss: 0.6816 - val_acc: 0.5701\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6893 - acc: 0.5487 - val_loss: 0.6814 - val_acc: 0.5701\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6845 - acc: 0.5533 - val_loss: 0.6827 - val_acc: 0.5701\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.6828 - acc: 0.5545 - val_loss: 0.6799 - val_acc: 0.5701\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.6821 - acc: 0.5558 - val_loss: 0.6860 - val_acc: 0.6168\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6835 - acc: 0.6181 - val_loss: 0.6782 - val_acc: 0.5701\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6788 - acc: 0.5487 - val_loss: 0.6771 - val_acc: 0.5701\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6761 - acc: 0.5578 - val_loss: 0.6825 - val_acc: 0.6075\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.6802 - acc: 0.6337 - val_loss: 0.6750 - val_acc: 0.5701\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6740 - acc: 0.5493 - val_loss: 0.6750 - val_acc: 0.5701\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6747 - acc: 0.5664 - val_loss: 0.6799 - val_acc: 0.6636\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6698 - acc: 0.6482 - val_loss: 0.6722 - val_acc: 0.5701\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6667 - acc: 0.5513 - val_loss: 0.6717 - val_acc: 0.5701\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.6606 - acc: 0.5606 - val_loss: 0.6688 - val_acc: 0.5701\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6552 - acc: 0.5658 - val_loss: 0.6713 - val_acc: 0.6729\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6525 - acc: 0.7306 - val_loss: 0.6623 - val_acc: 0.5701\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6462 - acc: 0.5640 - val_loss: 0.6771 - val_acc: 0.4860\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.6493 - acc: 0.6177 - val_loss: 0.6538 - val_acc: 0.5701\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.6459 - acc: 0.5671 - val_loss: 0.6460 - val_acc: 0.6168\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6260 - acc: 0.5984 - val_loss: 0.6421 - val_acc: 0.7477\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6111 - acc: 0.7964 - val_loss: 0.6349 - val_acc: 0.7570\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6066 - acc: 0.7487 - val_loss: 0.6483 - val_acc: 0.5514\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6063 - acc: 0.7122 - val_loss: 0.6113 - val_acc: 0.7850\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.5823 - acc: 0.8162 - val_loss: 0.6441 - val_acc: 0.5701\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.5977 - acc: 0.6621 - val_loss: 0.6711 - val_acc: 0.4393\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6007 - acc: 0.5156 - val_loss: 0.5791 - val_acc: 0.6822\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.5562 - acc: 0.6750 - val_loss: 0.5647 - val_acc: 0.8879\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.5173 - acc: 0.8477 - val_loss: 0.5359 - val_acc: 0.8131\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.4991 - acc: 0.8346 - val_loss: 0.5194 - val_acc: 0.8131\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.4768 - acc: 0.8200 - val_loss: 0.5320 - val_acc: 0.8692\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.4591 - acc: 0.9279 - val_loss: 0.5049 - val_acc: 0.7570\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 0.4414 - acc: 0.8208 - val_loss: 0.5001 - val_acc: 0.8505\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.4105 - acc: 0.9151 - val_loss: 0.4363 - val_acc: 0.8598\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.3838 - acc: 0.8798 - val_loss: 0.4755 - val_acc: 0.7570\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.3946 - acc: 0.8190 - val_loss: 0.4501 - val_acc: 0.8411\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.3851 - acc: 0.8713 - val_loss: 0.3840 - val_acc: 0.9065\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.3185 - acc: 0.9317 - val_loss: 0.4254 - val_acc: 0.8037\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.3312 - acc: 0.8465 - val_loss: 0.5901 - val_acc: 0.5701\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.3945 - acc: 0.7759 - val_loss: 0.4515 - val_acc: 0.7850\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.3490 - acc: 0.8471 - val_loss: 0.4634 - val_acc: 0.7103\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.3089 - acc: 0.8892 - val_loss: 0.3699 - val_acc: 0.8505\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.2851 - acc: 0.8755 - val_loss: 0.3440 - val_acc: 0.9065\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.2476 - acc: 0.9608 - val_loss: 0.2955 - val_acc: 0.9159\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.2199 - acc: 0.9290 - val_loss: 0.2894 - val_acc: 0.9065\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.2016 - acc: 0.9444 - val_loss: 0.3065 - val_acc: 0.9065\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.2003 - acc: 0.9568 - val_loss: 0.2870 - val_acc: 0.8972\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.1886 - acc: 0.9192 - val_loss: 0.2947 - val_acc: 0.8879\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.1847 - acc: 0.9624 - val_loss: 0.2594 - val_acc: 0.9065\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.1642 - acc: 0.9299 - val_loss: 0.2517 - val_acc: 0.9159\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.1474 - acc: 0.9804 - val_loss: 0.2355 - val_acc: 0.9252\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.1460 - acc: 0.9388 - val_loss: 0.2227 - val_acc: 0.9252\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1228 - acc: 0.9758 - val_loss: 0.2145 - val_acc: 0.9252\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.1196 - acc: 0.9647 - val_loss: 0.2249 - val_acc: 0.9252\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.1151 - acc: 0.9824 - val_loss: 0.2105 - val_acc: 0.9346\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.1097 - acc: 0.9517 - val_loss: 0.2072 - val_acc: 0.9346\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0952 - acc: 0.9871 - val_loss: 0.1991 - val_acc: 0.9346\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0973 - acc: 0.9759 - val_loss: 0.1873 - val_acc: 0.9252\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0862 - acc: 0.9696 - val_loss: 0.1927 - val_acc: 0.9346\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0877 - acc: 0.9906 - val_loss: 0.2279 - val_acc: 0.9159\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0943 - acc: 0.9549 - val_loss: 0.2658 - val_acc: 0.8879\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.1041 - acc: 0.9649 - val_loss: 0.2374 - val_acc: 0.9159\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0996 - acc: 0.9510 - val_loss: 0.2158 - val_acc: 0.9252\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0861 - acc: 0.9684 - val_loss: 0.2406 - val_acc: 0.9159\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0984 - acc: 0.9558 - val_loss: 0.2293 - val_acc: 0.9159\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0824 - acc: 0.9716 - val_loss: 0.2233 - val_acc: 0.9159\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.0791 - acc: 0.9685 - val_loss: 0.2203 - val_acc: 0.9346\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0731 - acc: 0.9926 - val_loss: 0.1872 - val_acc: 0.9346\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0646 - acc: 0.9710 - val_loss: 0.1592 - val_acc: 0.9533\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0532 - acc: 0.9947 - val_loss: 0.1764 - val_acc: 0.9439\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0504 - acc: 0.9966 - val_loss: 0.1836 - val_acc: 0.9346\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0502 - acc: 0.9784 - val_loss: 0.1542 - val_acc: 0.9626\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0445 - acc: 0.9980 - val_loss: 0.1578 - val_acc: 0.9439\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.0416 - acc: 0.9986 - val_loss: 0.1820 - val_acc: 0.9439\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0439 - acc: 0.9879 - val_loss: 0.1490 - val_acc: 0.9626\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0383 - acc: 0.9993 - val_loss: 0.1509 - val_acc: 0.9533\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0365 - acc: 0.9987 - val_loss: 0.1726 - val_acc: 0.9439\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.0373 - acc: 0.9940 - val_loss: 0.1486 - val_acc: 0.9626\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0294 - acc: 0.9993 - val_loss: 0.1494 - val_acc: 0.9533\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0316 - acc: 0.9987 - val_loss: 0.1541 - val_acc: 0.9533\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0287 - acc: 0.9979 - val_loss: 0.1523 - val_acc: 0.9533\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0279 - acc: 0.9987 - val_loss: 0.1468 - val_acc: 0.9533\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0286 - acc: 0.9987 - val_loss: 0.1496 - val_acc: 0.9533\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0256 - acc: 0.9987 - val_loss: 0.1533 - val_acc: 0.9533\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0232 - acc: 0.9993 - val_loss: 0.1417 - val_acc: 0.9533\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0221 - acc: 0.9993 - val_loss: 0.1412 - val_acc: 0.9720\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0191 - acc: 0.9993 - val_loss: 0.1515 - val_acc: 0.9533\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0212 - acc: 0.9987 - val_loss: 0.1405 - val_acc: 0.9720\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0202 - acc: 0.9987 - val_loss: 0.1411 - val_acc: 0.9720\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.0187 - acc: 0.9987 - val_loss: 0.1498 - val_acc: 0.9533\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0188 - acc: 0.9987 - val_loss: 0.1389 - val_acc: 0.9720\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0174 - acc: 0.9987 - val_loss: 0.1395 - val_acc: 0.9720\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0158 - acc: 0.9993 - val_loss: 0.1483 - val_acc: 0.9533\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0155 - acc: 0.9993 - val_loss: 0.1414 - val_acc: 0.9720\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0141 - acc: 0.9993 - val_loss: 0.1405 - val_acc: 0.9720\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0144 - acc: 0.9987 - val_loss: 0.1424 - val_acc: 0.9626\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0131 - acc: 0.9993 - val_loss: 0.1425 - val_acc: 0.9626\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0128 - acc: 0.9993 - val_loss: 0.1387 - val_acc: 0.9720\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0126 - acc: 0.9993 - val_loss: 0.1408 - val_acc: 0.9720\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.0113 - acc: 0.9993 - val_loss: 0.1418 - val_acc: 0.9720\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0109 - acc: 0.9993 - val_loss: 0.1407 - val_acc: 0.9720\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0117 - acc: 0.9987 - val_loss: 0.1408 - val_acc: 0.9720\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0114 - acc: 0.9987 - val_loss: 0.1425 - val_acc: 0.9626\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0103 - acc: 0.9993 - val_loss: 0.1390 - val_acc: 0.9720\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0099 - acc: 0.9993 - val_loss: 0.1422 - val_acc: 0.9720\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0101 - acc: 0.9987 - val_loss: 0.1442 - val_acc: 0.9626\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0095 - acc: 0.9987 - val_loss: 0.1395 - val_acc: 0.9720\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0086 - acc: 0.9987 - val_loss: 0.1406 - val_acc: 0.9720\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 0.0081 - acc: 0.9993 - val_loss: 0.1455 - val_acc: 0.9720\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0083 - acc: 0.9987 - val_loss: 0.1413 - val_acc: 0.9720\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 0.0076 - acc: 0.9993 - val_loss: 0.1450 - val_acc: 0.9720\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.1432 - val_acc: 0.9720\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1409 - val_acc: 0.9720\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.1456 - val_acc: 0.9720\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1455 - val_acc: 0.9720\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9720\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1434 - val_acc: 0.9720\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1495 - val_acc: 0.9720\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1498 - val_acc: 0.9720\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.1505 - val_acc: 0.9720\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.1476 - val_acc: 0.9720\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1490 - val_acc: 0.9720\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1541 - val_acc: 0.9720\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1453 - val_acc: 0.9720\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1449 - val_acc: 0.9720\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9626\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1507 - val_acc: 0.9720\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1469 - val_acc: 0.9720\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1599 - val_acc: 0.9720\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1563 - val_acc: 0.9720\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1476 - val_acc: 0.9720\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1521 - val_acc: 0.9720\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1637 - val_acc: 0.9720\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1539 - val_acc: 0.9720\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1555 - val_acc: 0.9720\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1603 - val_acc: 0.9720\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1594 - val_acc: 0.9720\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1596 - val_acc: 0.9720\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1622 - val_acc: 0.9720\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1602 - val_acc: 0.9720\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1634 - val_acc: 0.9720\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1648 - val_acc: 0.9720\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1621 - val_acc: 0.9720\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1599 - val_acc: 0.9720\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9720\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9720\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1632 - val_acc: 0.9720\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1648 - val_acc: 0.9720\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1707 - val_acc: 0.9720\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1692 - val_acc: 0.9720\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 0.9720\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1662 - val_acc: 0.9720\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9720\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9720\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1685 - val_acc: 0.9720\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1697 - val_acc: 0.9720\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1759 - val_acc: 0.9720\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1737 - val_acc: 0.9720\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1691 - val_acc: 0.9720\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1748 - val_acc: 0.9720\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1786 - val_acc: 0.9720\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1740 - val_acc: 0.9720\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 0.9720\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1796 - val_acc: 0.9720\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1807 - val_acc: 0.9720\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1754 - val_acc: 0.9720\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1759 - val_acc: 0.9720\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1807 - val_acc: 0.9720\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 9.6955e-04 - acc: 1.0000 - val_loss: 0.1793 - val_acc: 0.9720\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 9.4383e-04 - acc: 1.0000 - val_loss: 0.1774 - val_acc: 0.9720\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 9.5539e-04 - acc: 1.0000 - val_loss: 0.1797 - val_acc: 0.9720\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.6605e-04 - acc: 1.0000 - val_loss: 0.1791 - val_acc: 0.9720\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 9.0111e-04 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 0.9720\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 8.4020e-04 - acc: 1.0000 - val_loss: 0.1823 - val_acc: 0.9720\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.3891e-04 - acc: 1.0000 - val_loss: 0.1812 - val_acc: 0.9720\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 8.1802e-04 - acc: 1.0000 - val_loss: 0.1799 - val_acc: 0.9720\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.9219e-04 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9720\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 7.0466e-04 - acc: 1.0000 - val_loss: 0.1844 - val_acc: 0.9720\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.5998e-04 - acc: 1.0000 - val_loss: 0.1844 - val_acc: 0.9720\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.2233e-04 - acc: 1.0000 - val_loss: 0.1831 - val_acc: 0.9720\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 7.7586e-04 - acc: 1.0000 - val_loss: 0.1832 - val_acc: 0.9720\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 7.0559e-04 - acc: 1.0000 - val_loss: 0.1862 - val_acc: 0.9720\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 6.6448e-04 - acc: 1.0000 - val_loss: 0.1874 - val_acc: 0.9720\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.5898e-04 - acc: 1.0000 - val_loss: 0.1839 - val_acc: 0.9720\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 6.9640e-04 - acc: 1.0000 - val_loss: 0.1855 - val_acc: 0.9720\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 6.6579e-04 - acc: 1.0000 - val_loss: 0.1892 - val_acc: 0.9720\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 6.6537e-04 - acc: 1.0000 - val_loss: 0.1888 - val_acc: 0.9720\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 6.2772e-04 - acc: 1.0000 - val_loss: 0.1889 - val_acc: 0.9720\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 6.0388e-04 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9720\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.5953e-04 - acc: 1.0000 - val_loss: 0.1875 - val_acc: 0.9720\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 5.3966e-04 - acc: 1.0000 - val_loss: 0.1903 - val_acc: 0.9720\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 5.4297e-04 - acc: 1.0000 - val_loss: 0.1915 - val_acc: 0.9720\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.3252e-04 - acc: 1.0000 - val_loss: 0.1890 - val_acc: 0.9720\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 5.2470e-04 - acc: 1.0000 - val_loss: 0.1893 - val_acc: 0.9720\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.2016e-04 - acc: 1.0000 - val_loss: 0.1930 - val_acc: 0.9720\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.3530e-04 - acc: 1.0000 - val_loss: 0.1919 - val_acc: 0.9720\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.1290e-04 - acc: 1.0000 - val_loss: 0.1936 - val_acc: 0.9720\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.7920e-04 - acc: 1.0000 - val_loss: 0.1940 - val_acc: 0.9720\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 4.7715e-04 - acc: 1.0000 - val_loss: 0.1918 - val_acc: 0.9720\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 4.7413e-04 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9720\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 4.7166e-04 - acc: 1.0000 - val_loss: 0.1953 - val_acc: 0.9720\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.5728e-04 - acc: 1.0000 - val_loss: 0.1907 - val_acc: 0.9720\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 4.3187e-04 - acc: 1.0000 - val_loss: 0.1920 - val_acc: 0.9720\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.3316e-04 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9720\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.2145e-04 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9720\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.9856e-04 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9720\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 4.0106e-04 - acc: 1.0000 - val_loss: 0.1958 - val_acc: 0.9720\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.9960e-04 - acc: 1.0000 - val_loss: 0.1976 - val_acc: 0.9720\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.0069e-04 - acc: 1.0000 - val_loss: 0.1974 - val_acc: 0.9720\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.8940e-04 - acc: 1.0000 - val_loss: 0.1948 - val_acc: 0.9720\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.4633e-04 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.9720\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.6614e-04 - acc: 1.0000 - val_loss: 0.2002 - val_acc: 0.9720\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.6849e-04 - acc: 1.0000 - val_loss: 0.1970 - val_acc: 0.9720\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.6959e-04 - acc: 1.0000 - val_loss: 0.1971 - val_acc: 0.9720\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.5011e-04 - acc: 1.0000 - val_loss: 0.2011 - val_acc: 0.9720\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.1268e-04 - acc: 1.0000 - val_loss: 0.2002 - val_acc: 0.9720\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.6395e-04 - acc: 1.0000 - val_loss: 0.1973 - val_acc: 0.9720\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.1829e-04 - acc: 1.0000 - val_loss: 0.2005 - val_acc: 0.9720\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.3118e-04 - acc: 1.0000 - val_loss: 0.2042 - val_acc: 0.9720\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.2028e-04 - acc: 1.0000 - val_loss: 0.2009 - val_acc: 0.9720\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.0367e-04 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9720\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.0156e-04 - acc: 1.0000 - val_loss: 0.2012 - val_acc: 0.9720\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 3.0103e-04 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9720\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.8362e-04 - acc: 1.0000 - val_loss: 0.2036 - val_acc: 0.9720\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.7818e-04 - acc: 1.0000 - val_loss: 0.1985 - val_acc: 0.9720\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.8235e-04 - acc: 1.0000 - val_loss: 0.1992 - val_acc: 0.9720\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.7715e-04 - acc: 1.0000 - val_loss: 0.2042 - val_acc: 0.9720\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.7796e-04 - acc: 1.0000 - val_loss: 0.2066 - val_acc: 0.9720\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.5444e-04 - acc: 1.0000 - val_loss: 0.2051 - val_acc: 0.9720\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.4556e-04 - acc: 1.0000 - val_loss: 0.2027 - val_acc: 0.9720\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.5417e-04 - acc: 1.0000 - val_loss: 0.2032 - val_acc: 0.9720\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.4975e-04 - acc: 1.0000 - val_loss: 0.2057 - val_acc: 0.9720\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.5611e-04 - acc: 1.0000 - val_loss: 0.2061 - val_acc: 0.9720\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 2.5536e-04 - acc: 1.0000 - val_loss: 0.2043 - val_acc: 0.9720\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.2767e-04 - acc: 1.0000 - val_loss: 0.2043 - val_acc: 0.9720\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.2934e-04 - acc: 1.0000 - val_loss: 0.2053 - val_acc: 0.9720\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.4544e-04 - acc: 1.0000 - val_loss: 0.2074 - val_acc: 0.9720\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.3410e-04 - acc: 1.0000 - val_loss: 0.2075 - val_acc: 0.9720\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.4045e-04 - acc: 1.0000 - val_loss: 0.2067 - val_acc: 0.9720\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.3874e-04 - acc: 1.0000 - val_loss: 0.2076 - val_acc: 0.9720\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 2.2586e-04 - acc: 1.0000 - val_loss: 0.2079 - val_acc: 0.9720\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.1948e-04 - acc: 1.0000 - val_loss: 0.2086 - val_acc: 0.9720\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.1589e-04 - acc: 1.0000 - val_loss: 0.2086 - val_acc: 0.9720\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.1941e-04 - acc: 1.0000 - val_loss: 0.2081 - val_acc: 0.9720\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.1205e-04 - acc: 1.0000 - val_loss: 0.2085 - val_acc: 0.9720\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.0856e-04 - acc: 1.0000 - val_loss: 0.2086 - val_acc: 0.9720\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.9612e-04 - acc: 1.0000 - val_loss: 0.2090 - val_acc: 0.9720\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.0458e-04 - acc: 1.0000 - val_loss: 0.2092 - val_acc: 0.9720\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.0175e-04 - acc: 1.0000 - val_loss: 0.2113 - val_acc: 0.9720\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.9827e-04 - acc: 1.0000 - val_loss: 0.2118 - val_acc: 0.9720\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.0115e-04 - acc: 1.0000 - val_loss: 0.2095 - val_acc: 0.9720\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.9151e-04 - acc: 1.0000 - val_loss: 0.2096 - val_acc: 0.9720\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.8318e-04 - acc: 1.0000 - val_loss: 0.2099 - val_acc: 0.9720\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.7268e-04 - acc: 1.0000 - val_loss: 0.2111 - val_acc: 0.9720\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.6962e-04 - acc: 1.0000 - val_loss: 0.2126 - val_acc: 0.9720\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.8099e-04 - acc: 1.0000 - val_loss: 0.2127 - val_acc: 0.9720\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.7187e-04 - acc: 1.0000 - val_loss: 0.2119 - val_acc: 0.9720\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.8227e-04 - acc: 1.0000 - val_loss: 0.2117 - val_acc: 0.9720\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.7607e-04 - acc: 1.0000 - val_loss: 0.2139 - val_acc: 0.9720\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.7480e-04 - acc: 1.0000 - val_loss: 0.2132 - val_acc: 0.9720\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.8241e-04 - acc: 1.0000 - val_loss: 0.2114 - val_acc: 0.9720\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.7267e-04 - acc: 1.0000 - val_loss: 0.2120 - val_acc: 0.9720\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.7917e-04 - acc: 1.0000 - val_loss: 0.2145 - val_acc: 0.9720\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.5955e-04 - acc: 1.0000 - val_loss: 0.2157 - val_acc: 0.9720\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.6130e-04 - acc: 1.0000 - val_loss: 0.2133 - val_acc: 0.9720\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.5688e-04 - acc: 1.0000 - val_loss: 0.2130 - val_acc: 0.9720\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.7083e-04 - acc: 1.0000 - val_loss: 0.2148 - val_acc: 0.9720\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.5251e-04 - acc: 1.0000 - val_loss: 0.2157 - val_acc: 0.9720\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.5137e-04 - acc: 1.0000 - val_loss: 0.2156 - val_acc: 0.9720\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.4984e-04 - acc: 1.0000 - val_loss: 0.2148 - val_acc: 0.9720\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.5072e-04 - acc: 1.0000 - val_loss: 0.2138 - val_acc: 0.9720\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.5663e-04 - acc: 1.0000 - val_loss: 0.2151 - val_acc: 0.9720\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 198ms/step - loss: 1.4876e-04 - acc: 1.0000 - val_loss: 0.2168 - val_acc: 0.9720\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.4857e-04 - acc: 1.0000 - val_loss: 0.2179 - val_acc: 0.9720\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.4844e-04 - acc: 1.0000 - val_loss: 0.2164 - val_acc: 0.9720\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.5533e-04 - acc: 1.0000 - val_loss: 0.2151 - val_acc: 0.9720\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 1.5025e-04 - acc: 1.0000 - val_loss: 0.2157 - val_acc: 0.9720\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.3779e-04 - acc: 1.0000 - val_loss: 0.2178 - val_acc: 0.9720\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.3719e-04 - acc: 1.0000 - val_loss: 0.2181 - val_acc: 0.9720\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.4076e-04 - acc: 1.0000 - val_loss: 0.2175 - val_acc: 0.9720\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.3868e-04 - acc: 1.0000 - val_loss: 0.2174 - val_acc: 0.9720\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.3952e-04 - acc: 1.0000 - val_loss: 0.2181 - val_acc: 0.9720\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.3481e-04 - acc: 1.0000 - val_loss: 0.2185 - val_acc: 0.9720\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.3266e-04 - acc: 1.0000 - val_loss: 0.2181 - val_acc: 0.9720\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.3130e-04 - acc: 1.0000 - val_loss: 0.2187 - val_acc: 0.9720\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.2247e-04 - acc: 1.0000 - val_loss: 0.2188 - val_acc: 0.9720\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.3470e-04 - acc: 1.0000 - val_loss: 0.2184 - val_acc: 0.9720\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.2285e-04 - acc: 1.0000 - val_loss: 0.2198 - val_acc: 0.9720\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.3184e-04 - acc: 1.0000 - val_loss: 0.2197 - val_acc: 0.9720\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.2553e-04 - acc: 1.0000 - val_loss: 0.2197 - val_acc: 0.9720\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 1.2479e-04 - acc: 1.0000 - val_loss: 0.2199 - val_acc: 0.9720\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2098e-04 - acc: 1.0000 - val_loss: 0.2211 - val_acc: 0.9720\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2440e-04 - acc: 1.0000 - val_loss: 0.2213 - val_acc: 0.9720\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.2583e-04 - acc: 1.0000 - val_loss: 0.2213 - val_acc: 0.9720\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2280e-04 - acc: 1.0000 - val_loss: 0.2209 - val_acc: 0.9720\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.1980e-04 - acc: 1.0000 - val_loss: 0.2205 - val_acc: 0.9720\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.1734e-04 - acc: 1.0000 - val_loss: 0.2202 - val_acc: 0.9720\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.1685e-04 - acc: 1.0000 - val_loss: 0.2208 - val_acc: 0.9720\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.1223e-04 - acc: 1.0000 - val_loss: 0.2223 - val_acc: 0.9720\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.0744e-04 - acc: 1.0000 - val_loss: 0.2231 - val_acc: 0.9720\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.1410e-04 - acc: 1.0000 - val_loss: 0.2225 - val_acc: 0.9720\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.0808e-04 - acc: 1.0000 - val_loss: 0.2228 - val_acc: 0.9720\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 1.0943e-04 - acc: 1.0000 - val_loss: 0.2227 - val_acc: 0.9720\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.0938e-04 - acc: 1.0000 - val_loss: 0.2222 - val_acc: 0.9720\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.1591e-04 - acc: 1.0000 - val_loss: 0.2228 - val_acc: 0.9720\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.0411e-04 - acc: 1.0000 - val_loss: 0.2234 - val_acc: 0.9720\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.0879e-04 - acc: 1.0000 - val_loss: 0.2244 - val_acc: 0.9720\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.1430e-04 - acc: 1.0000 - val_loss: 0.2244 - val_acc: 0.9720\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.0536e-04 - acc: 1.0000 - val_loss: 0.2240 - val_acc: 0.9720\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.0343e-04 - acc: 1.0000 - val_loss: 0.2244 - val_acc: 0.9720\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.0075e-04 - acc: 1.0000 - val_loss: 0.2248 - val_acc: 0.9720\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.0633e-04 - acc: 1.0000 - val_loss: 0.2238 - val_acc: 0.9720\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.0358e-04 - acc: 1.0000 - val_loss: 0.2245 - val_acc: 0.9720\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.0064e-04 - acc: 1.0000 - val_loss: 0.2253 - val_acc: 0.9720\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 9.9889e-05 - acc: 1.0000 - val_loss: 0.2257 - val_acc: 0.9720\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 9.9063e-05 - acc: 1.0000 - val_loss: 0.2252 - val_acc: 0.9720\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 9.4629e-05 - acc: 1.0000 - val_loss: 0.2255 - val_acc: 0.9720\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.0053e-04 - acc: 1.0000 - val_loss: 0.2258 - val_acc: 0.9720\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 9.0418e-05 - acc: 1.0000 - val_loss: 0.2265 - val_acc: 0.9720\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 9.6730e-05 - acc: 1.0000 - val_loss: 0.2259 - val_acc: 0.9720\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.0104e-04 - acc: 1.0000 - val_loss: 0.2266 - val_acc: 0.9720\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 9.4978e-05 - acc: 1.0000 - val_loss: 0.2273 - val_acc: 0.9720\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 9.7504e-05 - acc: 1.0000 - val_loss: 0.2271 - val_acc: 0.9720\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 9.4669e-05 - acc: 1.0000 - val_loss: 0.2271 - val_acc: 0.9720\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 9.3150e-05 - acc: 1.0000 - val_loss: 0.2272 - val_acc: 0.9720\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 8.9284e-05 - acc: 1.0000 - val_loss: 0.2283 - val_acc: 0.9720\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 9.1344e-05 - acc: 1.0000 - val_loss: 0.2292 - val_acc: 0.9720\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.4026e-05 - acc: 1.0000 - val_loss: 0.2286 - val_acc: 0.9720\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 8.6529e-05 - acc: 1.0000 - val_loss: 0.2278 - val_acc: 0.9720\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 8.9537e-05 - acc: 1.0000 - val_loss: 0.2278 - val_acc: 0.9720\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.9287e-05 - acc: 1.0000 - val_loss: 0.2284 - val_acc: 0.9720\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.0942e-05 - acc: 1.0000 - val_loss: 0.2301 - val_acc: 0.9720\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 8.6304e-05 - acc: 1.0000 - val_loss: 0.2302 - val_acc: 0.9720\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.3557e-05 - acc: 1.0000 - val_loss: 0.2294 - val_acc: 0.9720\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 8.2684e-05 - acc: 1.0000 - val_loss: 0.2289 - val_acc: 0.9720\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 8.1891e-05 - acc: 1.0000 - val_loss: 0.2283 - val_acc: 0.9720\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.3799e-05 - acc: 1.0000 - val_loss: 0.2294 - val_acc: 0.9720\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 8.5580e-05 - acc: 1.0000 - val_loss: 0.2313 - val_acc: 0.9720\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 8.0237e-05 - acc: 1.0000 - val_loss: 0.2315 - val_acc: 0.9720\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 8.0164e-05 - acc: 1.0000 - val_loss: 0.2313 - val_acc: 0.9720\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 7.9786e-05 - acc: 1.0000 - val_loss: 0.2320 - val_acc: 0.9720\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 8.1764e-05 - acc: 1.0000 - val_loss: 0.2332 - val_acc: 0.9720\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.8655e-05 - acc: 1.0000 - val_loss: 0.2320 - val_acc: 0.9720\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.5004e-05 - acc: 1.0000 - val_loss: 0.2319 - val_acc: 0.9720\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 7.8439e-05 - acc: 1.0000 - val_loss: 0.2320 - val_acc: 0.9720\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 7.3419e-05 - acc: 1.0000 - val_loss: 0.2334 - val_acc: 0.9720\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 7.7616e-05 - acc: 1.0000 - val_loss: 0.2353 - val_acc: 0.9720\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 7.4558e-05 - acc: 1.0000 - val_loss: 0.2340 - val_acc: 0.9720\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.2778e-05 - acc: 1.0000 - val_loss: 0.2341 - val_acc: 0.9720\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 7.1824e-05 - acc: 1.0000 - val_loss: 0.2332 - val_acc: 0.9626\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 7.2393e-05 - acc: 1.0000 - val_loss: 0.2339 - val_acc: 0.9720\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 7.4917e-05 - acc: 1.0000 - val_loss: 0.2348 - val_acc: 0.9720\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 7.4325e-05 - acc: 1.0000 - val_loss: 0.2340 - val_acc: 0.9720\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.9891e-05 - acc: 1.0000 - val_loss: 0.2334 - val_acc: 0.9720\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 6.7005e-05 - acc: 1.0000 - val_loss: 0.2334 - val_acc: 0.9720\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 6.7903e-05 - acc: 1.0000 - val_loss: 0.2347 - val_acc: 0.9626\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.5667e-05 - acc: 1.0000 - val_loss: 0.2368 - val_acc: 0.9720\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 6.6108e-05 - acc: 1.0000 - val_loss: 0.2380 - val_acc: 0.9720\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 6.5727e-05 - acc: 1.0000 - val_loss: 0.2390 - val_acc: 0.9720\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 6.8224e-05 - acc: 1.0000 - val_loss: 0.2375 - val_acc: 0.9720\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 6.1074e-05 - acc: 1.0000 - val_loss: 0.2389 - val_acc: 0.9720\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 6.6437e-05 - acc: 1.0000 - val_loss: 0.2358 - val_acc: 0.9626\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 6.6126e-05 - acc: 1.0000 - val_loss: 0.2395 - val_acc: 0.9720\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 6.5519e-05 - acc: 1.0000 - val_loss: 0.2399 - val_acc: 0.9720\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 6.0643e-05 - acc: 1.0000 - val_loss: 0.2365 - val_acc: 0.9626\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.2058e-05 - acc: 1.0000 - val_loss: 0.2404 - val_acc: 0.9720\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.1339e-05 - acc: 1.0000 - val_loss: 0.2417 - val_acc: 0.9720\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 6.8985e-05 - acc: 1.0000 - val_loss: 0.2374 - val_acc: 0.9720\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 6.2674e-05 - acc: 1.0000 - val_loss: 0.2333 - val_acc: 0.9720\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.4088e-05 - acc: 1.0000 - val_loss: 0.2316 - val_acc: 0.9720\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 7.0669e-05 - acc: 1.0000 - val_loss: 0.2335 - val_acc: 0.9720\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 6.0968e-05 - acc: 1.0000 - val_loss: 0.2367 - val_acc: 0.9720\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.8869e-05 - acc: 1.0000 - val_loss: 0.2334 - val_acc: 0.9626\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 5.8981e-05 - acc: 1.0000 - val_loss: 0.2388 - val_acc: 0.9720\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 5.5740e-05 - acc: 1.0000 - val_loss: 0.2452 - val_acc: 0.9720\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 5.7365e-05 - acc: 1.0000 - val_loss: 0.2387 - val_acc: 0.9626\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.9918e-05 - acc: 1.0000 - val_loss: 0.2387 - val_acc: 0.9626\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 191ms/step - loss: 4.9243e-05 - acc: 1.0000 - val_loss: 0.2433 - val_acc: 0.9720\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.0618e-05 - acc: 1.0000 - val_loss: 0.2422 - val_acc: 0.9720\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 4.7554e-05 - acc: 1.0000 - val_loss: 0.2403 - val_acc: 0.9720\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.6900e-05 - acc: 1.0000 - val_loss: 0.2409 - val_acc: 0.9720\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.3958e-05 - acc: 1.0000 - val_loss: 0.2423 - val_acc: 0.9720\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 4.5894e-05 - acc: 1.0000 - val_loss: 0.2387 - val_acc: 0.9626\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.8822e-05 - acc: 1.0000 - val_loss: 0.2422 - val_acc: 0.9720\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.4228e-05 - acc: 1.0000 - val_loss: 0.2417 - val_acc: 0.9720\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 4.2633e-05 - acc: 1.0000 - val_loss: 0.2370 - val_acc: 0.9626\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.4311e-05 - acc: 1.0000 - val_loss: 0.2429 - val_acc: 0.9720\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.3762e-05 - acc: 1.0000 - val_loss: 0.2410 - val_acc: 0.9720\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.9580e-05 - acc: 1.0000 - val_loss: 0.2371 - val_acc: 0.9626\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 4.5713e-05 - acc: 1.0000 - val_loss: 0.2457 - val_acc: 0.9720\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 4.4925e-05 - acc: 1.0000 - val_loss: 0.2397 - val_acc: 0.9720\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.9393e-05 - acc: 1.0000 - val_loss: 0.2371 - val_acc: 0.9626\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.2574e-05 - acc: 1.0000 - val_loss: 0.2450 - val_acc: 0.9720\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.8552e-05 - acc: 1.0000 - val_loss: 0.2380 - val_acc: 0.9626\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.8361e-05 - acc: 1.0000 - val_loss: 0.2412 - val_acc: 0.9720\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.7287e-05 - acc: 1.0000 - val_loss: 0.2441 - val_acc: 0.9720\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.8133e-05 - acc: 1.0000 - val_loss: 0.2369 - val_acc: 0.9626\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.8114e-05 - acc: 1.0000 - val_loss: 0.2450 - val_acc: 0.9720\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 3.8356e-05 - acc: 1.0000 - val_loss: 0.2390 - val_acc: 0.9626\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.3134e-05 - acc: 1.0000 - val_loss: 0.2400 - val_acc: 0.9626\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.4214e-05 - acc: 1.0000 - val_loss: 0.2424 - val_acc: 0.9720\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.3208e-05 - acc: 1.0000 - val_loss: 0.2400 - val_acc: 0.9626\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.2991e-05 - acc: 1.0000 - val_loss: 0.2412 - val_acc: 0.9720\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.1877e-05 - acc: 1.0000 - val_loss: 0.2415 - val_acc: 0.9720\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.1031e-05 - acc: 1.0000 - val_loss: 0.2397 - val_acc: 0.9626\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 3.1737e-05 - acc: 1.0000 - val_loss: 0.2472 - val_acc: 0.9720\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.4251e-05 - acc: 1.0000 - val_loss: 0.2445 - val_acc: 0.9720\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.8182e-05 - acc: 1.0000 - val_loss: 0.2390 - val_acc: 0.9626\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.1855e-05 - acc: 1.0000 - val_loss: 0.2476 - val_acc: 0.9720\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.1828e-05 - acc: 1.0000 - val_loss: 0.2393 - val_acc: 0.9626\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.0348e-05 - acc: 1.0000 - val_loss: 0.2425 - val_acc: 0.9720\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.9315e-05 - acc: 1.0000 - val_loss: 0.2452 - val_acc: 0.9720\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.8656e-05 - acc: 1.0000 - val_loss: 0.2393 - val_acc: 0.9626\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.9629e-05 - acc: 1.0000 - val_loss: 0.2459 - val_acc: 0.9720\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.8502e-05 - acc: 1.0000 - val_loss: 0.2405 - val_acc: 0.9626\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.6798e-05 - acc: 1.0000 - val_loss: 0.2417 - val_acc: 0.9720\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.5799e-05 - acc: 1.0000 - val_loss: 0.2419 - val_acc: 0.9720\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 2.4512e-05 - acc: 1.0000 - val_loss: 0.2426 - val_acc: 0.9720\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.4170e-05 - acc: 1.0000 - val_loss: 0.2419 - val_acc: 0.9720\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.3569e-05 - acc: 1.0000 - val_loss: 0.2460 - val_acc: 0.9720\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.6010e-05 - acc: 1.0000 - val_loss: 0.2448 - val_acc: 0.9720\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.3304e-05 - acc: 1.0000 - val_loss: 0.2405 - val_acc: 0.9626\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.3017e-05 - acc: 1.0000 - val_loss: 0.2475 - val_acc: 0.9720\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.3031e-05 - acc: 1.0000 - val_loss: 0.2421 - val_acc: 0.9720\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 2.2593e-05 - acc: 1.0000 - val_loss: 0.2439 - val_acc: 0.9720\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 2.0791e-05 - acc: 1.0000 - val_loss: 0.2460 - val_acc: 0.9720\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 2.2266e-05 - acc: 1.0000 - val_loss: 0.2431 - val_acc: 0.9720\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.0778e-05 - acc: 1.0000 - val_loss: 0.2441 - val_acc: 0.9720\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 2.0627e-05 - acc: 1.0000 - val_loss: 0.2434 - val_acc: 0.9720\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.8612e-05 - acc: 1.0000 - val_loss: 0.2448 - val_acc: 0.9720\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.9972e-05 - acc: 1.0000 - val_loss: 0.2418 - val_acc: 0.9720\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 1.9379e-05 - acc: 1.0000 - val_loss: 0.2469 - val_acc: 0.9720\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.8711e-05 - acc: 1.0000 - val_loss: 0.2420 - val_acc: 0.9720\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.8252e-05 - acc: 1.0000 - val_loss: 0.2429 - val_acc: 0.9720\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.7820e-05 - acc: 1.0000 - val_loss: 0.2457 - val_acc: 0.9720\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.8018e-05 - acc: 1.0000 - val_loss: 0.2430 - val_acc: 0.9720\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.7407e-05 - acc: 1.0000 - val_loss: 0.2433 - val_acc: 0.9720\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.7202e-05 - acc: 1.0000 - val_loss: 0.2435 - val_acc: 0.9720\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 1.5305e-05 - acc: 1.0000 - val_loss: 0.2432 - val_acc: 0.9720\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.5137e-05 - acc: 1.0000 - val_loss: 0.2433 - val_acc: 0.9720\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.6631e-05 - acc: 1.0000 - val_loss: 0.2448 - val_acc: 0.9720\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.5696e-05 - acc: 1.0000 - val_loss: 0.2444 - val_acc: 0.9720\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.5152e-05 - acc: 1.0000 - val_loss: 0.2425 - val_acc: 0.9720\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.5337e-05 - acc: 1.0000 - val_loss: 0.2456 - val_acc: 0.9720\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 1.5658e-05 - acc: 1.0000 - val_loss: 0.2428 - val_acc: 0.9720\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 1.5261e-05 - acc: 1.0000 - val_loss: 0.2459 - val_acc: 0.9720\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.4943e-05 - acc: 1.0000 - val_loss: 0.2448 - val_acc: 0.9720\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.3951e-05 - acc: 1.0000 - val_loss: 0.2447 - val_acc: 0.9720\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.2759e-05 - acc: 1.0000 - val_loss: 0.2414 - val_acc: 0.9626\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.4284e-05 - acc: 1.0000 - val_loss: 0.2467 - val_acc: 0.9720\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.3201e-05 - acc: 1.0000 - val_loss: 0.2435 - val_acc: 0.9720\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.3792e-05 - acc: 1.0000 - val_loss: 0.2456 - val_acc: 0.9720\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.3401e-05 - acc: 1.0000 - val_loss: 0.2466 - val_acc: 0.9720\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.3935e-05 - acc: 1.0000 - val_loss: 0.2416 - val_acc: 0.9626\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.2319e-05 - acc: 1.0000 - val_loss: 0.2475 - val_acc: 0.9720\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.1850e-05 - acc: 1.0000 - val_loss: 0.2439 - val_acc: 0.9720\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 1.1961e-05 - acc: 1.0000 - val_loss: 0.2468 - val_acc: 0.9720\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.1498e-05 - acc: 1.0000 - val_loss: 0.2452 - val_acc: 0.9720\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 1.1659e-05 - acc: 1.0000 - val_loss: 0.2451 - val_acc: 0.9720\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.1780e-05 - acc: 1.0000 - val_loss: 0.2476 - val_acc: 0.9720\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 1.1785e-05 - acc: 1.0000 - val_loss: 0.2438 - val_acc: 0.9720\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.1876e-05 - acc: 1.0000 - val_loss: 0.2444 - val_acc: 0.9720\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2628e-05 - acc: 1.0000 - val_loss: 0.2506 - val_acc: 0.9720\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.1275e-05 - acc: 1.0000 - val_loss: 0.2419 - val_acc: 0.9626\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.1292e-05 - acc: 1.0000 - val_loss: 0.2517 - val_acc: 0.9720\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.1619e-05 - acc: 1.0000 - val_loss: 0.2450 - val_acc: 0.9720\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.0242e-05 - acc: 1.0000 - val_loss: 0.2454 - val_acc: 0.9720\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.0222e-05 - acc: 1.0000 - val_loss: 0.2499 - val_acc: 0.9720\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.1031e-05 - acc: 1.0000 - val_loss: 0.2423 - val_acc: 0.9720\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.0836e-05 - acc: 1.0000 - val_loss: 0.2476 - val_acc: 0.9720\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 9.8647e-06 - acc: 1.0000 - val_loss: 0.2473 - val_acc: 0.9720\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 1.0807e-05 - acc: 1.0000 - val_loss: 0.2425 - val_acc: 0.9720\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 9.9080e-06 - acc: 1.0000 - val_loss: 0.2523 - val_acc: 0.9720\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 1.0840e-05 - acc: 1.0000 - val_loss: 0.2440 - val_acc: 0.9720\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 9.7045e-06 - acc: 1.0000 - val_loss: 0.2449 - val_acc: 0.9720\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 8.9564e-06 - acc: 1.0000 - val_loss: 0.2500 - val_acc: 0.9720\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 9.6076e-06 - acc: 1.0000 - val_loss: 0.2448 - val_acc: 0.9720\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 9.5309e-06 - acc: 1.0000 - val_loss: 0.2486 - val_acc: 0.9720\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 9.5738e-06 - acc: 1.0000 - val_loss: 0.2519 - val_acc: 0.9720\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 8.0748e-06 - acc: 1.0000 - val_loss: 0.2426 - val_acc: 0.9626\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 9.2515e-06 - acc: 1.0000 - val_loss: 0.2484 - val_acc: 0.9720\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.8948e-06 - acc: 1.0000 - val_loss: 0.2490 - val_acc: 0.9720\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 8.1432e-06 - acc: 1.0000 - val_loss: 0.2437 - val_acc: 0.9720\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 8.6888e-06 - acc: 1.0000 - val_loss: 0.2491 - val_acc: 0.9720\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 8.5556e-06 - acc: 1.0000 - val_loss: 0.2491 - val_acc: 0.9720\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 7.9384e-06 - acc: 1.0000 - val_loss: 0.2452 - val_acc: 0.9720\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 8.3904e-06 - acc: 1.0000 - val_loss: 0.2491 - val_acc: 0.9720\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 8.2006e-06 - acc: 1.0000 - val_loss: 0.2467 - val_acc: 0.9720\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 7.6509e-06 - acc: 1.0000 - val_loss: 0.2467 - val_acc: 0.9720\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 7.2886e-06 - acc: 1.0000 - val_loss: 0.2493 - val_acc: 0.9720\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 7.4219e-06 - acc: 1.0000 - val_loss: 0.2484 - val_acc: 0.9720\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 7.5412e-06 - acc: 1.0000 - val_loss: 0.2470 - val_acc: 0.9720\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 7.6410e-06 - acc: 1.0000 - val_loss: 0.2501 - val_acc: 0.9720\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 7.1886e-06 - acc: 1.0000 - val_loss: 0.2482 - val_acc: 0.9720\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 7.2689e-06 - acc: 1.0000 - val_loss: 0.2463 - val_acc: 0.9720\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qzK4SJB5y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "57c3a1bc-d221-4139-d4cb-9bd77fe81016"
      },
      "source": [
        "plt.figure(figsize =(5,3))\n",
        "plt.plot(history.history['acc'], marker='.', label='tune')\n",
        "plt.plot(history.history['val_acc'], marker='.', label='test')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
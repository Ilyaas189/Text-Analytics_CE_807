{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA Model_DS_80_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ilyaas189/Text-Analytics_CE_807/blob/main/LDA_Model_DS_80_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "h48neXM-ANwE",
        "outputId": "82526e73-1d16-49b8-d03d-1a53323abc63"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from google.colab import files\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import random\n",
        "uploaded = files.upload()\n",
        "files = list(uploaded.keys())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d2f7c065-d999-462c-bb6a-6ecf65e55071\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d2f7c065-d999-462c-bb6a-6ecf65e55071\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcrJU_pzAhOm",
        "outputId": "47610d33-b5aa-4b7e-e59a-db69fad1bdb6"
      },
      "source": [
        "# Import Dataset\n",
        "data = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "print(data.target_names.unique())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
            " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
            " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
            " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
            " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
            " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "SnGiNUYGAtLQ",
        "outputId": "bfcb3ad8-f74d-4e07-bfa1-574a31edfcc5"
      },
      "source": [
        "data.head(20)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
              "      <td>16</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
              "      <td>13</td>\n",
              "      <td>sci.med</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
              "      <td>3</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
              "      <td>8</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>From: david@terminus.ericsson.se (David Bold)\\...</td>\n",
              "      <td>19</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>From: dbm0000@tm0006.lerc.nasa.gov (David B. M...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...</td>\n",
              "      <td>6</td>\n",
              "      <td>misc.forsale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...</td>\n",
              "      <td>12</td>\n",
              "      <td>sci.electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>From: abarden@tybse1.uucp (Ann Marie Barden)\\n...</td>\n",
              "      <td>5</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              content  ...              target_names\n",
              "0   From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...                 rec.autos\n",
              "1   From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...     comp.sys.mac.hardware\n",
              "2   From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...     comp.sys.mac.hardware\n",
              "3   From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...             comp.graphics\n",
              "4   From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...                 sci.space\n",
              "5   From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...  ...        talk.politics.guns\n",
              "6   From: bmdelane@quads.uchicago.edu (brian manni...  ...                   sci.med\n",
              "7   From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...  ...  comp.sys.ibm.pc.hardware\n",
              "8   From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...  ...   comp.os.ms-windows.misc\n",
              "9   From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...  ...     comp.sys.mac.hardware\n",
              "10  From: irwin@cmptrc.lonestar.org (Irwin Arnstei...  ...           rec.motorcycles\n",
              "11  From: david@terminus.ericsson.se (David Bold)\\...  ...        talk.religion.misc\n",
              "12  From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...  ...     comp.sys.mac.hardware\n",
              "13  From: dbm0000@tm0006.lerc.nasa.gov (David B. M...  ...                 sci.space\n",
              "14  From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...  ...              misc.forsale\n",
              "15  From: mathew <mathew@mantis.co.uk>\\nSubject: R...  ...               alt.atheism\n",
              "16  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...  ...             comp.graphics\n",
              "17  From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...  ...                 rec.autos\n",
              "18  From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...  ...           sci.electronics\n",
              "19  From: abarden@tybse1.uucp (Ann Marie Barden)\\n...  ...            comp.windows.x\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1t4Hd65BKo4",
        "outputId": "54f4d237-c35b-4bf1-b606-608d9f08eccb"
      },
      "source": [
        "data_clusterization = data[['content', 'target_names']]\n",
        "data_clusterization.dropna(inplace=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "0xRJ8_03Bd1W",
        "outputId": "a8ee72e8-ee48-436c-8372-387b95ea6c1f"
      },
      "source": [
        "data_clusterization.head(2)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content           target_names\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...              rec.autos\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  comp.sys.mac.hardware"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iUh1DoLBmXP",
        "outputId": "d67cf264-2526-4085-f51e-150c0c295c52"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7hwfWd1Bw8S"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        " stemmer = SnowballStemmer(language='english')\n",
        " return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        " result = []\n",
        " for token in gensim.utils.simple_preprocess(text):\n",
        "   if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "     result.append(lemmatize_stemming(token))\n",
        " return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJfVX8biB_Sa"
      },
      "source": [
        "processed_docs = data_clusterization['content'].map(preprocess)\n",
        "data_processed = processed_docs.to_frame()\n",
        "data_processed['content'] = data_processed.content.apply(lambda x: ' '.join(x))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCHPTBYJClMy",
        "outputId": "3339fad6-6ea4-4b77-cbd4-28a3da1d7504"
      },
      "source": [
        "!pip install tokenize_uk\n",
        "from collections import Counter\n",
        "from tokenize_uk.tokenize_uk import tokenize_words"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenize_uk\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/21/72abb0304b532e1b2d2473b50d8063ddd0943e3b3fe7e86b366bc4d02aa2/tokenize_uk-0.2.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tokenize_uk) (1.15.0)\n",
            "Building wheels for collected packages: tokenize-uk\n",
            "  Building wheel for tokenize-uk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tokenize-uk: filename=tokenize_uk-0.2.0-py2.py3-none-any.whl size=4565 sha256=cf099857ffd556b7f8aceb88511890741514070d427549c702c4ef1cf0e2ebf7\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/e1/95/fd8af5b40aeebdc4e178974e7f638f5553aa8772117054db9e\n",
            "Successfully built tokenize-uk\n",
            "Installing collected packages: tokenize-uk\n",
            "Successfully installed tokenize-uk-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "94mq8WUoCqHq",
        "outputId": "9419c187-b063-4dfd-e436-b14751a35f59"
      },
      "source": [
        "def display_words(data, title, ax):\n",
        " count = Counter(sum(map(lambda text: tokenize_words(text), data), []))\n",
        " popular = np.array(sorted(count.items(), key=lambda x: x[1], reverse=True)[:20])\n",
        " plt.sca(ax)\n",
        " plt.title(title)\n",
        " plt.bar(popular[:,0], np.int32(popular[:,1]))\n",
        " plt.xticks(rotation=\"vertical\")\n",
        "fig, ax = plt.subplots(figsize=(16, 5))\n",
        "display_words(data_processed.sample(1000).content, \"The most popular words]\", ax)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCM4qevNC5Ty"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMnRgz3aC8f5",
        "outputId": "d13935df-900a-4b8b-9a23-ea50669a51df"
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "count_data = count_vectorizer.fit_transform(data_processed['content'])\n",
        "count_data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11314x61410 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 934270 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TmSX73jDEJS"
      },
      "source": [
        "likelihood = []\n",
        "n_clusters = []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9uTcUJlDHT0"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hki6oWR0DLwb"
      },
      "source": [
        "def estimate_number_clusters(data, nclusters):\n",
        " for n in nclusters:\n",
        "   likelihood.append(LDA(n_components=n, n_jobs=-1).fit(data).score(data))\n",
        " n_clusters.append(n)\n",
        " print(\"Sccesfully estimated \", n)\n",
        " fig, ax = plt.subplots(figsize=(15, 5))\n",
        " sns.lineplot(x=n_clusters, y=likelihood, ax=ax)\n",
        " ax.set_title('Elbow method for choosing n, likelihood')\n",
        " ax.set_ylabel('Likelihood')\n",
        " ax.set_xlabel('n')\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CBG_y1fJszZ"
      },
      "source": [
        "# estimate_number_clusters(count_data, [10, 15, 20, 50])\n",
        " \n",
        " "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XNMixjQJuYE"
      },
      "source": [
        "def print_topics(model, count_vectorizer, n_top_words):\n",
        "  words = count_vectorizer.get_feature_names()\n",
        "  for topic_idx, topic in enumerate(model.components_):\n",
        "    print(\"\\nTopic #%d:\" % topic_idx)\n",
        "    print(\" \".join([words[i]\n",
        "  for i in topic.argsort()[:-n_top_words - 1:-1]]))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugizp_hhFpzm"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWtTkYX1Ftia",
        "outputId": "73b5d888-42b5-4113-e374-dc2281402465"
      },
      "source": [
        "number_topics = 80\n",
        "number_words = 10\n",
        "# Create and fit the LDA model\n",
        "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
        "lda.fit(count_data)\n",
        "# Print the topics found by the LDA model\n",
        "print(\"Topics found via LDA:\")\n",
        "print_topics(lda, count_vectorizer, number_words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topics found via LDA:\n",
            "\n",
            "Topic #0:\n",
            "line subject organ thank univers post mail host nntp know\n",
            "\n",
            "Topic #1:\n",
            "moral keith object write caltech subject line organ think host\n",
            "\n",
            "Topic #2:\n",
            "wire grind circuit subject outlet connect line need neutral write\n",
            "\n",
            "Topic #3:\n",
            "access digex subject line organ post write convex nntp host\n",
            "\n",
            "Topic #4:\n",
            "encrypt chip clipper secur govern escrow privaci technolog phone key\n",
            "\n",
            "Topic #5:\n",
            "line organ subject write nasa cost softwar articl post nntp\n",
            "\n",
            "Topic #6:\n",
            "line subject organ mous univers post nntp host john articl\n",
            "\n",
            "Topic #7:\n",
            "columbia game line subject organ gari upenn post univers nntp\n",
            "\n",
            "Topic #8:\n",
            "risc write subject line instruct organ articl louisvill hang mean\n",
            "\n",
            "Topic #9:\n",
            "bike like line good subject organ articl write look think\n",
            "\n",
            "Topic #10:\n",
            "line subject organ articl post write david nntp uoknor host\n",
            "\n",
            "Topic #11:\n",
            "write organ subject articl know line david plan gainey henrik\n",
            "\n",
            "Topic #12:\n",
            "subject organ line want like write articl think help time\n",
            "\n",
            "Topic #13:\n",
            "imag jpeg keyboard color file format convert type berkeley version\n",
            "\n",
            "Topic #14:\n",
            "entri number program file chip build serial line need section\n",
            "\n",
            "Topic #15:\n",
            "navi sequenc oasi organ line subject nswc echo host present\n",
            "\n",
            "Topic #16:\n",
            "israel isra arab jew palestinian state write attack articl subject\n",
            "\n",
            "Topic #17:\n",
            "dseg organ line subject pyron skndiv univers articl nntp host\n",
            "\n",
            "Topic #18:\n",
            "speed netcom line subject organ write articl time mitr brian\n",
            "\n",
            "Topic #19:\n",
            "homosexu cramer univers optilink inform nation space clayton center organ\n",
            "\n",
            "Topic #20:\n",
            "hell line organ subject oakland pain vela post write univers\n",
            "\n",
            "Topic #21:\n",
            "write subject articl line organ like dyer think post acceler\n",
            "\n",
            "Topic #22:\n",
            "flyer line hallam soderstrom pictur subject right organ puck sleev\n",
            "\n",
            "Topic #23:\n",
            "pitt bank gordon articl write pittsburgh subject line organ ingr\n",
            "\n",
            "Topic #24:\n",
            "write subject line organ psuvm articl post fido nntp pocket\n",
            "\n",
            "Topic #25:\n",
            "imag file data mail program inform softwar user avail includ\n",
            "\n",
            "Topic #26:\n",
            "right state govern clinton peopl presid constitut think militia organ\n",
            "\n",
            "Topic #27:\n",
            "peopl think right like govern countri person problem time want\n",
            "\n",
            "Topic #28:\n",
            "team play period hockey player goal king power draft edmonton\n",
            "\n",
            "Topic #29:\n",
            "write organ articl line subject rise good holland hulman distribut\n",
            "\n",
            "Topic #30:\n",
            "monitor line subject window organ oracl post nntp host write\n",
            "\n",
            "Topic #31:\n",
            "hockey line organ subject game playoff team leaf univers wing\n",
            "\n",
            "Topic #32:\n",
            "stratus appear write organ articl post subject line nntp copi\n",
            "\n",
            "Topic #33:\n",
            "request list contact version send univers mail program machin avail\n",
            "\n",
            "Topic #34:\n",
            "copi rchz cx_s sehari chzd cx_scx x_scx rlhz chzv zrlk\n",
            "\n",
            "Topic #35:\n",
            "gatech prism harri write subject organ georgia institut line technolog\n",
            "\n",
            "Topic #36:\n",
            "arizona cancer water write line organ smoke subject arbor ranck\n",
            "\n",
            "Topic #37:\n",
            "encrypt public secur ripem cryptographi algorithm cipher messag crypt know\n",
            "\n",
            "Topic #38:\n",
            "write like post organ articl subject line morri smith think\n",
            "\n",
            "Topic #39:\n",
            "buffalo subject organ line write post captain nntp host articl\n",
            "\n",
            "Topic #40:\n",
            "diseas doctor medic patient effect studi treatment caus organ test\n",
            "\n",
            "Topic #41:\n",
            "jesus sandvik austin write utexa kent christ appl christian lord\n",
            "\n",
            "Topic #42:\n",
            "gun file weapon firearm crime control like crimin state handgun\n",
            "\n",
            "Topic #43:\n",
            "line subject write organ articl know point post right udel\n",
            "\n",
            "Topic #44:\n",
            "scsi cool devic chip line power write subject tower time\n",
            "\n",
            "Topic #45:\n",
            "subject line post atheism write organ pope articl univers east\n",
            "\n",
            "Topic #46:\n",
            "line subject organ write post host articl year nntp state\n",
            "\n",
            "Topic #47:\n",
            "sale washington price subject line organ offer ship host distribut\n",
            "\n",
            "Topic #48:\n",
            "andrew line byte subject organ mellon carnegi bit problem pittsburgh\n",
            "\n",
            "Topic #49:\n",
            "scienc radar detector write organ subject scientif articl line think\n",
            "\n",
            "Topic #50:\n",
            "subject line organ freenet carleton packard hewlett write steven brandei\n",
            "\n",
            "Topic #51:\n",
            "line subject post organ host nntp appl printer univers distribut\n",
            "\n",
            "Topic #52:\n",
            "drug philip line informatik subject organ tammi write articl ucar\n",
            "\n",
            "Topic #53:\n",
            "nrhj wwiz gizw bhjn bxom pnei nriz tbxn pmfq wmbxn\n",
            "\n",
            "Topic #54:\n",
            "uchicago organ subject line midway articl chicago univers write like\n",
            "\n",
            "Topic #55:\n",
            "server motif window widget subject applic display client version avail\n",
            "\n",
            "Topic #56:\n",
            "netcom cleveland line organ freenet subject write articl iastat batf\n",
            "\n",
            "Topic #57:\n",
            "presid stephanopoulo work launch know go job say think satellit\n",
            "\n",
            "Topic #58:\n",
            "window file program output line write subject organ char creat\n",
            "\n",
            "Topic #59:\n",
            "insur alaska health write articl aurora sound privat cost nsmca\n",
            "\n",
            "Topic #60:\n",
            "space nasa orbit earth mission launch moon henri shuttl lunar\n",
            "\n",
            "Topic #61:\n",
            "game team year play player season think score good basebal\n",
            "\n",
            "Topic #62:\n",
            "paul jesus christian church sabbath cathol worship ceremoni subject sunday\n",
            "\n",
            "Topic #63:\n",
            "font line subject duke organ post write univers nntp host\n",
            "\n",
            "Topic #64:\n",
            "subject organ line jewish jake boni write articl post opinion\n",
            "\n",
            "Topic #65:\n",
            "line write organ subject post templ articl mark univers nada\n",
            "\n",
            "Topic #66:\n",
            "state ohio magnus articl write organ line subject year good\n",
            "\n",
            "Topic #67:\n",
            "drive disk control problem hard work line port subject organ\n",
            "\n",
            "Topic #68:\n",
            "islam muslim monash good write organ religion line subject rice\n",
            "\n",
            "Topic #69:\n",
            "colorado line subject post organ write host nntp articl boulder\n",
            "\n",
            "Topic #70:\n",
            "say go come know peopl time tell think leav happen\n",
            "\n",
            "Topic #71:\n",
            "cwru organ cleveland western line subject reserv post articl write\n",
            "\n",
            "Topic #72:\n",
            "govern write articl thor organ libertarian peopl steveh regul line\n",
            "\n",
            "Topic #73:\n",
            "line food post subject organ write batteri like articl know\n",
            "\n",
            "Topic #74:\n",
            "armenian turkish turk greek turkey armenia peopl argic serdar genocid\n",
            "\n",
            "Topic #75:\n",
            "weapon weaver firearm hunt miller committe line subject write organ\n",
            "\n",
            "Topic #76:\n",
            "virginia health report articl write organ white medic drug line\n",
            "\n",
            "Topic #77:\n",
            "christian believ think peopl know exist say bibl write mean\n",
            "\n",
            "Topic #78:\n",
            "card driver video mode color window line graphic subject organ\n",
            "\n",
            "Topic #79:\n",
            "indiana ucsc biggest section applic militari silver almanac licens firearm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "LrPaQEiuGRt3",
        "outputId": "39936c1d-2336-45f1-ff72-a2803fa7f896"
      },
      "source": [
        "cluster_probabilities = lda.transform(count_data)\n",
        "data_processed['target'] = np.argmax(cluster_probabilities, axis=1)\n",
        "data_processed.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lerxst thing subject nntp post host organ univ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>guykuo carson washington subject clock poll fi...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twilli purdu thoma willi subject question orga...</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jgreen amber green subject weitek organ harri ...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>head harvard jonathan mcdowel subject shuttl l...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  target\n",
              "0  lerxst thing subject nntp post host organ univ...       0\n",
              "1  guykuo carson washington subject clock poll fi...      30\n",
              "2  twilli purdu thoma willi subject question orga...      51\n",
              "3  jgreen amber green subject weitek organ harri ...      18\n",
              "4  head harvard jonathan mcdowel subject shuttl l...       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJNJOHB9GkKP"
      },
      "source": [
        "import seaborn as sns\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "At3W9AMVGnga",
        "outputId": "de9c2d9e-c4b4-4a62-d94e-78faa868852b"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "sns.countplot(x=data_processed.target);\n",
        "ax.set_title(\"Number of articles that correspond to the topic\");\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ07JMrCRAYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b09cc3f-06bc-42e7-a6af-90ae787f2600"
      },
      "source": [
        "#Loading the data set - training data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "mydata_train = fetch_20newsgroups(subset='train', shuffle=True, remove = ('headers', 'footers', 'quotes'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpyae_wBRHIU",
        "outputId": "ad2d28d8-10b7-4753-bb0f-2f6080a4e034"
      },
      "source": [
        "list(mydata_train)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'filenames', 'target_names', 'target', 'DESCR']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsmrhUPeRJ9l",
        "outputId": "7384ee19-c2b2-4bb3-bcf4-51020e4a9ae6"
      },
      "source": [
        "print('Training data size:', len(mydata_train['data']))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size: 11314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv1WrOdSRONT",
        "outputId": "d419111b-2722-4d47-8534-1c72467913a3"
      },
      "source": [
        "# Printing all the categories\n",
        "mydata_train.target_names"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krZedPVlRRxL",
        "outputId": "76299e50-a23f-42b1-97d2-12a240983857"
      },
      "source": [
        "\n",
        "# Finding frequency of each category\n",
        "targets, frequency = np.unique(mydata_train.target, return_counts=True)\n",
        "targets, frequency"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "        17, 18, 19]),\n",
              " array([480, 584, 591, 590, 578, 593, 585, 594, 598, 597, 600, 595, 591,\n",
              "        594, 593, 599, 546, 564, 465, 377]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSr8qhRVRWTb",
        "outputId": "5caf507d-ea63-443d-d9e9-81a19932c32b"
      },
      "source": [
        "targets_str = np.array(mydata_train.target_names)\n",
        "print(list(zip(targets_str, frequency)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('alt.atheism', 480), ('comp.graphics', 584), ('comp.os.ms-windows.misc', 591), ('comp.sys.ibm.pc.hardware', 590), ('comp.sys.mac.hardware', 578), ('comp.windows.x', 593), ('misc.forsale', 585), ('rec.autos', 594), ('rec.motorcycles', 598), ('rec.sport.baseball', 597), ('rec.sport.hockey', 600), ('sci.crypt', 595), ('sci.electronics', 591), ('sci.med', 594), ('sci.space', 593), ('soc.religion.christian', 599), ('talk.politics.guns', 546), ('talk.politics.mideast', 564), ('talk.politics.misc', 465), ('talk.religion.misc', 377)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pZ_KnVPRZSm"
      },
      "source": [
        "mydata_test = fetch_20newsgroups(subset='test', shuffle=True, remove = ('headers', 'footers', 'quotes'))\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEcSYoJmRcUc",
        "outputId": "1509ac46-4623-4f69-ac1e-4da6066a6450"
      },
      "source": [
        "print('Testing data size:', len(mydata_test['data']))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing data size: 7532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "_aSKch0QRf_o",
        "outputId": "31d847de-0773-4f29-837e-3948db5621bb"
      },
      "source": [
        "mydata_train_df = pd.DataFrame({'data': mydata_train.data, 'target': mydata_train.target})\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I was wondering if anyone out there could enli...       7\n",
              "1  A fair number of brave souls who upgraded thei...       4\n",
              "2  well folks, my mac plus finally gave up the gh...       4\n",
              "3  \\nDo you have Weitek's address/phone number?  ...       1\n",
              "4  From article <C5owCB.n3p@world.std.com>, by to...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "ttru-cT7Rj9K",
        "outputId": "db1200a2-3b66-4867-99d3-9523855dfa82"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "import re\n",
        "import string\n",
        "\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_train_df['data'] = mydata_train_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks  my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\ndo you have weitek s address phone number   ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>from article      world std com   by tombaker ...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i was wondering if anyone out there could enli...       7\n",
              "1  a fair number of brave souls who upgraded thei...       4\n",
              "2  well folks  my mac plus finally gave up the gh...       4\n",
              "3  \\ndo you have weitek s address phone number   ...       1\n",
              "4  from article      world std com   by tombaker ...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "8f6jlH07RoBH",
        "outputId": "616ac2ac-6fc0-4b90-cef5-f11e467346e6"
      },
      "source": [
        "mydata_test_df = pd.DataFrame({'data': mydata_test.data, 'target': mydata_test.target})\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIn a word, yes.\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThey were attacking the Iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nI've just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I am a little confused on all of the models of...       7\n",
              "1  I'm not familiar at all with the format of the...       5\n",
              "2                                \\nIn a word, yes.\\n       0\n",
              "3  \\nThey were attacking the Iraqis to drive them...      17\n",
              "4  \\nI've just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "tUjU5KP5RrlP",
        "outputId": "58582e8a-a3c4-4021-fefe-279a8d8d3e8d"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_test_df['data'] = mydata_test_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i m not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nin a word  yes \\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nthey were attacking the iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\ni ve just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i am a little confused on all of the models of...       7\n",
              "1  i m not familiar at all with the format of the...       5\n",
              "2                                \\nin a word  yes \\n       0\n",
              "3  \\nthey were attacking the iraqis to drive them...      17\n",
              "4  \\ni ve just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUELDX2-bNNg",
        "outputId": "d9248a62-c68e-4173-8a4a-87a8bee32363"
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "X_train_cv = count_vect.fit_transform(mydata_train_df.data) # fit_transform learns the\n",
        "X_test_cv = count_vect.transform(mydata_test_df.data) # transform uses the same vocab an\n",
        "print(X_train_cv.shape)\n",
        "print(type(X_train_cv))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11314, 67822)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRUtZ9-VAkiY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
        "from keras.models import Model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Oz3FjnHAqOw",
        "outputId": "5b785869-d42a-4b97-fabb-6dee503dc5c9"
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian'] \n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, \n",
        "                                      categories=categories,)\n",
        "\n",
        "print (newsgroups_train.target_names)\n",
        "print (len(newsgroups_train.data))\n",
        "\n",
        "#print (newsgroups_train.data[1])\n",
        "print(\"\\n\".join(newsgroups_train.data[0].split(\"\\n\")[10:15]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'soc.religion.christian']\n",
            "1079\n",
            "   WASHINGTON, April 19  -- A symposium on the Dead Sea \n",
            "Scrolls will be held at the Library of Congress on Wednesday,\n",
            "April 21, and Thursday, April 22.  The two-day program, cosponsored\n",
            "by the library and Baltimore Hebrew University, with additional\n",
            "support from the Project Judaica Foundation, will be held in the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9VVEyQWAu6m",
        "outputId": "92834333-d153-4c80-97b4-cc8c46e5dda9"
      },
      "source": [
        "%%time\n",
        "\n",
        "texts = []\n",
        "\n",
        "labels=newsgroups_train.target\n",
        "texts = newsgroups_train.data\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NB_WORDS = 20000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "print (sequences[0][:10])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19, 8762, 3621, 11894, 58, 8762, 3621, 43, 1472, 2]\n",
            "CPU times: user 613 ms, sys: 9.02 ms, total: 622 ms\n",
            "Wall time: 625 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C-jZJV1Ay0E",
        "outputId": "e1c53f3f-812f-416e-9c60-66caac605621"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20030 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3leeqbJA1-q",
        "outputId": "6736055d-46ca-4823-ace4-eb1f310faffe"
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print (data.shape)\n",
        "print (data[0][200:250])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1079, 1000)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0    19  8762  3621 11894    58  8762  3621\n",
            "    43  1472     2  2130     3   189   450  1001  3622  2980  1682   476\n",
            "   627    50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TATKrjgmA6lK",
        "outputId": "b97b2e8f-bd6b-4e1e-dd9a-b9d0cd05e3e7"
      },
      "source": [
        "labels = to_categorical(np.array(labels))\n",
        "\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1079, 1000)\n",
            "Shape of label tensor: (1079, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKD1nppNA_cG",
        "outputId": "54932cae-f89b-4cf7-86e3-7986f9ce57b3"
      },
      "source": [
        "VALIDATION_SPLIT = 0.1\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices) \n",
        "data = data[indices] \n",
        "labels = labels[indices] \n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples] \n",
        "y_train = labels[:-nb_validation_samples] \n",
        "x_val = data[-nb_validation_samples:] \n",
        "y_val = labels[-nb_validation_samples:] \n",
        "\n",
        "print (x_train.shape)\n",
        "print (y_train.shape)\n",
        "\n",
        "print('Number of positive and negative reviews in traing and validation set ') \n",
        "print (y_train.sum(axis=0))\n",
        "print (y_val.sum(axis=0))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(972, 1000)\n",
            "(972, 2)\n",
            "Number of positive and negative reviews in traing and validation set \n",
            "[438. 534.]\n",
            "[42. 65.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "1jN7GicoBSkh",
        "outputId": "b2902851-99b5-4cd9-bb00-e9285726fde9"
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros.\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print (embedding_matrix.shape)\n",
        "\n",
        "print (embedding_matrix[0][:10])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6fb53264530f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# words not found in embedding index will be all-zeros.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StT4yPYaBUgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d86aeee-ed25-4255-c548-8670139ea539"
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix], \n",
        "                            input_length=MAX_SEQUENCE_LENGTH, \n",
        "                            trainable=False)\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32') \n",
        "embedded_sequences = embedding_layer(sequence_input) \n",
        "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences) \n",
        "l_pool1 = MaxPooling1D(5)(l_cov1) \n",
        "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1) \n",
        "l_pool2 = MaxPooling1D(5)(l_cov2) \n",
        "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2) \n",
        "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
        "\n",
        "l_flat = Flatten()(l_pool3) \n",
        "l_dense = Dense(128, activation='relu')(l_flat) \n",
        "preds = Dense(2, activation='softmax')(l_dense)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1000)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 1000, 100)         2003100   \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 996, 128)          64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 199, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 195, 128)          82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 39, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 35, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 2,248,094\n",
            "Trainable params: 244,994\n",
            "Non-trainable params: 2,003,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohWKe6xrBfGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6eeb7a-2a88-4072-b07c-f8363a4c19b4"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "                    epochs=500, batch_size=512)   "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 10s 5s/step - loss: 0.8529 - acc: 0.4857 - val_loss: 0.6691 - val_acc: 0.6075\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.7107 - acc: 0.5035 - val_loss: 0.7096 - val_acc: 0.3925\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6946 - acc: 0.4985 - val_loss: 0.6721 - val_acc: 0.6075\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.7037 - acc: 0.5420 - val_loss: 0.6780 - val_acc: 0.6075\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6880 - acc: 0.5484 - val_loss: 0.6857 - val_acc: 0.6075\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6889 - acc: 0.5466 - val_loss: 0.6720 - val_acc: 0.6075\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6882 - acc: 0.5525 - val_loss: 0.6719 - val_acc: 0.6075\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6853 - acc: 0.5544 - val_loss: 0.6871 - val_acc: 0.6075\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6891 - acc: 0.5679 - val_loss: 0.6747 - val_acc: 0.6075\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 9s 5s/step - loss: 0.6861 - acc: 0.5512 - val_loss: 0.6693 - val_acc: 0.6075\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6845 - acc: 0.5551 - val_loss: 0.6800 - val_acc: 0.6075\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6848 - acc: 0.5564 - val_loss: 0.6797 - val_acc: 0.6075\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6847 - acc: 0.5531 - val_loss: 0.6702 - val_acc: 0.6075\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6830 - acc: 0.5518 - val_loss: 0.6734 - val_acc: 0.6075\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6828 - acc: 0.5485 - val_loss: 0.6765 - val_acc: 0.6075\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6818 - acc: 0.5498 - val_loss: 0.6685 - val_acc: 0.6075\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6826 - acc: 0.5446 - val_loss: 0.6721 - val_acc: 0.6075\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6791 - acc: 0.5485 - val_loss: 0.6698 - val_acc: 0.6075\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 0.6779 - acc: 0.5479 - val_loss: 0.6701 - val_acc: 0.6075\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6763 - acc: 0.5557 - val_loss: 0.6717 - val_acc: 0.6075\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 0.6747 - acc: 0.5614 - val_loss: 0.6709 - val_acc: 0.6075\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6756 - acc: 0.5637 - val_loss: 0.6674 - val_acc: 0.6075\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6742 - acc: 0.6021 - val_loss: 0.6681 - val_acc: 0.6262\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6691 - acc: 0.5741 - val_loss: 0.6589 - val_acc: 0.6075\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 11s 6s/step - loss: 0.6718 - acc: 0.5713 - val_loss: 0.6726 - val_acc: 0.6822\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 10s 4s/step - loss: 0.6682 - acc: 0.6559 - val_loss: 0.6582 - val_acc: 0.6075\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6589 - acc: 0.5684 - val_loss: 0.6733 - val_acc: 0.7477\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6613 - acc: 0.7697 - val_loss: 0.6507 - val_acc: 0.6075\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6561 - acc: 0.5685 - val_loss: 0.6542 - val_acc: 0.6449\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6503 - acc: 0.7286 - val_loss: 0.6426 - val_acc: 0.6075\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6474 - acc: 0.5730 - val_loss: 0.6586 - val_acc: 0.7850\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6403 - acc: 0.7971 - val_loss: 0.6355 - val_acc: 0.6075\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6437 - acc: 0.6452 - val_loss: 0.6413 - val_acc: 0.7850\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6434 - acc: 0.7394 - val_loss: 0.6488 - val_acc: 0.7103\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6314 - acc: 0.6742 - val_loss: 0.6139 - val_acc: 0.6542\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6265 - acc: 0.5926 - val_loss: 0.6187 - val_acc: 0.8131\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6230 - acc: 0.7269 - val_loss: 0.6050 - val_acc: 0.7383\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6140 - acc: 0.7195 - val_loss: 0.5997 - val_acc: 0.6542\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.6048 - acc: 0.6314 - val_loss: 0.6393 - val_acc: 0.5327\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.5987 - acc: 0.6577 - val_loss: 0.5940 - val_acc: 0.6542\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.5869 - acc: 0.6545 - val_loss: 0.5887 - val_acc: 0.8692\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.5654 - acc: 0.8807 - val_loss: 0.5712 - val_acc: 0.8692\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.5488 - acc: 0.8351 - val_loss: 0.5492 - val_acc: 0.7290\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.5316 - acc: 0.8040 - val_loss: 0.5540 - val_acc: 0.8785\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.5149 - acc: 0.8886 - val_loss: 0.5146 - val_acc: 0.7196\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.5139 - acc: 0.7717 - val_loss: 0.4847 - val_acc: 0.8037\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 0.4665 - acc: 0.8324 - val_loss: 0.4781 - val_acc: 0.8972\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.4532 - acc: 0.8733 - val_loss: 0.4700 - val_acc: 0.8785\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.4336 - acc: 0.8775 - val_loss: 0.4044 - val_acc: 0.9252\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.3817 - acc: 0.9048 - val_loss: 0.4049 - val_acc: 0.9252\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.3917 - acc: 0.8774 - val_loss: 0.4835 - val_acc: 0.7477\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.4370 - acc: 0.8003 - val_loss: 0.3264 - val_acc: 0.9252\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.3460 - acc: 0.8731 - val_loss: 0.3876 - val_acc: 0.8318\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.3903 - acc: 0.8113 - val_loss: 0.3790 - val_acc: 0.8785\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.3497 - acc: 0.9045 - val_loss: 0.3203 - val_acc: 0.8879\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.3324 - acc: 0.8597 - val_loss: 0.2942 - val_acc: 0.9346\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.3102 - acc: 0.9197 - val_loss: 0.2839 - val_acc: 0.9159\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.3097 - acc: 0.8709 - val_loss: 0.2614 - val_acc: 0.9439\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.2652 - acc: 0.9284 - val_loss: 0.2651 - val_acc: 0.9346\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.2692 - acc: 0.9154 - val_loss: 0.2608 - val_acc: 0.9159\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.2499 - acc: 0.9113 - val_loss: 0.3269 - val_acc: 0.8879\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.2651 - acc: 0.9287 - val_loss: 0.2508 - val_acc: 0.9159\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.2487 - acc: 0.9004 - val_loss: 0.2516 - val_acc: 0.9252\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.2171 - acc: 0.9467 - val_loss: 0.2101 - val_acc: 0.9346\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.2071 - acc: 0.9225 - val_loss: 0.2019 - val_acc: 0.9346\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1915 - acc: 0.9448 - val_loss: 0.1995 - val_acc: 0.9346\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1751 - acc: 0.9433 - val_loss: 0.1867 - val_acc: 0.9346\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1701 - acc: 0.9461 - val_loss: 0.1908 - val_acc: 0.9439\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1558 - acc: 0.9508 - val_loss: 0.1736 - val_acc: 0.9346\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1428 - acc: 0.9535 - val_loss: 0.2036 - val_acc: 0.9252\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1545 - acc: 0.9634 - val_loss: 0.1635 - val_acc: 0.9346\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1449 - acc: 0.9530 - val_loss: 0.1648 - val_acc: 0.9346\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1423 - acc: 0.9414 - val_loss: 0.2206 - val_acc: 0.9346\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1372 - acc: 0.9731 - val_loss: 0.1767 - val_acc: 0.9346\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1478 - acc: 0.9402 - val_loss: 0.2374 - val_acc: 0.9346\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1431 - acc: 0.9607 - val_loss: 0.1600 - val_acc: 0.9439\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1181 - acc: 0.9557 - val_loss: 0.2054 - val_acc: 0.9346\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1299 - acc: 0.9655 - val_loss: 0.1595 - val_acc: 0.9439\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1176 - acc: 0.9565 - val_loss: 0.1779 - val_acc: 0.9439\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1067 - acc: 0.9708 - val_loss: 0.1450 - val_acc: 0.9346\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0899 - acc: 0.9658 - val_loss: 0.1890 - val_acc: 0.9252\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.1021 - acc: 0.9722 - val_loss: 0.1394 - val_acc: 0.9346\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0788 - acc: 0.9711 - val_loss: 0.1645 - val_acc: 0.9439\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0831 - acc: 0.9851 - val_loss: 0.1363 - val_acc: 0.9346\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 0.0706 - acc: 0.9691 - val_loss: 0.1608 - val_acc: 0.9346\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0721 - acc: 0.9885 - val_loss: 0.1283 - val_acc: 0.9533\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0625 - acc: 0.9779 - val_loss: 0.1379 - val_acc: 0.9533\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0545 - acc: 0.9913 - val_loss: 0.1252 - val_acc: 0.9533\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0507 - acc: 0.9865 - val_loss: 0.1470 - val_acc: 0.9346\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0557 - acc: 0.9932 - val_loss: 0.1386 - val_acc: 0.9533\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0613 - acc: 0.9703 - val_loss: 0.1608 - val_acc: 0.9439\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0542 - acc: 0.9953 - val_loss: 0.1261 - val_acc: 0.9533\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0463 - acc: 0.9892 - val_loss: 0.1246 - val_acc: 0.9533\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 0.0385 - acc: 0.9973 - val_loss: 0.1177 - val_acc: 0.9533\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 9s 5s/step - loss: 0.0356 - acc: 0.9953 - val_loss: 0.1164 - val_acc: 0.9533\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 11s 5s/step - loss: 0.0298 - acc: 0.9953 - val_loss: 0.1243 - val_acc: 0.9533\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0314 - acc: 0.9980 - val_loss: 0.1165 - val_acc: 0.9533\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0283 - acc: 0.9953 - val_loss: 0.1197 - val_acc: 0.9533\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0276 - acc: 0.9980 - val_loss: 0.1146 - val_acc: 0.9533\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0252 - acc: 0.9960 - val_loss: 0.1135 - val_acc: 0.9533\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0225 - acc: 0.9973 - val_loss: 0.1134 - val_acc: 0.9533\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0201 - acc: 0.9973 - val_loss: 0.1130 - val_acc: 0.9533\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0183 - acc: 0.9986 - val_loss: 0.1145 - val_acc: 0.9626\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0181 - acc: 0.9980 - val_loss: 0.1126 - val_acc: 0.9533\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0172 - acc: 0.9986 - val_loss: 0.1202 - val_acc: 0.9533\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0200 - acc: 0.9973 - val_loss: 0.1571 - val_acc: 0.9533\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0311 - acc: 0.9919 - val_loss: 0.1852 - val_acc: 0.9252\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0323 - acc: 0.9973 - val_loss: 0.1487 - val_acc: 0.9533\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0257 - acc: 0.9920 - val_loss: 0.1422 - val_acc: 0.9533\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0219 - acc: 0.9987 - val_loss: 0.1275 - val_acc: 0.9626\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0198 - acc: 0.9953 - val_loss: 0.1110 - val_acc: 0.9626\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.1207 - val_acc: 0.9533\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.1233 - val_acc: 0.9626\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0134 - acc: 0.9987 - val_loss: 0.1078 - val_acc: 0.9626\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.1052 - val_acc: 0.9626\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.1197 - val_acc: 0.9626\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9626\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9626\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1146 - val_acc: 0.9626\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9626\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9626\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9626\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9626\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.1083 - val_acc: 0.9626\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 0.9533\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9626\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9626\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9626\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1088 - val_acc: 0.9626\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9626\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9626\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9626\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 0.9626\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9626\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1088 - val_acc: 0.9626\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9626\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1109 - val_acc: 0.9626\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9626\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9626\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9626\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9626\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9626\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1112 - val_acc: 0.9626\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9626\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1110 - val_acc: 0.9626\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9626\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1121 - val_acc: 0.9626\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9626\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1124 - val_acc: 0.9626\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1130 - val_acc: 0.9626\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1127 - val_acc: 0.9626\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9626\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1142 - val_acc: 0.9626\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1144 - val_acc: 0.9626\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1141 - val_acc: 0.9626\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1140 - val_acc: 0.9626\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9626\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1148 - val_acc: 0.9626\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9626\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 9.7305e-04 - acc: 1.0000 - val_loss: 0.1165 - val_acc: 0.9626\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 9.4280e-04 - acc: 1.0000 - val_loss: 0.1160 - val_acc: 0.9626\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.8688e-04 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9626\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.1043e-04 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9626\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.3770e-04 - acc: 1.0000 - val_loss: 0.1173 - val_acc: 0.9626\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.4593e-04 - acc: 1.0000 - val_loss: 0.1175 - val_acc: 0.9626\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.3310e-04 - acc: 1.0000 - val_loss: 0.1179 - val_acc: 0.9626\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.3422e-04 - acc: 1.0000 - val_loss: 0.1185 - val_acc: 0.9626\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.5547e-04 - acc: 1.0000 - val_loss: 0.1185 - val_acc: 0.9626\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.9455e-04 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9626\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.0542e-04 - acc: 1.0000 - val_loss: 0.1199 - val_acc: 0.9626\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.6414e-04 - acc: 1.0000 - val_loss: 0.1193 - val_acc: 0.9626\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.4827e-04 - acc: 1.0000 - val_loss: 0.1196 - val_acc: 0.9626\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.2064e-04 - acc: 1.0000 - val_loss: 0.1198 - val_acc: 0.9626\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.9921e-04 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 0.9626\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.3906e-04 - acc: 1.0000 - val_loss: 0.1215 - val_acc: 0.9626\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.9297e-04 - acc: 1.0000 - val_loss: 0.1203 - val_acc: 0.9626\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.1838e-04 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9626\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.1775e-04 - acc: 1.0000 - val_loss: 0.1228 - val_acc: 0.9626\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.2527e-04 - acc: 1.0000 - val_loss: 0.1226 - val_acc: 0.9626\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.8067e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9626\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.8435e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9626\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.4083e-04 - acc: 1.0000 - val_loss: 0.1238 - val_acc: 0.9626\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.4902e-04 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9626\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.4236e-04 - acc: 1.0000 - val_loss: 0.1238 - val_acc: 0.9626\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.2696e-04 - acc: 1.0000 - val_loss: 0.1235 - val_acc: 0.9626\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.3435e-04 - acc: 1.0000 - val_loss: 0.1240 - val_acc: 0.9626\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.8703e-04 - acc: 1.0000 - val_loss: 0.1254 - val_acc: 0.9626\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.9159e-04 - acc: 1.0000 - val_loss: 0.1265 - val_acc: 0.9626\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.6303e-04 - acc: 1.0000 - val_loss: 0.1255 - val_acc: 0.9626\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.8092e-04 - acc: 1.0000 - val_loss: 0.1248 - val_acc: 0.9626\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.6980e-04 - acc: 1.0000 - val_loss: 0.1256 - val_acc: 0.9626\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.6640e-04 - acc: 1.0000 - val_loss: 0.1265 - val_acc: 0.9626\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.3354e-04 - acc: 1.0000 - val_loss: 0.1272 - val_acc: 0.9626\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.2865e-04 - acc: 1.0000 - val_loss: 0.1269 - val_acc: 0.9626\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.3648e-04 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 0.9626\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.1828e-04 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9626\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.0898e-04 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 0.9626\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.1456e-04 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9626\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.1439e-04 - acc: 1.0000 - val_loss: 0.1279 - val_acc: 0.9626\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.7911e-04 - acc: 1.0000 - val_loss: 0.1284 - val_acc: 0.9626\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.9524e-04 - acc: 1.0000 - val_loss: 0.1291 - val_acc: 0.9626\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.7045e-04 - acc: 1.0000 - val_loss: 0.1298 - val_acc: 0.9626\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.7658e-04 - acc: 1.0000 - val_loss: 0.1294 - val_acc: 0.9626\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.5614e-04 - acc: 1.0000 - val_loss: 0.1291 - val_acc: 0.9626\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.5207e-04 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9626\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.4683e-04 - acc: 1.0000 - val_loss: 0.1304 - val_acc: 0.9626\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.3604e-04 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9626\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.2818e-04 - acc: 1.0000 - val_loss: 0.1307 - val_acc: 0.9626\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.3074e-04 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9626\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.3044e-04 - acc: 1.0000 - val_loss: 0.1306 - val_acc: 0.9626\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.3698e-04 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9626\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.2678e-04 - acc: 1.0000 - val_loss: 0.1321 - val_acc: 0.9626\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.2216e-04 - acc: 1.0000 - val_loss: 0.1328 - val_acc: 0.9626\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.0295e-04 - acc: 1.0000 - val_loss: 0.1324 - val_acc: 0.9626\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.1381e-04 - acc: 1.0000 - val_loss: 0.1318 - val_acc: 0.9626\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.0490e-04 - acc: 1.0000 - val_loss: 0.1322 - val_acc: 0.9626\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.0582e-04 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 0.9626\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.0060e-04 - acc: 1.0000 - val_loss: 0.1338 - val_acc: 0.9626\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.7546e-04 - acc: 1.0000 - val_loss: 0.1338 - val_acc: 0.9626\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.9435e-04 - acc: 1.0000 - val_loss: 0.1335 - val_acc: 0.9626\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.8800e-04 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9626\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.9202e-04 - acc: 1.0000 - val_loss: 0.1342 - val_acc: 0.9626\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.6731e-04 - acc: 1.0000 - val_loss: 0.1350 - val_acc: 0.9626\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.8133e-04 - acc: 1.0000 - val_loss: 0.1349 - val_acc: 0.9626\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.6908e-04 - acc: 1.0000 - val_loss: 0.1348 - val_acc: 0.9626\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.7874e-04 - acc: 1.0000 - val_loss: 0.1348 - val_acc: 0.9626\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.5536e-04 - acc: 1.0000 - val_loss: 0.1351 - val_acc: 0.9626\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.5561e-04 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9626\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.6130e-04 - acc: 1.0000 - val_loss: 0.1359 - val_acc: 0.9626\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.5831e-04 - acc: 1.0000 - val_loss: 0.1363 - val_acc: 0.9626\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.5457e-04 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9626\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.4583e-04 - acc: 1.0000 - val_loss: 0.1366 - val_acc: 0.9626\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.4098e-04 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9626\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.3909e-04 - acc: 1.0000 - val_loss: 0.1366 - val_acc: 0.9626\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.3649e-04 - acc: 1.0000 - val_loss: 0.1369 - val_acc: 0.9626\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.3315e-04 - acc: 1.0000 - val_loss: 0.1375 - val_acc: 0.9626\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.3957e-04 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9626\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.3607e-04 - acc: 1.0000 - val_loss: 0.1382 - val_acc: 0.9626\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.2656e-04 - acc: 1.0000 - val_loss: 0.1382 - val_acc: 0.9626\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.2598e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9626\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.3391e-04 - acc: 1.0000 - val_loss: 0.1378 - val_acc: 0.9626\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.2210e-04 - acc: 1.0000 - val_loss: 0.1382 - val_acc: 0.9626\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.2786e-04 - acc: 1.0000 - val_loss: 0.1386 - val_acc: 0.9626\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.2283e-04 - acc: 1.0000 - val_loss: 0.1392 - val_acc: 0.9626\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.1949e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9626\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.1788e-04 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9626\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.1516e-04 - acc: 1.0000 - val_loss: 0.1396 - val_acc: 0.9626\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.1308e-04 - acc: 1.0000 - val_loss: 0.1397 - val_acc: 0.9626\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.0655e-04 - acc: 1.0000 - val_loss: 0.1398 - val_acc: 0.9626\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.0533e-04 - acc: 1.0000 - val_loss: 0.1401 - val_acc: 0.9626\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.1037e-04 - acc: 1.0000 - val_loss: 0.1404 - val_acc: 0.9626\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.0952e-04 - acc: 1.0000 - val_loss: 0.1403 - val_acc: 0.9626\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.1192e-04 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 0.9626\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.0331e-04 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9626\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.0500e-04 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 0.9626\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 9.6059e-05 - acc: 1.0000 - val_loss: 0.1411 - val_acc: 0.9626\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 9.5068e-05 - acc: 1.0000 - val_loss: 0.1415 - val_acc: 0.9626\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.0071e-04 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9626\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 9.7077e-05 - acc: 1.0000 - val_loss: 0.1417 - val_acc: 0.9626\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 9.7856e-05 - acc: 1.0000 - val_loss: 0.1418 - val_acc: 0.9626\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 9.2886e-05 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9626\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.9972e-05 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9626\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 9.5047e-05 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 0.9626\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 9.3090e-05 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9626\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.7238e-05 - acc: 1.0000 - val_loss: 0.1428 - val_acc: 0.9626\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.7251e-05 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9626\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 9.0143e-05 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9626\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.2541e-05 - acc: 1.0000 - val_loss: 0.1432 - val_acc: 0.9626\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.6882e-05 - acc: 1.0000 - val_loss: 0.1435 - val_acc: 0.9626\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.8736e-05 - acc: 1.0000 - val_loss: 0.1438 - val_acc: 0.9626\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.6949e-05 - acc: 1.0000 - val_loss: 0.1440 - val_acc: 0.9626\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.2425e-05 - acc: 1.0000 - val_loss: 0.1439 - val_acc: 0.9626\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.6438e-05 - acc: 1.0000 - val_loss: 0.1439 - val_acc: 0.9626\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.9913e-05 - acc: 1.0000 - val_loss: 0.1440 - val_acc: 0.9626\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.6896e-05 - acc: 1.0000 - val_loss: 0.1444 - val_acc: 0.9626\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.7365e-05 - acc: 1.0000 - val_loss: 0.1447 - val_acc: 0.9626\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 8.1133e-05 - acc: 1.0000 - val_loss: 0.1445 - val_acc: 0.9626\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.1660e-05 - acc: 1.0000 - val_loss: 0.1449 - val_acc: 0.9626\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.6294e-05 - acc: 1.0000 - val_loss: 0.1449 - val_acc: 0.9626\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.5149e-05 - acc: 1.0000 - val_loss: 0.1453 - val_acc: 0.9626\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.1571e-05 - acc: 1.0000 - val_loss: 0.1455 - val_acc: 0.9626\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.5984e-05 - acc: 1.0000 - val_loss: 0.1454 - val_acc: 0.9626\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.0755e-05 - acc: 1.0000 - val_loss: 0.1456 - val_acc: 0.9626\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.9813e-05 - acc: 1.0000 - val_loss: 0.1458 - val_acc: 0.9626\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.7501e-05 - acc: 1.0000 - val_loss: 0.1462 - val_acc: 0.9626\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.6901e-05 - acc: 1.0000 - val_loss: 0.1461 - val_acc: 0.9626\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.0480e-05 - acc: 1.0000 - val_loss: 0.1460 - val_acc: 0.9626\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 7.3667e-05 - acc: 1.0000 - val_loss: 0.1462 - val_acc: 0.9626\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.2242e-05 - acc: 1.0000 - val_loss: 0.1467 - val_acc: 0.9626\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.6140e-05 - acc: 1.0000 - val_loss: 0.1469 - val_acc: 0.9626\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.9854e-05 - acc: 1.0000 - val_loss: 0.1470 - val_acc: 0.9626\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 9s 5s/step - loss: 6.0778e-05 - acc: 1.0000 - val_loss: 0.1469 - val_acc: 0.9626\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.0921e-05 - acc: 1.0000 - val_loss: 0.1470 - val_acc: 0.9626\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.3860e-05 - acc: 1.0000 - val_loss: 0.1471 - val_acc: 0.9626\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.6607e-05 - acc: 1.0000 - val_loss: 0.1473 - val_acc: 0.9626\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.4717e-05 - acc: 1.0000 - val_loss: 0.1477 - val_acc: 0.9626\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.9389e-05 - acc: 1.0000 - val_loss: 0.1480 - val_acc: 0.9626\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.8170e-05 - acc: 1.0000 - val_loss: 0.1481 - val_acc: 0.9626\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.0740e-05 - acc: 1.0000 - val_loss: 0.1479 - val_acc: 0.9626\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.9444e-05 - acc: 1.0000 - val_loss: 0.1479 - val_acc: 0.9626\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 6.1602e-05 - acc: 1.0000 - val_loss: 0.1482 - val_acc: 0.9626\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.6878e-05 - acc: 1.0000 - val_loss: 0.1485 - val_acc: 0.9626\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.7292e-05 - acc: 1.0000 - val_loss: 0.1486 - val_acc: 0.9626\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.6346e-05 - acc: 1.0000 - val_loss: 0.1488 - val_acc: 0.9626\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.2775e-05 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 0.9626\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.5097e-05 - acc: 1.0000 - val_loss: 0.1490 - val_acc: 0.9626\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.9013e-05 - acc: 1.0000 - val_loss: 0.1490 - val_acc: 0.9626\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.1416e-05 - acc: 1.0000 - val_loss: 0.1491 - val_acc: 0.9626\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.4938e-05 - acc: 1.0000 - val_loss: 0.1493 - val_acc: 0.9626\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.2681e-05 - acc: 1.0000 - val_loss: 0.1495 - val_acc: 0.9626\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.0334e-05 - acc: 1.0000 - val_loss: 0.1497 - val_acc: 0.9626\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.3123e-05 - acc: 1.0000 - val_loss: 0.1497 - val_acc: 0.9626\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.9321e-05 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9626\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 5.3495e-05 - acc: 1.0000 - val_loss: 0.1500 - val_acc: 0.9626\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.8355e-05 - acc: 1.0000 - val_loss: 0.1501 - val_acc: 0.9626\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.7030e-05 - acc: 1.0000 - val_loss: 0.1504 - val_acc: 0.9626\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.9644e-05 - acc: 1.0000 - val_loss: 0.1505 - val_acc: 0.9626\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.4995e-05 - acc: 1.0000 - val_loss: 0.1507 - val_acc: 0.9626\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.5903e-05 - acc: 1.0000 - val_loss: 0.1507 - val_acc: 0.9626\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.9126e-05 - acc: 1.0000 - val_loss: 0.1507 - val_acc: 0.9626\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.7151e-05 - acc: 1.0000 - val_loss: 0.1508 - val_acc: 0.9626\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.7993e-05 - acc: 1.0000 - val_loss: 0.1509 - val_acc: 0.9626\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.3989e-05 - acc: 1.0000 - val_loss: 0.1513 - val_acc: 0.9626\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.6702e-05 - acc: 1.0000 - val_loss: 0.1514 - val_acc: 0.9626\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.8155e-05 - acc: 1.0000 - val_loss: 0.1515 - val_acc: 0.9626\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.6457e-05 - acc: 1.0000 - val_loss: 0.1516 - val_acc: 0.9626\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.6196e-05 - acc: 1.0000 - val_loss: 0.1517 - val_acc: 0.9626\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.2876e-05 - acc: 1.0000 - val_loss: 0.1517 - val_acc: 0.9626\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.3785e-05 - acc: 1.0000 - val_loss: 0.1520 - val_acc: 0.9626\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.0742e-05 - acc: 1.0000 - val_loss: 0.1520 - val_acc: 0.9626\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.2369e-05 - acc: 1.0000 - val_loss: 0.1520 - val_acc: 0.9626\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.4040e-05 - acc: 1.0000 - val_loss: 0.1521 - val_acc: 0.9626\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.2911e-05 - acc: 1.0000 - val_loss: 0.1525 - val_acc: 0.9626\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.9560e-05 - acc: 1.0000 - val_loss: 0.1528 - val_acc: 0.9626\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.0534e-05 - acc: 1.0000 - val_loss: 0.1528 - val_acc: 0.9626\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.8604e-05 - acc: 1.0000 - val_loss: 0.1527 - val_acc: 0.9626\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.9376e-05 - acc: 1.0000 - val_loss: 0.1529 - val_acc: 0.9626\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.8986e-05 - acc: 1.0000 - val_loss: 0.1530 - val_acc: 0.9626\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.0067e-05 - acc: 1.0000 - val_loss: 0.1531 - val_acc: 0.9626\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.9703e-05 - acc: 1.0000 - val_loss: 0.1533 - val_acc: 0.9626\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.8396e-05 - acc: 1.0000 - val_loss: 0.1535 - val_acc: 0.9626\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.9777e-05 - acc: 1.0000 - val_loss: 0.1536 - val_acc: 0.9626\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.0178e-05 - acc: 1.0000 - val_loss: 0.1535 - val_acc: 0.9626\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 4.0578e-05 - acc: 1.0000 - val_loss: 0.1536 - val_acc: 0.9626\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.7926e-05 - acc: 1.0000 - val_loss: 0.1539 - val_acc: 0.9626\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.8451e-05 - acc: 1.0000 - val_loss: 0.1539 - val_acc: 0.9626\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.5458e-05 - acc: 1.0000 - val_loss: 0.1541 - val_acc: 0.9626\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.7341e-05 - acc: 1.0000 - val_loss: 0.1542 - val_acc: 0.9626\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.5372e-05 - acc: 1.0000 - val_loss: 0.1543 - val_acc: 0.9626\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.6144e-05 - acc: 1.0000 - val_loss: 0.1543 - val_acc: 0.9626\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.5637e-05 - acc: 1.0000 - val_loss: 0.1544 - val_acc: 0.9626\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.5273e-05 - acc: 1.0000 - val_loss: 0.1546 - val_acc: 0.9626\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.5425e-05 - acc: 1.0000 - val_loss: 0.1549 - val_acc: 0.9626\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.4561e-05 - acc: 1.0000 - val_loss: 0.1551 - val_acc: 0.9626\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.5052e-05 - acc: 1.0000 - val_loss: 0.1550 - val_acc: 0.9626\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.3416e-05 - acc: 1.0000 - val_loss: 0.1550 - val_acc: 0.9626\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.4148e-05 - acc: 1.0000 - val_loss: 0.1550 - val_acc: 0.9626\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.3017e-05 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.9626\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.5235e-05 - acc: 1.0000 - val_loss: 0.1555 - val_acc: 0.9626\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.3130e-05 - acc: 1.0000 - val_loss: 0.1556 - val_acc: 0.9626\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.2151e-05 - acc: 1.0000 - val_loss: 0.1556 - val_acc: 0.9626\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.1638e-05 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.9626\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 3.3354e-05 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 0.9626\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.1258e-05 - acc: 1.0000 - val_loss: 0.1557 - val_acc: 0.9626\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.2472e-05 - acc: 1.0000 - val_loss: 0.1560 - val_acc: 0.9626\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.1702e-05 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 0.9626\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.2591e-05 - acc: 1.0000 - val_loss: 0.1565 - val_acc: 0.9626\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.3227e-05 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 0.9626\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.0360e-05 - acc: 1.0000 - val_loss: 0.1565 - val_acc: 0.9626\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.9554e-05 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 0.9626\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.0858e-05 - acc: 1.0000 - val_loss: 0.1565 - val_acc: 0.9626\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.9257e-05 - acc: 1.0000 - val_loss: 0.1566 - val_acc: 0.9626\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.9531e-05 - acc: 1.0000 - val_loss: 0.1568 - val_acc: 0.9626\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.0951e-05 - acc: 1.0000 - val_loss: 0.1570 - val_acc: 0.9626\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.9053e-05 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.9626\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.0227e-05 - acc: 1.0000 - val_loss: 0.1572 - val_acc: 0.9626\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.0679e-05 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.9626\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.8355e-05 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.9626\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.8978e-05 - acc: 1.0000 - val_loss: 0.1574 - val_acc: 0.9626\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.7808e-05 - acc: 1.0000 - val_loss: 0.1575 - val_acc: 0.9626\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.8245e-05 - acc: 1.0000 - val_loss: 0.1577 - val_acc: 0.9626\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 3.0311e-05 - acc: 1.0000 - val_loss: 0.1578 - val_acc: 0.9626\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.7155e-05 - acc: 1.0000 - val_loss: 0.1578 - val_acc: 0.9626\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.6853e-05 - acc: 1.0000 - val_loss: 0.1579 - val_acc: 0.9626\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.8139e-05 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 0.9626\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.7999e-05 - acc: 1.0000 - val_loss: 0.1580 - val_acc: 0.9626\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.9020e-05 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 0.9626\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.6554e-05 - acc: 1.0000 - val_loss: 0.1582 - val_acc: 0.9626\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.7858e-05 - acc: 1.0000 - val_loss: 0.1583 - val_acc: 0.9626\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.7536e-05 - acc: 1.0000 - val_loss: 0.1585 - val_acc: 0.9626\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.5760e-05 - acc: 1.0000 - val_loss: 0.1586 - val_acc: 0.9626\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.4479e-05 - acc: 1.0000 - val_loss: 0.1588 - val_acc: 0.9626\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.5256e-05 - acc: 1.0000 - val_loss: 0.1588 - val_acc: 0.9626\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.7357e-05 - acc: 1.0000 - val_loss: 0.1587 - val_acc: 0.9626\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.5819e-05 - acc: 1.0000 - val_loss: 0.1588 - val_acc: 0.9626\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.5005e-05 - acc: 1.0000 - val_loss: 0.1589 - val_acc: 0.9626\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.3942e-05 - acc: 1.0000 - val_loss: 0.1591 - val_acc: 0.9626\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.4821e-05 - acc: 1.0000 - val_loss: 0.1593 - val_acc: 0.9626\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.4499e-05 - acc: 1.0000 - val_loss: 0.1594 - val_acc: 0.9626\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.4885e-05 - acc: 1.0000 - val_loss: 0.1595 - val_acc: 0.9626\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.5329e-05 - acc: 1.0000 - val_loss: 0.1594 - val_acc: 0.9626\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.4007e-05 - acc: 1.0000 - val_loss: 0.1594 - val_acc: 0.9626\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.5115e-05 - acc: 1.0000 - val_loss: 0.1594 - val_acc: 0.9626\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.3108e-05 - acc: 1.0000 - val_loss: 0.1596 - val_acc: 0.9626\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.3970e-05 - acc: 1.0000 - val_loss: 0.1598 - val_acc: 0.9626\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.2353e-05 - acc: 1.0000 - val_loss: 0.1601 - val_acc: 0.9626\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.2299e-05 - acc: 1.0000 - val_loss: 0.1602 - val_acc: 0.9626\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.2001e-05 - acc: 1.0000 - val_loss: 0.1603 - val_acc: 0.9626\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.2107e-05 - acc: 1.0000 - val_loss: 0.1603 - val_acc: 0.9626\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.2998e-05 - acc: 1.0000 - val_loss: 0.1603 - val_acc: 0.9626\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.3110e-05 - acc: 1.0000 - val_loss: 0.1602 - val_acc: 0.9626\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.5106e-05 - acc: 1.0000 - val_loss: 0.1603 - val_acc: 0.9626\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.3047e-05 - acc: 1.0000 - val_loss: 0.1605 - val_acc: 0.9626\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.2192e-05 - acc: 1.0000 - val_loss: 0.1608 - val_acc: 0.9626\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.2402e-05 - acc: 1.0000 - val_loss: 0.1609 - val_acc: 0.9626\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.3667e-05 - acc: 1.0000 - val_loss: 0.1608 - val_acc: 0.9626\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.3160e-05 - acc: 1.0000 - val_loss: 0.1609 - val_acc: 0.9626\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.2049e-05 - acc: 1.0000 - val_loss: 0.1610 - val_acc: 0.9626\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.1551e-05 - acc: 1.0000 - val_loss: 0.1611 - val_acc: 0.9626\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.0433e-05 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.9626\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.2891e-05 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.9626\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.1634e-05 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.9626\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.9140e-05 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.9626\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.1263e-05 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.9626\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.1429e-05 - acc: 1.0000 - val_loss: 0.1615 - val_acc: 0.9626\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.2062e-05 - acc: 1.0000 - val_loss: 0.1617 - val_acc: 0.9626\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.9473e-05 - acc: 1.0000 - val_loss: 0.1619 - val_acc: 0.9626\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.0498e-05 - acc: 1.0000 - val_loss: 0.1620 - val_acc: 0.9626\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.9831e-05 - acc: 1.0000 - val_loss: 0.1620 - val_acc: 0.9626\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 2.0305e-05 - acc: 1.0000 - val_loss: 0.1620 - val_acc: 0.9626\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.9201e-05 - acc: 1.0000 - val_loss: 0.1619 - val_acc: 0.9626\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.9055e-05 - acc: 1.0000 - val_loss: 0.1620 - val_acc: 0.9626\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.0983e-05 - acc: 1.0000 - val_loss: 0.1621 - val_acc: 0.9626\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.9869e-05 - acc: 1.0000 - val_loss: 0.1623 - val_acc: 0.9626\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.9824e-05 - acc: 1.0000 - val_loss: 0.1625 - val_acc: 0.9626\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.9423e-05 - acc: 1.0000 - val_loss: 0.1626 - val_acc: 0.9626\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 2.0007e-05 - acc: 1.0000 - val_loss: 0.1628 - val_acc: 0.9626\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.9035e-05 - acc: 1.0000 - val_loss: 0.1627 - val_acc: 0.9626\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.9121e-05 - acc: 1.0000 - val_loss: 0.1627 - val_acc: 0.9626\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.9058e-05 - acc: 1.0000 - val_loss: 0.1626 - val_acc: 0.9626\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.8006e-05 - acc: 1.0000 - val_loss: 0.1627 - val_acc: 0.9626\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.9891e-05 - acc: 1.0000 - val_loss: 0.1628 - val_acc: 0.9626\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.7453e-05 - acc: 1.0000 - val_loss: 0.1630 - val_acc: 0.9626\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.8985e-05 - acc: 1.0000 - val_loss: 0.1631 - val_acc: 0.9626\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.9175e-05 - acc: 1.0000 - val_loss: 0.1632 - val_acc: 0.9626\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.8204e-05 - acc: 1.0000 - val_loss: 0.1632 - val_acc: 0.9626\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.8020e-05 - acc: 1.0000 - val_loss: 0.1633 - val_acc: 0.9626\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.7575e-05 - acc: 1.0000 - val_loss: 0.1634 - val_acc: 0.9626\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.7999e-05 - acc: 1.0000 - val_loss: 0.1635 - val_acc: 0.9626\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.8183e-05 - acc: 1.0000 - val_loss: 0.1635 - val_acc: 0.9626\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.7476e-05 - acc: 1.0000 - val_loss: 0.1636 - val_acc: 0.9626\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6358e-05 - acc: 1.0000 - val_loss: 0.1636 - val_acc: 0.9626\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.7307e-05 - acc: 1.0000 - val_loss: 0.1637 - val_acc: 0.9626\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.7962e-05 - acc: 1.0000 - val_loss: 0.1638 - val_acc: 0.9626\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6819e-05 - acc: 1.0000 - val_loss: 0.1640 - val_acc: 0.9626\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.7056e-05 - acc: 1.0000 - val_loss: 0.1639 - val_acc: 0.9626\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.7783e-05 - acc: 1.0000 - val_loss: 0.1639 - val_acc: 0.9626\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.7356e-05 - acc: 1.0000 - val_loss: 0.1640 - val_acc: 0.9626\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.7691e-05 - acc: 1.0000 - val_loss: 0.1643 - val_acc: 0.9626\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.7862e-05 - acc: 1.0000 - val_loss: 0.1643 - val_acc: 0.9626\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6389e-05 - acc: 1.0000 - val_loss: 0.1644 - val_acc: 0.9626\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6601e-05 - acc: 1.0000 - val_loss: 0.1644 - val_acc: 0.9626\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6892e-05 - acc: 1.0000 - val_loss: 0.1644 - val_acc: 0.9626\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6682e-05 - acc: 1.0000 - val_loss: 0.1645 - val_acc: 0.9626\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6814e-05 - acc: 1.0000 - val_loss: 0.1647 - val_acc: 0.9626\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.7030e-05 - acc: 1.0000 - val_loss: 0.1648 - val_acc: 0.9626\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6414e-05 - acc: 1.0000 - val_loss: 0.1649 - val_acc: 0.9626\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6239e-05 - acc: 1.0000 - val_loss: 0.1649 - val_acc: 0.9626\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.5636e-05 - acc: 1.0000 - val_loss: 0.1650 - val_acc: 0.9626\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6289e-05 - acc: 1.0000 - val_loss: 0.1650 - val_acc: 0.9626\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.5143e-05 - acc: 1.0000 - val_loss: 0.1651 - val_acc: 0.9626\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.6539e-05 - acc: 1.0000 - val_loss: 0.1652 - val_acc: 0.9626\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6095e-05 - acc: 1.0000 - val_loss: 0.1652 - val_acc: 0.9626\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.5218e-05 - acc: 1.0000 - val_loss: 0.1654 - val_acc: 0.9626\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.5070e-05 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9626\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.6417e-05 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9626\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.7017e-05 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9626\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.5483e-05 - acc: 1.0000 - val_loss: 0.1656 - val_acc: 0.9626\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.4342e-05 - acc: 1.0000 - val_loss: 0.1657 - val_acc: 0.9626\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.5559e-05 - acc: 1.0000 - val_loss: 0.1658 - val_acc: 0.9626\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.3885e-05 - acc: 1.0000 - val_loss: 0.1658 - val_acc: 0.9626\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.5234e-05 - acc: 1.0000 - val_loss: 0.1658 - val_acc: 0.9626\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.4607e-05 - acc: 1.0000 - val_loss: 0.1660 - val_acc: 0.9626\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.5790e-05 - acc: 1.0000 - val_loss: 0.1661 - val_acc: 0.9626\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.5065e-05 - acc: 1.0000 - val_loss: 0.1662 - val_acc: 0.9626\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.5209e-05 - acc: 1.0000 - val_loss: 0.1662 - val_acc: 0.9626\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.4420e-05 - acc: 1.0000 - val_loss: 0.1662 - val_acc: 0.9626\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.4417e-05 - acc: 1.0000 - val_loss: 0.1662 - val_acc: 0.9626\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.5178e-05 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 0.9626\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.3587e-05 - acc: 1.0000 - val_loss: 0.1665 - val_acc: 0.9626\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.3839e-05 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9626\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.4630e-05 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9626\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.4196e-05 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9626\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.3599e-05 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 0.9626\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.3978e-05 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 0.9626\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.4519e-05 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 0.9626\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.4022e-05 - acc: 1.0000 - val_loss: 0.1669 - val_acc: 0.9626\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 9s 4s/step - loss: 1.4212e-05 - acc: 1.0000 - val_loss: 0.1670 - val_acc: 0.9626\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.2986e-05 - acc: 1.0000 - val_loss: 0.1670 - val_acc: 0.9626\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 8s 4s/step - loss: 1.3214e-05 - acc: 1.0000 - val_loss: 0.1672 - val_acc: 0.9626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qzK4SJB5y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "09ea22df-a36d-47af-a1a4-d4df25d15282"
      },
      "source": [
        "plt.figure(figsize =(5,3))\n",
        "plt.plot(history.history['acc'], marker='.', label='tune')\n",
        "plt.plot(history.history['val_acc'], marker='.', label='test')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGBi22ZGy38"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA Model_DS_70_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ilyaas189/Text-Analytics_CE_807/blob/main/LDA_Model_DS_70_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "h48neXM-ANwE",
        "outputId": "d756983c-d6ce-4015-bd39-01ea54eded0d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from google.colab import files\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import random\n",
        "uploaded = files.upload()\n",
        "files = list(uploaded.keys())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9cecea43-abf4-4fb1-ad0b-8150466f467d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9cecea43-abf4-4fb1-ad0b-8150466f467d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcrJU_pzAhOm",
        "outputId": "c0acd96e-9120-4ecb-e835-8e4804eae3b5"
      },
      "source": [
        "# Import Dataset\n",
        "data = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "print(data.target_names.unique())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
            " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
            " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
            " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
            " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
            " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "SnGiNUYGAtLQ",
        "outputId": "d5517f34-4cbc-4cf0-bebd-d7772d773d45"
      },
      "source": [
        "data.head(20)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
              "      <td>16</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
              "      <td>13</td>\n",
              "      <td>sci.med</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
              "      <td>3</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
              "      <td>8</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>From: david@terminus.ericsson.se (David Bold)\\...</td>\n",
              "      <td>19</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>From: dbm0000@tm0006.lerc.nasa.gov (David B. M...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...</td>\n",
              "      <td>6</td>\n",
              "      <td>misc.forsale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...</td>\n",
              "      <td>12</td>\n",
              "      <td>sci.electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>From: abarden@tybse1.uucp (Ann Marie Barden)\\n...</td>\n",
              "      <td>5</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              content  ...              target_names\n",
              "0   From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...                 rec.autos\n",
              "1   From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...     comp.sys.mac.hardware\n",
              "2   From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...     comp.sys.mac.hardware\n",
              "3   From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...             comp.graphics\n",
              "4   From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...                 sci.space\n",
              "5   From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...  ...        talk.politics.guns\n",
              "6   From: bmdelane@quads.uchicago.edu (brian manni...  ...                   sci.med\n",
              "7   From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...  ...  comp.sys.ibm.pc.hardware\n",
              "8   From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...  ...   comp.os.ms-windows.misc\n",
              "9   From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...  ...     comp.sys.mac.hardware\n",
              "10  From: irwin@cmptrc.lonestar.org (Irwin Arnstei...  ...           rec.motorcycles\n",
              "11  From: david@terminus.ericsson.se (David Bold)\\...  ...        talk.religion.misc\n",
              "12  From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...  ...     comp.sys.mac.hardware\n",
              "13  From: dbm0000@tm0006.lerc.nasa.gov (David B. M...  ...                 sci.space\n",
              "14  From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...  ...              misc.forsale\n",
              "15  From: mathew <mathew@mantis.co.uk>\\nSubject: R...  ...               alt.atheism\n",
              "16  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...  ...             comp.graphics\n",
              "17  From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...  ...                 rec.autos\n",
              "18  From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...  ...           sci.electronics\n",
              "19  From: abarden@tybse1.uucp (Ann Marie Barden)\\n...  ...            comp.windows.x\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1t4Hd65BKo4",
        "outputId": "425a97f9-8e44-4484-ede5-c56cad6e09da"
      },
      "source": [
        "data_clusterization = data[['content', 'target_names']]\n",
        "data_clusterization.dropna(inplace=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "0xRJ8_03Bd1W",
        "outputId": "3145fe22-afec-45bf-8017-54f0a8432640"
      },
      "source": [
        "data_clusterization.head(2)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content           target_names\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...              rec.autos\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  comp.sys.mac.hardware"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iUh1DoLBmXP",
        "outputId": "cc1940bb-33cb-49d4-df05-7b92fb6c7f22"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7hwfWd1Bw8S"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        " stemmer = SnowballStemmer(language='english')\n",
        " return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        " result = []\n",
        " for token in gensim.utils.simple_preprocess(text):\n",
        "   if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "     result.append(lemmatize_stemming(token))\n",
        " return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJfVX8biB_Sa"
      },
      "source": [
        "processed_docs = data_clusterization['content'].map(preprocess)\n",
        "data_processed = processed_docs.to_frame()\n",
        "data_processed['content'] = data_processed.content.apply(lambda x: ' '.join(x))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCHPTBYJClMy",
        "outputId": "b072aae9-a2cf-43f7-98ec-e7f7bb46169d"
      },
      "source": [
        "!pip install tokenize_uk\n",
        "from collections import Counter\n",
        "from tokenize_uk.tokenize_uk import tokenize_words"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenize_uk\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/21/72abb0304b532e1b2d2473b50d8063ddd0943e3b3fe7e86b366bc4d02aa2/tokenize_uk-0.2.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tokenize_uk) (1.15.0)\n",
            "Building wheels for collected packages: tokenize-uk\n",
            "  Building wheel for tokenize-uk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tokenize-uk: filename=tokenize_uk-0.2.0-py2.py3-none-any.whl size=4565 sha256=4cad7fdb9568de046db0bd45fdd75f96e047d52dcc9ea17284517878cf449c4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/e1/95/fd8af5b40aeebdc4e178974e7f638f5553aa8772117054db9e\n",
            "Successfully built tokenize-uk\n",
            "Installing collected packages: tokenize-uk\n",
            "Successfully installed tokenize-uk-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "94mq8WUoCqHq",
        "outputId": "f232f92e-1f5a-4d41-b656-d74548694184"
      },
      "source": [
        "def display_words(data, title, ax):\n",
        " count = Counter(sum(map(lambda text: tokenize_words(text), data), []))\n",
        " popular = np.array(sorted(count.items(), key=lambda x: x[1], reverse=True)[:20])\n",
        " plt.sca(ax)\n",
        " plt.title(title)\n",
        " plt.bar(popular[:,0], np.int32(popular[:,1]))\n",
        " plt.xticks(rotation=\"vertical\")\n",
        "fig, ax = plt.subplots(figsize=(16, 5))\n",
        "display_words(data_processed.sample(1000).content, \"The most popular words]\", ax)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCM4qevNC5Ty"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMnRgz3aC8f5",
        "outputId": "d78fc726-a899-4853-832f-96dcd490f049"
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "count_data = count_vectorizer.fit_transform(data_processed['content'])\n",
        "count_data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11314x61410 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 934270 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TmSX73jDEJS"
      },
      "source": [
        "likelihood = []\n",
        "n_clusters = []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9uTcUJlDHT0"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hki6oWR0DLwb"
      },
      "source": [
        "def estimate_number_clusters(data, nclusters):\n",
        " for n in nclusters:\n",
        "   likelihood.append(LDA(n_components=n, n_jobs=-1).fit(data).score(data))\n",
        " n_clusters.append(n)\n",
        " print(\"Sccesfully estimated \", n)\n",
        " fig, ax = plt.subplots(figsize=(15, 5))\n",
        " sns.lineplot(x=n_clusters, y=likelihood, ax=ax)\n",
        " ax.set_title('Elbow method for choosing n, likelihood')\n",
        " ax.set_ylabel('Likelihood')\n",
        " ax.set_xlabel('n')\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CBG_y1fJszZ"
      },
      "source": [
        "# estimate_number_clusters(count_data, [10, 15, 20, 50])\n",
        " \n",
        " "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XNMixjQJuYE"
      },
      "source": [
        "def print_topics(model, count_vectorizer, n_top_words):\n",
        "  words = count_vectorizer.get_feature_names()\n",
        "  for topic_idx, topic in enumerate(model.components_):\n",
        "    print(\"\\nTopic #%d:\" % topic_idx)\n",
        "    print(\" \".join([words[i]\n",
        "  for i in topic.argsort()[:-n_top_words - 1:-1]]))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugizp_hhFpzm"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWtTkYX1Ftia",
        "outputId": "d4e510a9-fe4e-45be-b50e-c16eb5ac697b"
      },
      "source": [
        "number_topics = 70\n",
        "number_words = 10\n",
        "# Create and fit the LDA model\n",
        "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
        "lda.fit(count_data)\n",
        "# Print the topics found by the LDA model\n",
        "print(\"Topics found via LDA:\")\n",
        "print_topics(lda, count_vectorizer, number_words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topics found via LDA:\n",
            "\n",
            "Topic #0:\n",
            "card line subject organ modem driver know port thank post\n",
            "\n",
            "Topic #1:\n",
            "moral uiuc write object subject line think organ articl univers\n",
            "\n",
            "Topic #2:\n",
            "pitt bank gordon articl write organ subject line pittsburgh repli\n",
            "\n",
            "Topic #3:\n",
            "access digex line subject organ alaska write host post nntp\n",
            "\n",
            "Topic #4:\n",
            "chip encrypt clipper secur govern escrow key phone technolog enforc\n",
            "\n",
            "Topic #5:\n",
            "netcom line organ subject write engin softwar know communic servic\n",
            "\n",
            "Topic #6:\n",
            "player year leagu organ line stanford subject univers season team\n",
            "\n",
            "Topic #7:\n",
            "columbia subject line organ univers post game host nntp sale\n",
            "\n",
            "Topic #8:\n",
            "write iastat mcgill line univers organ subject articl monash mcrcim\n",
            "\n",
            "Topic #9:\n",
            "line subject wire bike organ like power good need drive\n",
            "\n",
            "Topic #10:\n",
            "line organ subject post navi write articl nntp host robert\n",
            "\n",
            "Topic #11:\n",
            "write articl buffalo henrik line organ subject armenia say robert\n",
            "\n",
            "Topic #12:\n",
            "organ subject line louisvill articl write church main arromde creed\n",
            "\n",
            "Topic #13:\n",
            "imag file graphic format program jpeg color convert display keyboard\n",
            "\n",
            "Topic #14:\n",
            "entri program file rule section line info need build compil\n",
            "\n",
            "Topic #15:\n",
            "cwru cleveland freenet univers subject line western host organ reserv\n",
            "\n",
            "Topic #16:\n",
            "israel isra arab jew palestinian attack state kill jewish write\n",
            "\n",
            "Topic #17:\n",
            "david len busi world line graphit rchz organ subject plant\n",
            "\n",
            "Topic #18:\n",
            "right organ militia articl line write state subject peopl amend\n",
            "\n",
            "Topic #19:\n",
            "space univers cramer optilink homosexu nation research program inform april\n",
            "\n",
            "Topic #20:\n",
            "line organ subject freenet clarkson carleton hell gene wright rochest\n",
            "\n",
            "Topic #21:\n",
            "write subject articl line organ know post like dyer harvard\n",
            "\n",
            "Topic #22:\n",
            "gatech georgia michael prism flyer line subject univers organ technolog\n",
            "\n",
            "Topic #23:\n",
            "ingr absolut jake write boni opinion marri subject articl line\n",
            "\n",
            "Topic #24:\n",
            "appl sandvik caltech write kent organ line subject articl livesey\n",
            "\n",
            "Topic #25:\n",
            "mail data user list anonym includ inform internet softwar file\n",
            "\n",
            "Topic #26:\n",
            "state ohio write magnus line organ subject articl post univers\n",
            "\n",
            "Topic #27:\n",
            "peopl right govern think state countri like person want time\n",
            "\n",
            "Topic #28:\n",
            "play period power team ericsson sweden king goal edmonton philadelphia\n",
            "\n",
            "Topic #29:\n",
            "articl write line organ subject rise post uoknor hulman callison\n",
            "\n",
            "Topic #30:\n",
            "subject line organ monitor post washington nntp host univers window\n",
            "\n",
            "Topic #31:\n",
            "hockey team game play player line playoff subject organ leaf\n",
            "\n",
            "Topic #32:\n",
            "bellcor write iran line subject organ articl fist program fractal\n",
            "\n",
            "Topic #33:\n",
            "vote version contact type machin math compass andrew comment kadi\n",
            "\n",
            "Topic #34:\n",
            "motorcycl bike rider ride hydro levin jodi denizen rid cx_s\n",
            "\n",
            "Topic #35:\n",
            "subject line organ mathew file watson write world brandei keith\n",
            "\n",
            "Topic #36:\n",
            "food virginia cancer water center univers research cell organ tast\n",
            "\n",
            "Topic #37:\n",
            "write netcom articl ripem line organ subject david public code\n",
            "\n",
            "Topic #38:\n",
            "write articl cornel subject organ line libertarian post like thor\n",
            "\n",
            "Topic #39:\n",
            "line subject organ write post like nntp host articl know\n",
            "\n",
            "Topic #40:\n",
            "diseas doctor medic patient pain caus treatment organ subject problem\n",
            "\n",
            "Topic #41:\n",
            "jesus christian christ come church write say bibl paul lord\n",
            "\n",
            "Topic #42:\n",
            "gun weapon firearm crime polic like control crimin handgun state\n",
            "\n",
            "Topic #43:\n",
            "write line subject organ articl post udel like know nntp\n",
            "\n",
            "Topic #44:\n",
            "scsi cool line radar write tower subject organ water articl\n",
            "\n",
            "Topic #45:\n",
            "atheist atheism exist post subject east pope write articl cathol\n",
            "\n",
            "Topic #46:\n",
            "request line subject year report write increas organ state send\n",
            "\n",
            "Topic #47:\n",
            "encrypt cipher crypt cryptographi random attack secur public unit number\n",
            "\n",
            "Topic #48:\n",
            "andrew line arizona subject organ post baalk bit kelvin carnegi\n",
            "\n",
            "Topic #49:\n",
            "christian believ think peopl know question exist reason mean thing\n",
            "\n",
            "Topic #50:\n",
            "line subject organ duke univers point post host nntp write\n",
            "\n",
            "Topic #51:\n",
            "line subject organ post appl nntp host simm write printer\n",
            "\n",
            "Topic #52:\n",
            "drug legal tobacco health state report cigarett articl smokeless beckman\n",
            "\n",
            "Topic #53:\n",
            "nrhj wwiz gizw bhjn line bxom organ subject pnei nriz\n",
            "\n",
            "Topic #54:\n",
            "say go know come peopl like think tell time look\n",
            "\n",
            "Topic #55:\n",
            "window widget server motif applic subject display problem program file\n",
            "\n",
            "Topic #56:\n",
            "stratus write batf line subject waco organ rocket compound articl\n",
            "\n",
            "Topic #57:\n",
            "launch myer satellit koresh juda hang time greek claim persian\n",
            "\n",
            "Topic #58:\n",
            "file output program window line char write printf entri onam\n",
            "\n",
            "Topic #59:\n",
            "insur probe health radar privat launch satellit radio cost care\n",
            "\n",
            "Topic #60:\n",
            "space nasa orbit henri earth launch line organ shuttl subject\n",
            "\n",
            "Topic #61:\n",
            "game year team play season score pitch think run player\n",
            "\n",
            "Topic #62:\n",
            "presid clinton stephanopoulo go know think work say job senat\n",
            "\n",
            "Topic #63:\n",
            "font purdu organ line subject blah write articl hiram sale\n",
            "\n",
            "Topic #64:\n",
            "window organ subject line write articl jewish come post expos\n",
            "\n",
            "Topic #65:\n",
            "armenian turkish turk greek turkey argic serdar armenia genocid peopl\n",
            "\n",
            "Topic #66:\n",
            "write organ subject line articl harri good year post trade\n",
            "\n",
            "Topic #67:\n",
            "drive disk problem hard card control work driver memori floppi\n",
            "\n",
            "Topic #68:\n",
            "islam muslim book copi write line good organ subject cover\n",
            "\n",
            "Topic #69:\n",
            "colorado line subject organ post host nntp write articl univers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "LrPaQEiuGRt3",
        "outputId": "7ec3f6d1-51a1-4b0c-da4a-edc9d01ca6be"
      },
      "source": [
        "cluster_probabilities = lda.transform(count_data)\n",
        "data_processed['target'] = np.argmax(cluster_probabilities, axis=1)\n",
        "data_processed.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lerxst thing subject nntp post host organ univ...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>guykuo carson washington subject clock poll fi...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twilli purdu thoma willi subject question orga...</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jgreen amber green subject weitek organ harri ...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>head harvard jonathan mcdowel subject shuttl l...</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  target\n",
              "0  lerxst thing subject nntp post host organ univ...      21\n",
              "1  guykuo carson washington subject clock poll fi...      30\n",
              "2  twilli purdu thoma willi subject question orga...      51\n",
              "3  jgreen amber green subject weitek organ harri ...      26\n",
              "4  head harvard jonathan mcdowel subject shuttl l...      69"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJNJOHB9GkKP"
      },
      "source": [
        "import seaborn as sns\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "At3W9AMVGnga",
        "outputId": "529c0a90-7b64-424f-cd81-3879f6920302"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "sns.countplot(x=data_processed.target);\n",
        "ax.set_title(\"Number of articles that correspond to the topic\");\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ07JMrCRAYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9451b86f-2d2d-47d9-88fe-80c30cbf6614"
      },
      "source": [
        "#Loading the data set - training data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "mydata_train = fetch_20newsgroups(subset='train', shuffle=True, remove = ('headers', 'footers', 'quotes'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpyae_wBRHIU",
        "outputId": "0f794b54-52c3-4434-d5d1-c87dfc1d3356"
      },
      "source": [
        "list(mydata_train)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'filenames', 'target_names', 'target', 'DESCR']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsmrhUPeRJ9l",
        "outputId": "29760776-5f92-4fb9-9e86-4926a55f6f7f"
      },
      "source": [
        "print('Training data size:', len(mydata_train['data']))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size: 11314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv1WrOdSRONT",
        "outputId": "88e98240-278d-4091-fda4-bef6485bc8a0"
      },
      "source": [
        "# Printing all the categories\n",
        "mydata_train.target_names"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krZedPVlRRxL",
        "outputId": "05d69170-768c-4509-bf3f-e6a1b9c010f0"
      },
      "source": [
        "\n",
        "# Finding frequency of each category\n",
        "targets, frequency = np.unique(mydata_train.target, return_counts=True)\n",
        "targets, frequency"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "        17, 18, 19]),\n",
              " array([480, 584, 591, 590, 578, 593, 585, 594, 598, 597, 600, 595, 591,\n",
              "        594, 593, 599, 546, 564, 465, 377]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSr8qhRVRWTb",
        "outputId": "524491ce-b31a-4422-d08d-93eb011343ad"
      },
      "source": [
        "targets_str = np.array(mydata_train.target_names)\n",
        "print(list(zip(targets_str, frequency)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('alt.atheism', 480), ('comp.graphics', 584), ('comp.os.ms-windows.misc', 591), ('comp.sys.ibm.pc.hardware', 590), ('comp.sys.mac.hardware', 578), ('comp.windows.x', 593), ('misc.forsale', 585), ('rec.autos', 594), ('rec.motorcycles', 598), ('rec.sport.baseball', 597), ('rec.sport.hockey', 600), ('sci.crypt', 595), ('sci.electronics', 591), ('sci.med', 594), ('sci.space', 593), ('soc.religion.christian', 599), ('talk.politics.guns', 546), ('talk.politics.mideast', 564), ('talk.politics.misc', 465), ('talk.religion.misc', 377)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pZ_KnVPRZSm"
      },
      "source": [
        "mydata_test = fetch_20newsgroups(subset='test', shuffle=True, remove = ('headers', 'footers', 'quotes'))\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEcSYoJmRcUc",
        "outputId": "5fb2d482-2ba5-4dbf-f82c-a4fe7921d0ae"
      },
      "source": [
        "print('Testing data size:', len(mydata_test['data']))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing data size: 7532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "_aSKch0QRf_o",
        "outputId": "188786ed-a1a0-4647-b9f1-a71da405e981"
      },
      "source": [
        "mydata_train_df = pd.DataFrame({'data': mydata_train.data, 'target': mydata_train.target})\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I was wondering if anyone out there could enli...       7\n",
              "1  A fair number of brave souls who upgraded thei...       4\n",
              "2  well folks, my mac plus finally gave up the gh...       4\n",
              "3  \\nDo you have Weitek's address/phone number?  ...       1\n",
              "4  From article <C5owCB.n3p@world.std.com>, by to...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "ttru-cT7Rj9K",
        "outputId": "f6f935a4-dbb5-4899-b398-870857d9bc1b"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "import re\n",
        "import string\n",
        "\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_train_df['data'] = mydata_train_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_train_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i was wondering if anyone out there could enli...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a fair number of brave souls who upgraded thei...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well folks  my mac plus finally gave up the gh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\ndo you have weitek s address phone number   ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>from article      world std com   by tombaker ...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i was wondering if anyone out there could enli...       7\n",
              "1  a fair number of brave souls who upgraded thei...       4\n",
              "2  well folks  my mac plus finally gave up the gh...       4\n",
              "3  \\ndo you have weitek s address phone number   ...       1\n",
              "4  from article      world std com   by tombaker ...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "8f6jlH07RoBH",
        "outputId": "53491f1e-efe9-4e74-edcc-2de2a638ec49"
      },
      "source": [
        "mydata_test_df = pd.DataFrame({'data': mydata_test.data, 'target': mydata_test.target})\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIn a word, yes.\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThey were attacking the Iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nI've just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  I am a little confused on all of the models of...       7\n",
              "1  I'm not familiar at all with the format of the...       5\n",
              "2                                \\nIn a word, yes.\\n       0\n",
              "3  \\nThey were attacking the Iraqis to drive them...      17\n",
              "4  \\nI've just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "tUjU5KP5RrlP",
        "outputId": "40749d2e-498e-4139-9e94-099b7395f5d7"
      },
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "mydata_test_df['data'] = mydata_test_df.data.map(alphanumeric).map(punc_lower)\n",
        "mydata_test_df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i am a little confused on all of the models of...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i m not familiar at all with the format of the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nin a word  yes \\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nthey were attacking the iraqis to drive them...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\ni ve just spent two solid months arguing tha...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  target\n",
              "0  i am a little confused on all of the models of...       7\n",
              "1  i m not familiar at all with the format of the...       5\n",
              "2                                \\nin a word  yes \\n       0\n",
              "3  \\nthey were attacking the iraqis to drive them...      17\n",
              "4  \\ni ve just spent two solid months arguing tha...      19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUELDX2-bNNg",
        "outputId": "19b93fe6-724c-457e-80ce-a35c12da5415"
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "X_train_cv = count_vect.fit_transform(mydata_train_df.data) # fit_transform learns the\n",
        "X_test_cv = count_vect.transform(mydata_test_df.data) # transform uses the same vocab an\n",
        "print(X_train_cv.shape)\n",
        "print(type(X_train_cv))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11314, 67822)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRUtZ9-VAkiY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
        "from keras.models import Model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Oz3FjnHAqOw",
        "outputId": "8572e56b-2581-4a50-bc60-5578c138a3f5"
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian'] \n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, \n",
        "                                      categories=categories,)\n",
        "\n",
        "print (newsgroups_train.target_names)\n",
        "print (len(newsgroups_train.data))\n",
        "\n",
        "#print (newsgroups_train.data[1])\n",
        "print(\"\\n\".join(newsgroups_train.data[0].split(\"\\n\")[10:15]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'soc.religion.christian']\n",
            "1079\n",
            "   WASHINGTON, April 19  -- A symposium on the Dead Sea \n",
            "Scrolls will be held at the Library of Congress on Wednesday,\n",
            "April 21, and Thursday, April 22.  The two-day program, cosponsored\n",
            "by the library and Baltimore Hebrew University, with additional\n",
            "support from the Project Judaica Foundation, will be held in the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9VVEyQWAu6m",
        "outputId": "58243233-52cb-4462-8254-e6ffa5c40d68"
      },
      "source": [
        "%%time\n",
        "\n",
        "texts = []\n",
        "\n",
        "labels=newsgroups_train.target\n",
        "texts = newsgroups_train.data\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NB_WORDS = 20000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "print (sequences[0][:10])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19, 8762, 3621, 11894, 58, 8762, 3621, 43, 1472, 2]\n",
            "CPU times: user 442 ms, sys: 8.04 ms, total: 450 ms\n",
            "Wall time: 450 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C-jZJV1Ay0E",
        "outputId": "aee97acc-eeb2-4399-cf0b-b049ee408cf6"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20030 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3leeqbJA1-q",
        "outputId": "f5c0cd55-3b8d-485c-a068-217ad6ae68b4"
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print (data.shape)\n",
        "print (data[0][200:250])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1079, 1000)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0    19  8762  3621 11894    58  8762  3621\n",
            "    43  1472     2  2130     3   189   450  1001  3622  2980  1682   476\n",
            "   627    50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TATKrjgmA6lK",
        "outputId": "4c8836d3-47c9-4024-eddb-266078ef2401"
      },
      "source": [
        "labels = to_categorical(np.array(labels))\n",
        "\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1079, 1000)\n",
            "Shape of label tensor: (1079, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKD1nppNA_cG",
        "outputId": "81671a38-0f1d-4395-8c5d-bbbd97ad5f74"
      },
      "source": [
        "VALIDATION_SPLIT = 0.1\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices) \n",
        "data = data[indices] \n",
        "labels = labels[indices] \n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples] \n",
        "y_train = labels[:-nb_validation_samples] \n",
        "x_val = data[-nb_validation_samples:] \n",
        "y_val = labels[-nb_validation_samples:] \n",
        "\n",
        "print (x_train.shape)\n",
        "print (y_train.shape)\n",
        "\n",
        "print('Number of positive and negative reviews in traing and validation set ') \n",
        "print (y_train.sum(axis=0))\n",
        "print (y_val.sum(axis=0))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(972, 1000)\n",
            "(972, 2)\n",
            "Number of positive and negative reviews in traing and validation set \n",
            "[442. 530.]\n",
            "[38. 69.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "1jN7GicoBSkh",
        "outputId": "17f44b2c-31aa-4ddc-a6fe-8f40915fa87f"
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros.\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print (embedding_matrix.shape)\n",
        "\n",
        "print (embedding_matrix[0][:10])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6fb53264530f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# words not found in embedding index will be all-zeros.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StT4yPYaBUgr",
        "outputId": "8de829e2-4625-44e6-d423-d356afee1333"
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix], \n",
        "                            input_length=MAX_SEQUENCE_LENGTH, \n",
        "                            trainable=False)\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32') \n",
        "embedded_sequences = embedding_layer(sequence_input) \n",
        "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences) \n",
        "l_pool1 = MaxPooling1D(5)(l_cov1) \n",
        "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1) \n",
        "l_pool2 = MaxPooling1D(5)(l_cov2) \n",
        "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2) \n",
        "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
        "\n",
        "l_flat = Flatten()(l_pool3) \n",
        "l_dense = Dense(128, activation='relu')(l_flat) \n",
        "preds = Dense(2, activation='softmax')(l_dense)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1000)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1000, 100)         2003100   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 996, 128)          64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 199, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 195, 128)          82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 39, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 35, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 2,248,094\n",
            "Trainable params: 244,994\n",
            "Non-trainable params: 2,003,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohWKe6xrBfGj",
        "outputId": "6b4bb541-7a8c-44f1-d082-b64864a3144f"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "                    epochs=500, batch_size=512)   "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 35s 1s/step - loss: 0.7653 - acc: 0.4614 - val_loss: 0.6934 - val_acc: 0.4860\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.6997 - acc: 0.4983 - val_loss: 0.6861 - val_acc: 0.6355\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.6980 - acc: 0.5536 - val_loss: 0.6529 - val_acc: 0.6449\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6944 - acc: 0.5425 - val_loss: 0.6904 - val_acc: 0.6262\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6886 - acc: 0.6039 - val_loss: 0.6697 - val_acc: 0.6449\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 0.6848 - acc: 0.5425 - val_loss: 0.6628 - val_acc: 0.6449\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6848 - acc: 0.5473 - val_loss: 0.6751 - val_acc: 0.6262\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6835 - acc: 0.5535 - val_loss: 0.6676 - val_acc: 0.6449\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.6811 - acc: 0.5732 - val_loss: 0.6801 - val_acc: 0.6168\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6796 - acc: 0.5794 - val_loss: 0.6575 - val_acc: 0.6449\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6780 - acc: 0.5523 - val_loss: 0.6737 - val_acc: 0.6075\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 0.6760 - acc: 0.6268 - val_loss: 0.6832 - val_acc: 0.5794\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6743 - acc: 0.6673 - val_loss: 0.6512 - val_acc: 0.6449\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.6740 - acc: 0.5465 - val_loss: 0.6701 - val_acc: 0.5981\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6678 - acc: 0.6498 - val_loss: 0.6752 - val_acc: 0.6075\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.6654 - acc: 0.6637 - val_loss: 0.6474 - val_acc: 0.6449\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.6619 - acc: 0.5725 - val_loss: 0.6712 - val_acc: 0.6262\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6587 - acc: 0.7730 - val_loss: 0.6412 - val_acc: 0.6449\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6541 - acc: 0.5641 - val_loss: 0.6600 - val_acc: 0.6636\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.6611 - acc: 0.6299 - val_loss: 0.6400 - val_acc: 0.6542\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.6525 - acc: 0.6032 - val_loss: 0.6298 - val_acc: 0.6636\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.6454 - acc: 0.5674 - val_loss: 0.7026 - val_acc: 0.4299\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6503 - acc: 0.5664 - val_loss: 0.6235 - val_acc: 0.6636\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.6303 - acc: 0.5883 - val_loss: 0.6225 - val_acc: 0.7103\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.6086 - acc: 0.7613 - val_loss: 0.6393 - val_acc: 0.7664\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 0.6033 - acc: 0.8646 - val_loss: 0.5943 - val_acc: 0.7103\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.5939 - acc: 0.6782 - val_loss: 0.6246 - val_acc: 0.7664\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.5694 - acc: 0.8825 - val_loss: 0.5664 - val_acc: 0.7290\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.5511 - acc: 0.7515 - val_loss: 0.6333 - val_acc: 0.5421\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.5383 - acc: 0.7824 - val_loss: 0.5358 - val_acc: 0.7196\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.5289 - acc: 0.7378 - val_loss: 0.5942 - val_acc: 0.6729\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.5069 - acc: 0.7726 - val_loss: 0.4769 - val_acc: 0.7850\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.4579 - acc: 0.8266 - val_loss: 0.4653 - val_acc: 0.8879\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.4287 - acc: 0.8624 - val_loss: 0.4825 - val_acc: 0.8692\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.4016 - acc: 0.9126 - val_loss: 0.4243 - val_acc: 0.7757\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.4040 - acc: 0.8256 - val_loss: 0.4555 - val_acc: 0.8785\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.3576 - acc: 0.9054 - val_loss: 0.3560 - val_acc: 0.9159\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.3053 - acc: 0.9267 - val_loss: 0.3268 - val_acc: 0.9346\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.2730 - acc: 0.9244 - val_loss: 0.3501 - val_acc: 0.9065\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.2531 - acc: 0.9319 - val_loss: 0.2751 - val_acc: 0.9439\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.2399 - acc: 0.9217 - val_loss: 0.4481 - val_acc: 0.7850\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.4017 - acc: 0.8178 - val_loss: 0.4679 - val_acc: 0.7570\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.2924 - acc: 0.8907 - val_loss: 0.3424 - val_acc: 0.8505\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.2651 - acc: 0.8837 - val_loss: 0.4863 - val_acc: 0.7383\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.2827 - acc: 0.8908 - val_loss: 0.2758 - val_acc: 0.8972\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.2423 - acc: 0.8908 - val_loss: 0.2361 - val_acc: 0.9439\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.1937 - acc: 0.9406 - val_loss: 0.2924 - val_acc: 0.9065\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.1824 - acc: 0.9474 - val_loss: 0.2509 - val_acc: 0.9065\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.1890 - acc: 0.9244 - val_loss: 0.2310 - val_acc: 0.9252\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.1540 - acc: 0.9609 - val_loss: 0.2321 - val_acc: 0.9252\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.1390 - acc: 0.9596 - val_loss: 0.2077 - val_acc: 0.9346\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.1469 - acc: 0.9408 - val_loss: 0.2060 - val_acc: 0.9252\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.1263 - acc: 0.9589 - val_loss: 0.1790 - val_acc: 0.9439\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.1099 - acc: 0.9562 - val_loss: 0.1712 - val_acc: 0.9439\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.1011 - acc: 0.9637 - val_loss: 0.2098 - val_acc: 0.9065\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0993 - acc: 0.9757 - val_loss: 0.1584 - val_acc: 0.9439\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0893 - acc: 0.9596 - val_loss: 0.1630 - val_acc: 0.9439\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0767 - acc: 0.9825 - val_loss: 0.1443 - val_acc: 0.9439\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0691 - acc: 0.9743 - val_loss: 0.1464 - val_acc: 0.9439\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0700 - acc: 0.9886 - val_loss: 0.1370 - val_acc: 0.9533\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0687 - acc: 0.9675 - val_loss: 0.1508 - val_acc: 0.9252\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0658 - acc: 0.9932 - val_loss: 0.1395 - val_acc: 0.9439\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0692 - acc: 0.9689 - val_loss: 0.1287 - val_acc: 0.9439\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0572 - acc: 0.9926 - val_loss: 0.1274 - val_acc: 0.9439\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0495 - acc: 0.9925 - val_loss: 0.1404 - val_acc: 0.9439\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0495 - acc: 0.9859 - val_loss: 0.1711 - val_acc: 0.9346\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0509 - acc: 0.9993 - val_loss: 0.1204 - val_acc: 0.9533\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0454 - acc: 0.9878 - val_loss: 0.1153 - val_acc: 0.9626\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0381 - acc: 0.9960 - val_loss: 0.1435 - val_acc: 0.9346\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0403 - acc: 0.9986 - val_loss: 0.1168 - val_acc: 0.9533\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0372 - acc: 0.9892 - val_loss: 0.1052 - val_acc: 0.9626\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0283 - acc: 0.9933 - val_loss: 0.1210 - val_acc: 0.9439\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.1028 - val_acc: 0.9626\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0252 - acc: 0.9966 - val_loss: 0.1063 - val_acc: 0.9626\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0251 - acc: 0.9953 - val_loss: 0.1024 - val_acc: 0.9626\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.1005 - val_acc: 0.9626\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.0996 - val_acc: 0.9626\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0202 - acc: 0.9960 - val_loss: 0.0955 - val_acc: 0.9533\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0989 - val_acc: 0.9626\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.0939 - val_acc: 0.9533\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0962 - val_acc: 0.9626\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0921 - val_acc: 0.9533\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0916 - val_acc: 0.9626\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0899 - val_acc: 0.9626\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0922 - val_acc: 0.9626\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0890 - val_acc: 0.9626\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 0.9533\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0911 - val_acc: 0.9626\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0920 - val_acc: 0.9626\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0878 - val_acc: 0.9626\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0873 - val_acc: 0.9626\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0899 - val_acc: 0.9626\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0899 - val_acc: 0.9626\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0863 - val_acc: 0.9626\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0858 - val_acc: 0.9720\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0878 - val_acc: 0.9626\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0873 - val_acc: 0.9626\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0847 - val_acc: 0.9720\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 0.9626\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0858 - val_acc: 0.9626\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0857 - val_acc: 0.9533\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 0.9626\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 0.9626\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0844 - val_acc: 0.9626\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0850 - val_acc: 0.9626\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0853 - val_acc: 0.9626\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0853 - val_acc: 0.9626\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 0.9626\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0847 - val_acc: 0.9626\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 0.9720\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0859 - val_acc: 0.9626\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 0.9626\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0844 - val_acc: 0.9626\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 0.9626\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 0.9626\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0844 - val_acc: 0.9626\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 0.9626\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 0.9626\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0858 - val_acc: 0.9720\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9720\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 0.9626\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 0.9533\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0847 - val_acc: 0.9626\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 0.9626\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 0.9626\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9626\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0855 - val_acc: 0.9720\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0864 - val_acc: 0.9626\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0858 - val_acc: 0.9533\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 0.9533\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0857 - val_acc: 0.9720\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0860 - val_acc: 0.9720\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9626\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0865 - val_acc: 0.9626\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0874 - val_acc: 0.9720\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0865 - val_acc: 0.9533\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0862 - val_acc: 0.9533\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0858 - val_acc: 0.9533\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0865 - val_acc: 0.9533\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0865 - val_acc: 0.9533\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0877 - val_acc: 0.9720\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0870 - val_acc: 0.9533\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0868 - val_acc: 0.9533\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0867 - val_acc: 0.9533\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0869 - val_acc: 0.9533\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 9.4948e-04 - acc: 1.0000 - val_loss: 0.0869 - val_acc: 0.9533\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 9.5667e-04 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 0.9626\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 8.8612e-04 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 0.9626\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 8.5463e-04 - acc: 1.0000 - val_loss: 0.0884 - val_acc: 0.9626\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 8.3813e-04 - acc: 1.0000 - val_loss: 0.0881 - val_acc: 0.9533\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 8.5421e-04 - acc: 1.0000 - val_loss: 0.0871 - val_acc: 0.9533\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 8.4314e-04 - acc: 1.0000 - val_loss: 0.0870 - val_acc: 0.9533\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 7.6152e-04 - acc: 1.0000 - val_loss: 0.0881 - val_acc: 0.9626\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 7.6408e-04 - acc: 1.0000 - val_loss: 0.0892 - val_acc: 0.9626\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.4957e-04 - acc: 1.0000 - val_loss: 0.0888 - val_acc: 0.9626\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 7.4524e-04 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 0.9533\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 7.4660e-04 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 0.9626\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 7.0155e-04 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 0.9533\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 6.8641e-04 - acc: 1.0000 - val_loss: 0.0888 - val_acc: 0.9626\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 6.9015e-04 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9626\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 6.3950e-04 - acc: 1.0000 - val_loss: 0.0899 - val_acc: 0.9626\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 6.3577e-04 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9626\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 6.1178e-04 - acc: 1.0000 - val_loss: 0.0898 - val_acc: 0.9626\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 5.5007e-04 - acc: 1.0000 - val_loss: 0.0893 - val_acc: 0.9533\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 5.8182e-04 - acc: 1.0000 - val_loss: 0.0891 - val_acc: 0.9533\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 6.0255e-04 - acc: 1.0000 - val_loss: 0.0892 - val_acc: 0.9533\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 5.5681e-04 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9626\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.8161e-04 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 0.9626\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 5.5251e-04 - acc: 1.0000 - val_loss: 0.0908 - val_acc: 0.9626\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 5.2692e-04 - acc: 1.0000 - val_loss: 0.0904 - val_acc: 0.9626\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 5.0348e-04 - acc: 1.0000 - val_loss: 0.0902 - val_acc: 0.9533\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 4.6708e-04 - acc: 1.0000 - val_loss: 0.0904 - val_acc: 0.9626\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 4.9162e-04 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 0.9533\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 4.8799e-04 - acc: 1.0000 - val_loss: 0.0908 - val_acc: 0.9533\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.7072e-04 - acc: 1.0000 - val_loss: 0.0904 - val_acc: 0.9533\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 4.5671e-04 - acc: 1.0000 - val_loss: 0.0908 - val_acc: 0.9626\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 4.6012e-04 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 0.9533\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 4.3159e-04 - acc: 1.0000 - val_loss: 0.0910 - val_acc: 0.9626\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.4186e-04 - acc: 1.0000 - val_loss: 0.0917 - val_acc: 0.9626\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.2462e-04 - acc: 1.0000 - val_loss: 0.0921 - val_acc: 0.9626\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 3.9114e-04 - acc: 1.0000 - val_loss: 0.0919 - val_acc: 0.9533\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.9812e-04 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 0.9533\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.1483e-04 - acc: 1.0000 - val_loss: 0.0912 - val_acc: 0.9626\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.8328e-04 - acc: 1.0000 - val_loss: 0.0913 - val_acc: 0.9533\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.8034e-04 - acc: 1.0000 - val_loss: 0.0916 - val_acc: 0.9533\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.8851e-04 - acc: 1.0000 - val_loss: 0.0927 - val_acc: 0.9626\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.8135e-04 - acc: 1.0000 - val_loss: 0.0932 - val_acc: 0.9626\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.6755e-04 - acc: 1.0000 - val_loss: 0.0927 - val_acc: 0.9533\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.6650e-04 - acc: 1.0000 - val_loss: 0.0926 - val_acc: 0.9533\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 3.4819e-04 - acc: 1.0000 - val_loss: 0.0923 - val_acc: 0.9533\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.2879e-04 - acc: 1.0000 - val_loss: 0.0923 - val_acc: 0.9533\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 3.3949e-04 - acc: 1.0000 - val_loss: 0.0928 - val_acc: 0.9533\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 3.4085e-04 - acc: 1.0000 - val_loss: 0.0931 - val_acc: 0.9533\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.2155e-04 - acc: 1.0000 - val_loss: 0.0934 - val_acc: 0.9626\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.1771e-04 - acc: 1.0000 - val_loss: 0.0932 - val_acc: 0.9533\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.0544e-04 - acc: 1.0000 - val_loss: 0.0933 - val_acc: 0.9533\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.1938e-04 - acc: 1.0000 - val_loss: 0.0936 - val_acc: 0.9533\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.0181e-04 - acc: 1.0000 - val_loss: 0.0938 - val_acc: 0.9533\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 3.1773e-04 - acc: 1.0000 - val_loss: 0.0935 - val_acc: 0.9533\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.8826e-04 - acc: 1.0000 - val_loss: 0.0935 - val_acc: 0.9533\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.9161e-04 - acc: 1.0000 - val_loss: 0.0937 - val_acc: 0.9533\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 3.0581e-04 - acc: 1.0000 - val_loss: 0.0941 - val_acc: 0.9533\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.8348e-04 - acc: 1.0000 - val_loss: 0.0945 - val_acc: 0.9626\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.5933e-04 - acc: 1.0000 - val_loss: 0.0943 - val_acc: 0.9533\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.6205e-04 - acc: 1.0000 - val_loss: 0.0943 - val_acc: 0.9533\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.6144e-04 - acc: 1.0000 - val_loss: 0.0947 - val_acc: 0.9533\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.6567e-04 - acc: 1.0000 - val_loss: 0.0949 - val_acc: 0.9533\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.4436e-04 - acc: 1.0000 - val_loss: 0.0949 - val_acc: 0.9533\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.5259e-04 - acc: 1.0000 - val_loss: 0.0947 - val_acc: 0.9533\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.4530e-04 - acc: 1.0000 - val_loss: 0.0950 - val_acc: 0.9533\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 2.5103e-04 - acc: 1.0000 - val_loss: 0.0951 - val_acc: 0.9533\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 2.3419e-04 - acc: 1.0000 - val_loss: 0.0949 - val_acc: 0.9533\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.2591e-04 - acc: 1.0000 - val_loss: 0.0951 - val_acc: 0.9533\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.2519e-04 - acc: 1.0000 - val_loss: 0.0950 - val_acc: 0.9533\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.3580e-04 - acc: 1.0000 - val_loss: 0.0953 - val_acc: 0.9533\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 2.3083e-04 - acc: 1.0000 - val_loss: 0.0959 - val_acc: 0.9533\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.1754e-04 - acc: 1.0000 - val_loss: 0.0959 - val_acc: 0.9533\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.1766e-04 - acc: 1.0000 - val_loss: 0.0960 - val_acc: 0.9533\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.2198e-04 - acc: 1.0000 - val_loss: 0.0961 - val_acc: 0.9533\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 2.0604e-04 - acc: 1.0000 - val_loss: 0.0962 - val_acc: 0.9533\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.2184e-04 - acc: 1.0000 - val_loss: 0.0957 - val_acc: 0.9533\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 2.1158e-04 - acc: 1.0000 - val_loss: 0.0961 - val_acc: 0.9533\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.1050e-04 - acc: 1.0000 - val_loss: 0.0964 - val_acc: 0.9533\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.0665e-04 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 0.9533\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 2.0161e-04 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9533\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.9590e-04 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9533\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.0528e-04 - acc: 1.0000 - val_loss: 0.0968 - val_acc: 0.9533\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.9007e-04 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9533\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.8861e-04 - acc: 1.0000 - val_loss: 0.0969 - val_acc: 0.9533\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.8132e-04 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9533\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.7759e-04 - acc: 1.0000 - val_loss: 0.0970 - val_acc: 0.9533\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.7060e-04 - acc: 1.0000 - val_loss: 0.0972 - val_acc: 0.9533\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.7999e-04 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9533\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.7094e-04 - acc: 1.0000 - val_loss: 0.0976 - val_acc: 0.9533\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.6978e-04 - acc: 1.0000 - val_loss: 0.0980 - val_acc: 0.9533\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.7343e-04 - acc: 1.0000 - val_loss: 0.0975 - val_acc: 0.9533\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.6193e-04 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9533\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.6257e-04 - acc: 1.0000 - val_loss: 0.0983 - val_acc: 0.9533\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.6921e-04 - acc: 1.0000 - val_loss: 0.0981 - val_acc: 0.9533\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.7284e-04 - acc: 1.0000 - val_loss: 0.0978 - val_acc: 0.9533\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.6469e-04 - acc: 1.0000 - val_loss: 0.0980 - val_acc: 0.9533\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.6087e-04 - acc: 1.0000 - val_loss: 0.0985 - val_acc: 0.9533\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.5888e-04 - acc: 1.0000 - val_loss: 0.0980 - val_acc: 0.9533\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.5561e-04 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9533\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.6446e-04 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9533\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.5393e-04 - acc: 1.0000 - val_loss: 0.0987 - val_acc: 0.9533\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.5196e-04 - acc: 1.0000 - val_loss: 0.0986 - val_acc: 0.9533\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.4445e-04 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9533\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.5753e-04 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9533\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.5166e-04 - acc: 1.0000 - val_loss: 0.0992 - val_acc: 0.9533\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.4827e-04 - acc: 1.0000 - val_loss: 0.0987 - val_acc: 0.9533\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.4006e-04 - acc: 1.0000 - val_loss: 0.0991 - val_acc: 0.9533\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.3801e-04 - acc: 1.0000 - val_loss: 0.0992 - val_acc: 0.9533\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 1.3551e-04 - acc: 1.0000 - val_loss: 0.0991 - val_acc: 0.9533\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 1.3035e-04 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9533\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2925e-04 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9533\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2711e-04 - acc: 1.0000 - val_loss: 0.0991 - val_acc: 0.9533\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.3810e-04 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9533\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.3265e-04 - acc: 1.0000 - val_loss: 0.0997 - val_acc: 0.9533\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.3301e-04 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9533\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.2248e-04 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9533\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.1943e-04 - acc: 1.0000 - val_loss: 0.1002 - val_acc: 0.9533\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2775e-04 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9533\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2432e-04 - acc: 1.0000 - val_loss: 0.0997 - val_acc: 0.9533\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2452e-04 - acc: 1.0000 - val_loss: 0.1001 - val_acc: 0.9533\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2073e-04 - acc: 1.0000 - val_loss: 0.1003 - val_acc: 0.9533\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 1.1891e-04 - acc: 1.0000 - val_loss: 0.0999 - val_acc: 0.9533\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.2027e-04 - acc: 1.0000 - val_loss: 0.1001 - val_acc: 0.9533\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.0652e-04 - acc: 1.0000 - val_loss: 0.1004 - val_acc: 0.9533\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.1805e-04 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 0.9533\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.1271e-04 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 0.9533\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 1.1280e-04 - acc: 1.0000 - val_loss: 0.1003 - val_acc: 0.9533\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.1608e-04 - acc: 1.0000 - val_loss: 0.1004 - val_acc: 0.9533\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.0440e-04 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9533\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.1179e-04 - acc: 1.0000 - val_loss: 0.1004 - val_acc: 0.9533\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.0844e-04 - acc: 1.0000 - val_loss: 0.1004 - val_acc: 0.9533\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 1.0614e-04 - acc: 1.0000 - val_loss: 0.1009 - val_acc: 0.9533\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.0609e-04 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9533\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.0284e-04 - acc: 1.0000 - val_loss: 0.1010 - val_acc: 0.9533\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 1.0302e-04 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9533\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 9.5131e-05 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9533\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 1.0931e-04 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9533\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.0557e-04 - acc: 1.0000 - val_loss: 0.1011 - val_acc: 0.9533\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.0075e-04 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9533\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 1.0192e-04 - acc: 1.0000 - val_loss: 0.1012 - val_acc: 0.9533\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 9.6281e-05 - acc: 1.0000 - val_loss: 0.1014 - val_acc: 0.9533\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 9.8622e-05 - acc: 1.0000 - val_loss: 0.1016 - val_acc: 0.9533\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 9.8141e-05 - acc: 1.0000 - val_loss: 0.1017 - val_acc: 0.9533\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 9.6309e-05 - acc: 1.0000 - val_loss: 0.1013 - val_acc: 0.9533\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 9.8327e-05 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9533\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 9.0782e-05 - acc: 1.0000 - val_loss: 0.1017 - val_acc: 0.9533\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 9.9575e-05 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9533\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 9.4484e-05 - acc: 1.0000 - val_loss: 0.1018 - val_acc: 0.9533\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 8.9644e-05 - acc: 1.0000 - val_loss: 0.1018 - val_acc: 0.9533\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 9.4974e-05 - acc: 1.0000 - val_loss: 0.1022 - val_acc: 0.9533\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 9.4171e-05 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9533\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 9.1145e-05 - acc: 1.0000 - val_loss: 0.1021 - val_acc: 0.9533\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.7145e-05 - acc: 1.0000 - val_loss: 0.1021 - val_acc: 0.9533\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 8.8617e-05 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9533\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 8.5877e-05 - acc: 1.0000 - val_loss: 0.1021 - val_acc: 0.9533\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 8.8409e-05 - acc: 1.0000 - val_loss: 0.1025 - val_acc: 0.9533\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 8.5492e-05 - acc: 1.0000 - val_loss: 0.1025 - val_acc: 0.9533\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 8.5715e-05 - acc: 1.0000 - val_loss: 0.1025 - val_acc: 0.9533\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 8.4050e-05 - acc: 1.0000 - val_loss: 0.1026 - val_acc: 0.9533\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 8.6171e-05 - acc: 1.0000 - val_loss: 0.1028 - val_acc: 0.9533\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.3645e-05 - acc: 1.0000 - val_loss: 0.1024 - val_acc: 0.9533\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 7.9326e-05 - acc: 1.0000 - val_loss: 0.1027 - val_acc: 0.9533\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 8.1858e-05 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9533\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.7634e-05 - acc: 1.0000 - val_loss: 0.1027 - val_acc: 0.9533\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 8.1008e-05 - acc: 1.0000 - val_loss: 0.1026 - val_acc: 0.9533\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 7.8343e-05 - acc: 1.0000 - val_loss: 0.1028 - val_acc: 0.9533\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 7.8441e-05 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9533\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 7.9439e-05 - acc: 1.0000 - val_loss: 0.1027 - val_acc: 0.9533\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 7.2850e-05 - acc: 1.0000 - val_loss: 0.1032 - val_acc: 0.9533\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 8.1060e-05 - acc: 1.0000 - val_loss: 0.1032 - val_acc: 0.9533\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 8.1161e-05 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9533\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 7.0195e-05 - acc: 1.0000 - val_loss: 0.1032 - val_acc: 0.9533\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 7.9782e-05 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9533\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 6.9578e-05 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9533\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 7.5866e-05 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9533\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 7.4019e-05 - acc: 1.0000 - val_loss: 0.1035 - val_acc: 0.9533\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 7.5854e-05 - acc: 1.0000 - val_loss: 0.1038 - val_acc: 0.9533\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.4050e-05 - acc: 1.0000 - val_loss: 0.1033 - val_acc: 0.9533\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 7.1052e-05 - acc: 1.0000 - val_loss: 0.1036 - val_acc: 0.9533\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 7.0118e-05 - acc: 1.0000 - val_loss: 0.1039 - val_acc: 0.9533\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 6.9741e-05 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9533\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 7.1836e-05 - acc: 1.0000 - val_loss: 0.1036 - val_acc: 0.9533\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 6.7115e-05 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9533\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.1195e-05 - acc: 1.0000 - val_loss: 0.1038 - val_acc: 0.9533\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 6.4385e-05 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9533\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.9086e-05 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9533\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 6.2527e-05 - acc: 1.0000 - val_loss: 0.1041 - val_acc: 0.9533\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 6.9358e-05 - acc: 1.0000 - val_loss: 0.1041 - val_acc: 0.9533\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 6.8895e-05 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9533\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 6.4852e-05 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 0.9533\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 6.2238e-05 - acc: 1.0000 - val_loss: 0.1045 - val_acc: 0.9533\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.1171e-05 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 0.9533\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 6.3624e-05 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 0.9533\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 6.3609e-05 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9533\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.8140e-05 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 0.9533\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 6.1562e-05 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 0.9533\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 6.0083e-05 - acc: 1.0000 - val_loss: 0.1049 - val_acc: 0.9533\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.0183e-05 - acc: 1.0000 - val_loss: 0.1050 - val_acc: 0.9533\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.7906e-05 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9533\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 6.1039e-05 - acc: 1.0000 - val_loss: 0.1047 - val_acc: 0.9533\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 6.0151e-05 - acc: 1.0000 - val_loss: 0.1050 - val_acc: 0.9533\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.9921e-05 - acc: 1.0000 - val_loss: 0.1050 - val_acc: 0.9533\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 6.1318e-05 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9533\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 5.7702e-05 - acc: 1.0000 - val_loss: 0.1049 - val_acc: 0.9533\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 5.9798e-05 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9533\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 6.0751e-05 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9533\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 5.4067e-05 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9533\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.6870e-05 - acc: 1.0000 - val_loss: 0.1052 - val_acc: 0.9533\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 5.7313e-05 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9533\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 5.4279e-05 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9533\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 5.7321e-05 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9533\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 5.5335e-05 - acc: 1.0000 - val_loss: 0.1055 - val_acc: 0.9533\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 5.1890e-05 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9533\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 5.4752e-05 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9533\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 5.4012e-05 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 0.9533\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 5.6164e-05 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 0.9533\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 5.2773e-05 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 0.9533\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 5.3446e-05 - acc: 1.0000 - val_loss: 0.1055 - val_acc: 0.9533\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.2431e-05 - acc: 1.0000 - val_loss: 0.1059 - val_acc: 0.9533\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 5.3485e-05 - acc: 1.0000 - val_loss: 0.1057 - val_acc: 0.9533\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.0277e-05 - acc: 1.0000 - val_loss: 0.1058 - val_acc: 0.9533\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.9046e-05 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9533\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 5.1009e-05 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9533\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 5.3083e-05 - acc: 1.0000 - val_loss: 0.1061 - val_acc: 0.9533\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 5.1006e-05 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9533\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.8279e-05 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9533\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.6956e-05 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9533\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.8132e-05 - acc: 1.0000 - val_loss: 0.1065 - val_acc: 0.9533\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.9490e-05 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9533\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 5.1093e-05 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9533\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 4.8200e-05 - acc: 1.0000 - val_loss: 0.1066 - val_acc: 0.9533\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.3477e-05 - acc: 1.0000 - val_loss: 0.1066 - val_acc: 0.9533\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 4.6090e-05 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9533\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.6374e-05 - acc: 1.0000 - val_loss: 0.1065 - val_acc: 0.9533\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 4.9534e-05 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9533\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 4.7147e-05 - acc: 1.0000 - val_loss: 0.1068 - val_acc: 0.9533\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 4.5345e-05 - acc: 1.0000 - val_loss: 0.1066 - val_acc: 0.9533\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.5592e-05 - acc: 1.0000 - val_loss: 0.1065 - val_acc: 0.9533\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.6134e-05 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9533\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 4.6617e-05 - acc: 1.0000 - val_loss: 0.1074 - val_acc: 0.9533\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.4994e-05 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9533\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.5493e-05 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9533\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 4.4404e-05 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9533\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.1996e-05 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9533\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.4027e-05 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9533\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.3215e-05 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9533\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.2894e-05 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9533\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 4.5567e-05 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9533\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 4.3672e-05 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9533\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 4.3882e-05 - acc: 1.0000 - val_loss: 0.1074 - val_acc: 0.9533\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.4443e-05 - acc: 1.0000 - val_loss: 0.1074 - val_acc: 0.9533\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.1461e-05 - acc: 1.0000 - val_loss: 0.1074 - val_acc: 0.9533\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 4.2075e-05 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 0.9533\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.0278e-05 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9533\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 4.0942e-05 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9533\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 4.2163e-05 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9533\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.1399e-05 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9533\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.0322e-05 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9533\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.8103e-05 - acc: 1.0000 - val_loss: 0.1080 - val_acc: 0.9533\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 3.9610e-05 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9533\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 3.9548e-05 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9533\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 4.1933e-05 - acc: 1.0000 - val_loss: 0.1080 - val_acc: 0.9533\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 4.0237e-05 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9533\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.9502e-05 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9533\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 4.0305e-05 - acc: 1.0000 - val_loss: 0.1080 - val_acc: 0.9533\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.9937e-05 - acc: 1.0000 - val_loss: 0.1083 - val_acc: 0.9533\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 3.9653e-05 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9533\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.6554e-05 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9533\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.7918e-05 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9533\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.5648e-05 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9533\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.7504e-05 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9533\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.7937e-05 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9533\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.0070e-05 - acc: 1.0000 - val_loss: 0.1087 - val_acc: 0.9533\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.5030e-05 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9533\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.5427e-05 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9533\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 3.5323e-05 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9533\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 3.6645e-05 - acc: 1.0000 - val_loss: 0.1088 - val_acc: 0.9533\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.3539e-05 - acc: 1.0000 - val_loss: 0.1090 - val_acc: 0.9533\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.5030e-05 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9533\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.7240e-05 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9533\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 3.4693e-05 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9533\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.5575e-05 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9533\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.5481e-05 - acc: 1.0000 - val_loss: 0.1090 - val_acc: 0.9533\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.5740e-05 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9533\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.3590e-05 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9533\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 3.3937e-05 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9533\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.2908e-05 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9533\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 3.4884e-05 - acc: 1.0000 - val_loss: 0.1090 - val_acc: 0.9533\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 3.5421e-05 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9533\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.4636e-05 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9533\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.3933e-05 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9533\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.4704e-05 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9533\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 3.4299e-05 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9533\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.4669e-05 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9533\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.1480e-05 - acc: 1.0000 - val_loss: 0.1096 - val_acc: 0.9533\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.3172e-05 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9533\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.3589e-05 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9533\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.2277e-05 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9533\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.1628e-05 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9533\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.2382e-05 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9533\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 3.2460e-05 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9533\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 3.0518e-05 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9533\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.2119e-05 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9533\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.9158e-05 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9533\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.1881e-05 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9533\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 3.0481e-05 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9533\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 3.1616e-05 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9533\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.2000e-05 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9533\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 2.9593e-05 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 0.9533\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.9037e-05 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 0.9533\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 2.7626e-05 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 0.9533\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 3.0318e-05 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 0.9533\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 3.1147e-05 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 0.9533\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.9849e-05 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9533\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.0175e-05 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9533\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.7525e-05 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9533\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.8825e-05 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 0.9533\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.9073e-05 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9533\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 2.8725e-05 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9533\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.8498e-05 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9533\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.9139e-05 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9533\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.7764e-05 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9533\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 2.8443e-05 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9533\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.8698e-05 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 0.9533\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.9042e-05 - acc: 1.0000 - val_loss: 0.1109 - val_acc: 0.9533\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 2.7902e-05 - acc: 1.0000 - val_loss: 0.1110 - val_acc: 0.9533\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.8651e-05 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 0.9533\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.7761e-05 - acc: 1.0000 - val_loss: 0.1109 - val_acc: 0.9533\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.7783e-05 - acc: 1.0000 - val_loss: 0.1111 - val_acc: 0.9533\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.6356e-05 - acc: 1.0000 - val_loss: 0.1111 - val_acc: 0.9533\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 2.7201e-05 - acc: 1.0000 - val_loss: 0.1111 - val_acc: 0.9533\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 2.6634e-05 - acc: 1.0000 - val_loss: 0.1113 - val_acc: 0.9533\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 2.7099e-05 - acc: 1.0000 - val_loss: 0.1111 - val_acc: 0.9533\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.7481e-05 - acc: 1.0000 - val_loss: 0.1112 - val_acc: 0.9533\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.5912e-05 - acc: 1.0000 - val_loss: 0.1112 - val_acc: 0.9533\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 2.5015e-05 - acc: 1.0000 - val_loss: 0.1113 - val_acc: 0.9533\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.5750e-05 - acc: 1.0000 - val_loss: 0.1114 - val_acc: 0.9533\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 2.6394e-05 - acc: 1.0000 - val_loss: 0.1114 - val_acc: 0.9533\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 2.6523e-05 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9533\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 2.6586e-05 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9533\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.5200e-05 - acc: 1.0000 - val_loss: 0.1116 - val_acc: 0.9533\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.7168e-05 - acc: 1.0000 - val_loss: 0.1116 - val_acc: 0.9533\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 2.2881e-05 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9533\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.3592e-05 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9533\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.6335e-05 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9533\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 2.5058e-05 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9533\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 186ms/step - loss: 2.4836e-05 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9533\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 2.4923e-05 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9533\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.6674e-05 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9533\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 2.5024e-05 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9533\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.4338e-05 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9533\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.3548e-05 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9533\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 2.6188e-05 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9533\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.2713e-05 - acc: 1.0000 - val_loss: 0.1123 - val_acc: 0.9533\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 2.3863e-05 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qzK4SJB5y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "c5a17205-7bc2-495c-a687-010f7c24693b"
      },
      "source": [
        "plt.figure(figsize =(5,3))\n",
        "plt.plot(history.history['acc'], marker='.', label='tune')\n",
        "plt.plot(history.history['val_acc'], marker='.', label='test')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGBi22ZGy38"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}